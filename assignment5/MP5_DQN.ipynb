{"cells":[{"cell_type":"markdown","metadata":{"id":"mqXAPK6c324-"},"source":["# Deep Q-Learning "]},{"cell_type":"markdown","metadata":{"id":"ySoqeAAp325A"},"source":["Install dependencies for AI gym to run properly (shouldn't take more than a minute). If running on google cloud or running locally, only need to run once. Colab may require installing everytime the vm shuts down."]},{"cell_type":"code","source":["# you will be prompted with a window asking to grant permissions\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KJfA-_lR357n","executionInfo":{"status":"ok","timestamp":1683337698245,"user_tz":300,"elapsed":17451,"user":{"displayName":"Yoon Jae Hwang","userId":"10758045548003148631"}},"outputId":"f7063bab-4280-48e1-e362-b2721a75137f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# fill in the path in your Google Drive in the string below. Note: do not escape slashes or spaces\n","import os\n","datadir = \"/content/assignment5_materials\"\n","if not os.path.exists(datadir):\n","  !ln -s \"/content/drive/My Drive/CS444/assignment5_materials/\" $datadir # TODO: Fill your A5 path\n","os.chdir(datadir)\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tGbfwUbI4A_E","executionInfo":{"status":"ok","timestamp":1683337699585,"user_tz":300,"elapsed":371,"user":{"displayName":"Yoon Jae Hwang","userId":"10758045548003148631"}},"outputId":"00993cf0-71c3-4c45-9809-41f7afd69b1b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/CS444/assignment5_materials\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R1mHFysE325B","executionInfo":{"status":"ok","timestamp":1683337718249,"user_tz":300,"elapsed":17363,"user":{"displayName":"Yoon Jae Hwang","userId":"10758045548003148631"}},"outputId":"2db776d4-e27a-482f-e3c5-69e407f30b4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n","Collecting pyvirtualdisplay\n","  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.22.4)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n","Installing collected packages: pyvirtualdisplay\n","Successfully installed pyvirtualdisplay-3.0\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n","The following additional packages will be installed:\n","  freeglut3 libfontenc1 libpython2-stdlib libxfont2 libxkbfile1 python2\n","  python2-minimal x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n","  xserver-common\n","Suggested packages:\n","  python-tk python-numpy libgle3 python2-doc\n","The following NEW packages will be installed:\n","  freeglut3 libfontenc1 libpython2-stdlib libxfont2 libxkbfile1 python-opengl\n","  python2 python2-minimal x11-xkb-utils xfonts-base xfonts-encodings\n","  xfonts-utils xserver-common xvfb\n","0 upgraded, 14 newly installed, 0 to remove and 24 not upgraded.\n","Need to get 8,318 kB of archives.\n","After this operation, 18.0 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2-minimal amd64 2.7.17-2ubuntu4 [27.5 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpython2-stdlib amd64 2.7.17-2ubuntu4 [7,072 B]\n","Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 python2 amd64 2.7.17-2ubuntu4 [26.5 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu focal/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libfontenc1 amd64 1:1.1.4-0ubuntu1 [14.0 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu focal/main amd64 libxfont2 amd64 1:2.0.3-1 [91.7 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 libxkbfile1 amd64 1:1.1.0-1 [65.3 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 python-opengl all 3.1.0+dfsg-2build1 [486 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu focal/main amd64 x11-xkb-utils amd64 7.7+5 [158 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu1 [573 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-utils amd64 1:7.7+6 [91.5 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 xserver-common all 2:1.20.13-1ubuntu1~20.04.8 [27.2 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 xvfb amd64 2:1.20.13-1ubuntu1~20.04.8 [780 kB]\n","Fetched 8,318 kB in 1s (11.1 MB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 14.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package python2-minimal.\n","(Reading database ... 122518 files and directories currently installed.)\n","Preparing to unpack .../python2-minimal_2.7.17-2ubuntu4_amd64.deb ...\n","Unpacking python2-minimal (2.7.17-2ubuntu4) ...\n","Selecting previously unselected package libpython2-stdlib:amd64.\n","Preparing to unpack .../libpython2-stdlib_2.7.17-2ubuntu4_amd64.deb ...\n","Unpacking libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n","Setting up python2-minimal (2.7.17-2ubuntu4) ...\n","Selecting previously unselected package python2.\n","(Reading database ... 122547 files and directories currently installed.)\n","Preparing to unpack .../00-python2_2.7.17-2ubuntu4_amd64.deb ...\n","Unpacking python2 (2.7.17-2ubuntu4) ...\n","Selecting previously unselected package freeglut3:amd64.\n","Preparing to unpack .../01-freeglut3_2.8.1-3_amd64.deb ...\n","Unpacking freeglut3:amd64 (2.8.1-3) ...\n","Selecting previously unselected package libfontenc1:amd64.\n","Preparing to unpack .../02-libfontenc1_1%3a1.1.4-0ubuntu1_amd64.deb ...\n","Unpacking libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n","Selecting previously unselected package libxfont2:amd64.\n","Preparing to unpack .../03-libxfont2_1%3a2.0.3-1_amd64.deb ...\n","Unpacking libxfont2:amd64 (1:2.0.3-1) ...\n","Selecting previously unselected package libxkbfile1:amd64.\n","Preparing to unpack .../04-libxkbfile1_1%3a1.1.0-1_amd64.deb ...\n","Unpacking libxkbfile1:amd64 (1:1.1.0-1) ...\n","Selecting previously unselected package python-opengl.\n","Preparing to unpack .../05-python-opengl_3.1.0+dfsg-2build1_all.deb ...\n","Unpacking python-opengl (3.1.0+dfsg-2build1) ...\n","Selecting previously unselected package x11-xkb-utils.\n","Preparing to unpack .../06-x11-xkb-utils_7.7+5_amd64.deb ...\n","Unpacking x11-xkb-utils (7.7+5) ...\n","Selecting previously unselected package xfonts-encodings.\n","Preparing to unpack .../07-xfonts-encodings_1%3a1.0.5-0ubuntu1_all.deb ...\n","Unpacking xfonts-encodings (1:1.0.5-0ubuntu1) ...\n","Selecting previously unselected package xfonts-utils.\n","Preparing to unpack .../08-xfonts-utils_1%3a7.7+6_amd64.deb ...\n","Unpacking xfonts-utils (1:7.7+6) ...\n","Selecting previously unselected package xfonts-base.\n","Preparing to unpack .../09-xfonts-base_1%3a1.0.5_all.deb ...\n","Unpacking xfonts-base (1:1.0.5) ...\n","Selecting previously unselected package xserver-common.\n","Preparing to unpack .../10-xserver-common_2%3a1.20.13-1ubuntu1~20.04.8_all.deb ...\n","Unpacking xserver-common (2:1.20.13-1ubuntu1~20.04.8) ...\n","Selecting previously unselected package xvfb.\n","Preparing to unpack .../11-xvfb_2%3a1.20.13-1ubuntu1~20.04.8_amd64.deb ...\n","Unpacking xvfb (2:1.20.13-1ubuntu1~20.04.8) ...\n","Setting up freeglut3:amd64 (2.8.1-3) ...\n","Setting up libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n","Setting up python2 (2.7.17-2ubuntu4) ...\n","Setting up libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n","Setting up xfonts-encodings (1:1.0.5-0ubuntu1) ...\n","Setting up libxkbfile1:amd64 (1:1.1.0-1) ...\n","Setting up libxfont2:amd64 (1:2.0.3-1) ...\n","Setting up python-opengl (3.1.0+dfsg-2build1) ...\n","Setting up x11-xkb-utils (7.7+5) ...\n","Setting up xfonts-utils (1:7.7+6) ...\n","Setting up xfonts-base (1:1.0.5) ...\n","Setting up xserver-common (2:1.20.13-1ubuntu1~20.04.8) ...\n","Setting up xvfb (2:1.20.13-1ubuntu1~20.04.8) ...\n","Processing triggers for man-db (2.9.1-1) ...\n","Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n","Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"]}],"source":["!pip3 install gym pyvirtualdisplay\n","!sudo apt-get install -y xvfb python-opengl ffmpeg"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ikuJOKvI325C","executionInfo":{"status":"ok","timestamp":1683337751158,"user_tz":300,"elapsed":28321,"user":{"displayName":"Yoon Jae Hwang","userId":"10758045548003148631"}},"outputId":"5757cd72-3331-4dce-9073-401a57c84f46"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ez_setup\n","  Downloading ez_setup-0.9.tar.gz (6.6 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: ez_setup\n","  Building wheel for ez_setup (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ez_setup: filename=ez_setup-0.9-py3-none-any.whl size=11012 sha256=981a72488340c437566e59dff189f7187c7ee9f015fa71bd351809be4138b517\n","  Stored in directory: /root/.cache/pip/wheels/7a/d6/77/8f495e85fb7df23d41c328b9ea3cf0d9e83631b20bba479293\n","Successfully built ez_setup\n","Installing collected packages: ez_setup\n","Successfully installed ez_setup-0.9\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym[atari] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[atari]) (1.22.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[atari]) (2.2.1)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[atari]) (0.0.8)\n","Collecting ale-py~=0.7.5\n","  Downloading ale_py-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.7.5->gym[atari]) (5.12.0)\n","Installing collected packages: ale-py\n","Successfully installed ale-py-0.7.5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym[accept-rom-license] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license]) (0.0.8)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license]) (2.2.1)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[accept-rom-license]) (1.22.4)\n","Collecting autorom[accept-rom-license]~=0.4.2\n","  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (8.1.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (4.65.0)\n","Collecting AutoROM.accept-rom-license\n","  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (3.4)\n","Building wheels for collected packages: AutoROM.accept-rom-license\n","  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446676 sha256=afa0a4acfb4af6d62753283989a2c7dd1d8449b6e412169214ec2a07390b3a8f\n","  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n","Successfully built AutoROM.accept-rom-license\n","Installing collected packages: AutoROM.accept-rom-license, autorom\n","Successfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.4.2\n"]}],"source":["!pip3 install --upgrade setuptools --user\n","!pip3 install ez_setup \n","!pip3 install gym[atari] \n","!pip3 install gym[accept-rom-license] "]},{"cell_type":"markdown","metadata":{"id":"SnMgcaAq325C"},"source":["For this assignment we will implement the Deep Q-Learning algorithm with Experience Replay as described in breakthrough paper __\"Playing Atari with Deep Reinforcement Learning\"__. We will train an agent to play the famous game of __Breakout__."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"C1A5gNm5325C","executionInfo":{"status":"ok","timestamp":1683337761628,"user_tz":300,"elapsed":8714,"user":{"displayName":"Yoon Jae Hwang","userId":"10758045548003148631"}}},"outputs":[],"source":["%matplotlib inline\n","\n","import sys\n","import gym\n","import torch\n","import pylab\n","import random\n","import numpy as np\n","from collections import deque\n","from datetime import datetime\n","from copy import deepcopy\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from utils import find_max_lives, check_live, get_frame, get_init_state\n","from model import DQN\n","from config import *\n","\n","import matplotlib.pyplot as plt\n","# %load_ext autoreload\n","# %autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"FM-0apOq325D"},"source":["## Understanding the environment"]},{"cell_type":"markdown","metadata":{"id":"-Oiaia_s325D"},"source":["In the following cell, we initialize our game of __Breakout__ and you can see how the environment looks like. For further documentation of the of the environment refer to https://www.gymlibrary.dev/environments/atari/breakout/. \n","\n","In breakout, we will use 3 actions \"fire\", \"left\", and \"right\". \"fire\" is only used to reset the game when a life is lost, \"left\" moves the agent left and \"right\" moves the agent right."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"91D5URjs325D","executionInfo":{"status":"ok","timestamp":1683337764041,"user_tz":300,"elapsed":224,"user":{"displayName":"Yoon Jae Hwang","userId":"10758045548003148631"}},"outputId":"4630bed7-9e6c-4f35-af95-b45619493e85"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n"]}],"source":["env = gym.make('BreakoutDeterministic-v4')\n","state = env.reset()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vWDK-Prr325D","executionInfo":{"status":"ok","timestamp":1683337764749,"user_tz":300,"elapsed":143,"user":{"displayName":"Yoon Jae Hwang","userId":"10758045548003148631"}},"outputId":"a097ed6f-c4ae-4c5e-bc5c-f4a94045467d"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n","  logger.deprecation(\n"]}],"source":["number_lives = find_max_lives(env)\n","state_size = env.observation_space.shape\n","action_size = 3 #fire, left, and right"]},{"cell_type":"markdown","metadata":{"id":"B0xF1ME5325D"},"source":["## Creating a DQN Agent"]},{"cell_type":"markdown","metadata":{"id":"5hF9Wt7A325E"},"source":["Here we create a DQN Agent. This agent is defined in the __agent.py__. The corresponding neural network is defined in the __model.py__. Once you've created a working DQN agent, use the code in agent.py to create a double DQN agent in __agent_double.py__. Set the flag \"double_dqn\" to True to train the double DQN agent.\n","\n","__Evaluation Reward__ : The average reward received in the past 100 episodes/games.\n","\n","__Frame__ : Number of frames processed in total.\n","\n","__Memory Size__ : The current size of the replay memory."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"h4QrACa2325E","executionInfo":{"status":"ok","timestamp":1683337773214,"user_tz":300,"elapsed":6895,"user":{"displayName":"Yoon Jae Hwang","userId":"10758045548003148631"}}},"outputs":[],"source":["double_dqn = False # set to True if using double DQN agent\n","\n","if double_dqn:\n","    from agent_double import Agent\n","else:\n","    from agent import Agent\n","\n","agent = Agent(action_size)\n","evaluation_reward = deque(maxlen=evaluation_reward_length)\n","frame = 0\n","memory_size = 0"]},{"cell_type":"markdown","metadata":{"id":"-xc6tlxI325E"},"source":["### Main Training Loop"]},{"cell_type":"markdown","metadata":{"id":"FVxQ6V-H325E"},"source":["In this training loop, we do not render the screen because it slows down training signficantly. To watch the agent play the game, run the code in next section \"Visualize Agent Performance\""]},{"cell_type":"code","execution_count":9,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"lNRWaoah325E","executionInfo":{"status":"error","timestamp":1683346860962,"user_tz":300,"elapsed":9077790,"user":{"displayName":"Yoon Jae Hwang","userId":"10758045548003148631"}},"outputId":"b3986cc7-4536-4245-dc90-037f4a450a5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["episode: 0   score: 1.0   memory length: 172   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.0\n","episode: 1   score: 4.0   memory length: 433   epsilon: 1.0    steps: 261    lr: 0.0001     evaluation reward: 2.5\n","episode: 2   score: 2.0   memory length: 650   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 2.3333333333333335\n","episode: 3   score: 2.0   memory length: 849   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 2.25\n","episode: 4   score: 0.0   memory length: 973   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.8\n","episode: 5   score: 2.0   memory length: 1174   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.8333333333333333\n","episode: 6   score: 0.0   memory length: 1297   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5714285714285714\n","episode: 7   score: 2.0   memory length: 1497   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.625\n","episode: 8   score: 1.0   memory length: 1649   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.5555555555555556\n","episode: 9   score: 0.0   memory length: 1772   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4\n","episode: 10   score: 0.0   memory length: 1896   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2727272727272727\n","episode: 11   score: 0.0   memory length: 2020   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.1666666666666667\n","episode: 12   score: 1.0   memory length: 2190   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.1538461538461537\n","episode: 13   score: 2.0   memory length: 2388   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.2142857142857142\n","episode: 14   score: 0.0   memory length: 2512   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.1333333333333333\n","episode: 15   score: 1.0   memory length: 2663   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.125\n","episode: 16   score: 0.0   memory length: 2787   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.0588235294117647\n","episode: 17   score: 2.0   memory length: 3007   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.1111111111111112\n","episode: 18   score: 5.0   memory length: 3283   epsilon: 1.0    steps: 276    lr: 0.0001     evaluation reward: 1.3157894736842106\n","episode: 19   score: 1.0   memory length: 3455   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.3\n","episode: 20   score: 0.0   memory length: 3579   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2380952380952381\n","episode: 21   score: 1.0   memory length: 3751   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.2272727272727273\n","episode: 22   score: 2.0   memory length: 3950   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.2608695652173914\n","episode: 23   score: 2.0   memory length: 4148   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.2916666666666667\n","episode: 24   score: 2.0   memory length: 4368   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.32\n","episode: 25   score: 3.0   memory length: 4633   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.3846153846153846\n","episode: 26   score: 1.0   memory length: 4785   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.3703703703703705\n","episode: 27   score: 1.0   memory length: 4958   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.3571428571428572\n","episode: 28   score: 0.0   memory length: 5081   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3103448275862069\n","episode: 29   score: 0.0   memory length: 5205   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2666666666666666\n","episode: 30   score: 0.0   memory length: 5329   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2258064516129032\n","episode: 31   score: 0.0   memory length: 5453   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.1875\n","episode: 32   score: 3.0   memory length: 5702   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.2424242424242424\n","episode: 33   score: 2.0   memory length: 5901   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.2647058823529411\n","episode: 34   score: 0.0   memory length: 6025   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2285714285714286\n","episode: 35   score: 0.0   memory length: 6148   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.1944444444444444\n","episode: 36   score: 4.0   memory length: 6404   epsilon: 1.0    steps: 256    lr: 0.0001     evaluation reward: 1.2702702702702702\n","episode: 37   score: 1.0   memory length: 6574   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.263157894736842\n","episode: 38   score: 5.0   memory length: 6855   epsilon: 1.0    steps: 281    lr: 0.0001     evaluation reward: 1.358974358974359\n","episode: 39   score: 2.0   memory length: 7073   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.375\n","episode: 40   score: 2.0   memory length: 7271   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.3902439024390243\n","episode: 41   score: 2.0   memory length: 7472   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.4047619047619047\n","episode: 42   score: 2.0   memory length: 7670   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.4186046511627908\n","episode: 43   score: 1.0   memory length: 7822   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.4090909090909092\n","episode: 44   score: 1.0   memory length: 7974   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.4\n","episode: 45   score: 1.0   memory length: 8144   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.391304347826087\n","episode: 46   score: 0.0   memory length: 8267   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3617021276595744\n","episode: 47   score: 3.0   memory length: 8495   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.3958333333333333\n","episode: 48   score: 3.0   memory length: 8724   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.4285714285714286\n","episode: 49   score: 2.0   memory length: 8922   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.44\n","episode: 50   score: 3.0   memory length: 9194   epsilon: 1.0    steps: 272    lr: 0.0001     evaluation reward: 1.4705882352941178\n","episode: 51   score: 4.0   memory length: 9472   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 1.5192307692307692\n","episode: 52   score: 0.0   memory length: 9595   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.490566037735849\n","episode: 53   score: 2.0   memory length: 9794   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.5\n","episode: 54   score: 3.0   memory length: 10041   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.5272727272727273\n","episode: 55   score: 0.0   memory length: 10164   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n","episode: 56   score: 1.0   memory length: 10334   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.4912280701754386\n","episode: 57   score: 2.0   memory length: 10553   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.5\n","episode: 58   score: 1.0   memory length: 10704   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.4915254237288136\n","episode: 59   score: 1.0   memory length: 10876   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.4833333333333334\n","episode: 60   score: 3.0   memory length: 11143   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.5081967213114753\n","episode: 61   score: 1.0   memory length: 11312   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5\n","episode: 62   score: 0.0   memory length: 11436   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.4761904761904763\n","episode: 63   score: 1.0   memory length: 11588   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.46875\n","episode: 64   score: 1.0   memory length: 11740   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.4615384615384615\n","episode: 65   score: 1.0   memory length: 11891   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.4545454545454546\n","episode: 66   score: 4.0   memory length: 12209   epsilon: 1.0    steps: 318    lr: 0.0001     evaluation reward: 1.492537313432836\n","episode: 67   score: 0.0   memory length: 12332   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4705882352941178\n","episode: 68   score: 2.0   memory length: 12513   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.4782608695652173\n","episode: 69   score: 1.0   memory length: 12684   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.4714285714285715\n","episode: 70   score: 1.0   memory length: 12835   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.4647887323943662\n","episode: 71   score: 2.0   memory length: 13033   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.4722222222222223\n","episode: 72   score: 3.0   memory length: 13281   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.4931506849315068\n","episode: 73   score: 1.0   memory length: 13451   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.4864864864864864\n","episode: 74   score: 2.0   memory length: 13670   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.4933333333333334\n","episode: 75   score: 0.0   memory length: 13793   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4736842105263157\n","episode: 76   score: 2.0   memory length: 14011   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.4805194805194806\n","episode: 77   score: 2.0   memory length: 14210   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.4871794871794872\n","episode: 78   score: 0.0   memory length: 14333   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4683544303797469\n","episode: 79   score: 2.0   memory length: 14532   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.475\n","episode: 80   score: 0.0   memory length: 14656   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.4567901234567902\n","episode: 81   score: 4.0   memory length: 14936   epsilon: 1.0    steps: 280    lr: 0.0001     evaluation reward: 1.4878048780487805\n","episode: 82   score: 0.0   memory length: 15059   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4698795180722892\n","episode: 83   score: 0.0   memory length: 15183   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.4523809523809523\n","episode: 84   score: 1.0   memory length: 15352   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.4470588235294117\n","episode: 85   score: 1.0   memory length: 15523   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.441860465116279\n","episode: 86   score: 0.0   memory length: 15647   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.4252873563218391\n","episode: 87   score: 0.0   memory length: 15771   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.4090909090909092\n","episode: 88   score: 2.0   memory length: 15970   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.4157303370786516\n","episode: 89   score: 2.0   memory length: 16169   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.4222222222222223\n","episode: 90   score: 1.0   memory length: 16341   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.4175824175824177\n","episode: 91   score: 0.0   memory length: 16464   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.4021739130434783\n","episode: 92   score: 1.0   memory length: 16615   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.3978494623655915\n","episode: 93   score: 0.0   memory length: 16739   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.3829787234042554\n","episode: 94   score: 0.0   memory length: 16862   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.368421052631579\n","episode: 95   score: 3.0   memory length: 17129   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.3854166666666667\n","episode: 96   score: 1.0   memory length: 17302   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.3814432989690721\n","episode: 97   score: 2.0   memory length: 17521   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.3877551020408163\n","episode: 98   score: 1.0   memory length: 17691   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.3838383838383839\n","episode: 99   score: 1.0   memory length: 17860   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.38\n","episode: 100   score: 1.0   memory length: 18030   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.38\n","episode: 101   score: 4.0   memory length: 18344   epsilon: 1.0    steps: 314    lr: 0.0001     evaluation reward: 1.38\n","episode: 102   score: 0.0   memory length: 18468   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.36\n","episode: 103   score: 1.0   memory length: 18638   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.35\n","episode: 104   score: 1.0   memory length: 18790   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.36\n","episode: 105   score: 1.0   memory length: 18959   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.35\n","episode: 106   score: 0.0   memory length: 19083   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.35\n","episode: 107   score: 0.0   memory length: 19207   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.33\n","episode: 108   score: 2.0   memory length: 19408   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.34\n","episode: 109   score: 1.0   memory length: 19581   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.35\n","episode: 110   score: 2.0   memory length: 19779   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.37\n","episode: 111   score: 1.0   memory length: 19950   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.38\n","episode: 112   score: 4.0   memory length: 20228   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 1.41\n","episode: 113   score: 6.0   memory length: 20620   epsilon: 1.0    steps: 392    lr: 0.0001     evaluation reward: 1.45\n","episode: 114   score: 2.0   memory length: 20818   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.47\n","episode: 115   score: 3.0   memory length: 21085   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.49\n","episode: 116   score: 1.0   memory length: 21257   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.5\n","episode: 117   score: 3.0   memory length: 21503   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.51\n","episode: 118   score: 5.0   memory length: 21818   epsilon: 1.0    steps: 315    lr: 0.0001     evaluation reward: 1.51\n","episode: 119   score: 3.0   memory length: 22045   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.53\n","episode: 120   score: 2.0   memory length: 22264   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.55\n","episode: 121   score: 3.0   memory length: 22532   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.57\n","episode: 122   score: 1.0   memory length: 22704   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.56\n","episode: 123   score: 0.0   memory length: 22828   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.54\n","episode: 124   score: 3.0   memory length: 23098   epsilon: 1.0    steps: 270    lr: 0.0001     evaluation reward: 1.55\n","episode: 125   score: 1.0   memory length: 23268   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.53\n","episode: 126   score: 4.0   memory length: 23545   epsilon: 1.0    steps: 277    lr: 0.0001     evaluation reward: 1.56\n","episode: 127   score: 2.0   memory length: 23764   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.57\n","episode: 128   score: 3.0   memory length: 23990   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.6\n","episode: 129   score: 2.0   memory length: 24188   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.62\n","episode: 130   score: 2.0   memory length: 24408   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.64\n","episode: 131   score: 1.0   memory length: 24581   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.65\n","episode: 132   score: 0.0   memory length: 24705   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.62\n","episode: 133   score: 0.0   memory length: 24828   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\n","episode: 134   score: 1.0   memory length: 24999   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.61\n","episode: 135   score: 3.0   memory length: 25248   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.64\n","episode: 136   score: 0.0   memory length: 25372   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.6\n","episode: 137   score: 0.0   memory length: 25495   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.59\n","episode: 138   score: 0.0   memory length: 25619   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.54\n","episode: 139   score: 1.0   memory length: 25792   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.53\n","episode: 140   score: 1.0   memory length: 25963   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.52\n","episode: 141   score: 0.0   memory length: 26086   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n","episode: 142   score: 0.0   memory length: 26210   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.48\n","episode: 143   score: 1.0   memory length: 26382   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.48\n","episode: 144   score: 0.0   memory length: 26506   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.47\n","episode: 145   score: 2.0   memory length: 26709   epsilon: 1.0    steps: 203    lr: 0.0001     evaluation reward: 1.48\n","episode: 146   score: 0.0   memory length: 26832   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.48\n","episode: 147   score: 2.0   memory length: 27031   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.47\n","episode: 148   score: 2.0   memory length: 27232   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.46\n","episode: 149   score: 1.0   memory length: 27405   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.45\n","episode: 150   score: 0.0   memory length: 27529   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.42\n","episode: 151   score: 2.0   memory length: 27727   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.4\n","episode: 152   score: 1.0   memory length: 27896   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.41\n","episode: 153   score: 4.0   memory length: 28212   epsilon: 1.0    steps: 316    lr: 0.0001     evaluation reward: 1.43\n","episode: 154   score: 1.0   memory length: 28384   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.41\n","episode: 155   score: 1.0   memory length: 28535   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.42\n","episode: 156   score: 0.0   memory length: 28659   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.41\n","episode: 157   score: 1.0   memory length: 28830   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.4\n","episode: 158   score: 1.0   memory length: 28982   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.4\n","episode: 159   score: 0.0   memory length: 29106   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.39\n","episode: 160   score: 1.0   memory length: 29258   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.37\n","episode: 161   score: 2.0   memory length: 29477   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.38\n","episode: 162   score: 2.0   memory length: 29697   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.4\n","episode: 163   score: 0.0   memory length: 29821   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.39\n","episode: 164   score: 3.0   memory length: 30067   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.41\n","episode: 165   score: 1.0   memory length: 30237   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.41\n","episode: 166   score: 2.0   memory length: 30436   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.39\n","episode: 167   score: 1.0   memory length: 30588   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.4\n","episode: 168   score: 0.0   memory length: 30712   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.38\n","episode: 169   score: 1.0   memory length: 30882   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.38\n","episode: 170   score: 1.0   memory length: 31034   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.38\n","episode: 171   score: 0.0   memory length: 31158   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.36\n","episode: 172   score: 0.0   memory length: 31282   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.33\n","episode: 173   score: 3.0   memory length: 31550   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.35\n","episode: 174   score: 1.0   memory length: 31720   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.34\n","episode: 175   score: 0.0   memory length: 31844   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.34\n","episode: 176   score: 3.0   memory length: 32094   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.35\n","episode: 177   score: 0.0   memory length: 32217   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.33\n","episode: 178   score: 0.0   memory length: 32341   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.33\n","episode: 179   score: 2.0   memory length: 32559   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.33\n","episode: 180   score: 1.0   memory length: 32710   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.34\n","episode: 181   score: 1.0   memory length: 32879   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.31\n","episode: 182   score: 1.0   memory length: 33051   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.32\n","episode: 183   score: 6.0   memory length: 33465   epsilon: 1.0    steps: 414    lr: 0.0001     evaluation reward: 1.38\n","episode: 184   score: 4.0   memory length: 33734   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.41\n","episode: 185   score: 1.0   memory length: 33904   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.41\n","episode: 186   score: 3.0   memory length: 34151   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.44\n","episode: 187   score: 2.0   memory length: 34370   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.46\n","episode: 188   score: 3.0   memory length: 34616   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.47\n","episode: 189   score: 1.0   memory length: 34767   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.46\n","episode: 190   score: 2.0   memory length: 34966   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.47\n","episode: 191   score: 0.0   memory length: 35090   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.47\n","episode: 192   score: 1.0   memory length: 35241   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.47\n","episode: 193   score: 0.0   memory length: 35364   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\n","episode: 194   score: 2.0   memory length: 35548   epsilon: 1.0    steps: 184    lr: 0.0001     evaluation reward: 1.49\n","episode: 195   score: 2.0   memory length: 35749   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.48\n","episode: 196   score: 2.0   memory length: 35948   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.49\n","episode: 197   score: 4.0   memory length: 36246   epsilon: 1.0    steps: 298    lr: 0.0001     evaluation reward: 1.51\n","episode: 198   score: 3.0   memory length: 36474   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.53\n","episode: 199   score: 3.0   memory length: 36725   epsilon: 1.0    steps: 251    lr: 0.0001     evaluation reward: 1.55\n","episode: 200   score: 1.0   memory length: 36895   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.55\n","episode: 201   score: 2.0   memory length: 37093   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.53\n","episode: 202   score: 0.0   memory length: 37217   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.53\n","episode: 203   score: 2.0   memory length: 37415   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.54\n","episode: 204   score: 2.0   memory length: 37596   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.55\n","episode: 205   score: 0.0   memory length: 37719   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.54\n","episode: 206   score: 3.0   memory length: 37946   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.57\n","episode: 207   score: 0.0   memory length: 38070   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.57\n","episode: 208   score: 3.0   memory length: 38316   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.58\n","episode: 209   score: 0.0   memory length: 38440   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.57\n","episode: 210   score: 2.0   memory length: 38622   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.57\n","episode: 211   score: 0.0   memory length: 38745   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.56\n","episode: 212   score: 2.0   memory length: 38943   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.54\n","episode: 213   score: 1.0   memory length: 39115   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.49\n","episode: 214   score: 0.0   memory length: 39239   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.47\n","episode: 215   score: 7.0   memory length: 39537   epsilon: 1.0    steps: 298    lr: 0.0001     evaluation reward: 1.51\n","episode: 216   score: 1.0   memory length: 39689   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.51\n","episode: 217   score: 1.0   memory length: 39858   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.49\n","episode: 218   score: 2.0   memory length: 40075   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.46\n","episode: 219   score: 3.0   memory length: 40340   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.46\n","episode: 220   score: 0.0   memory length: 40464   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.44\n","episode: 221   score: 0.0   memory length: 40588   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.41\n","episode: 222   score: 1.0   memory length: 40757   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.41\n","episode: 223   score: 2.0   memory length: 40955   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.43\n","episode: 224   score: 1.0   memory length: 41107   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.41\n","episode: 225   score: 3.0   memory length: 41354   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.43\n","episode: 226   score: 0.0   memory length: 41477   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n","episode: 227   score: 2.0   memory length: 41697   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.39\n","episode: 228   score: 1.0   memory length: 41849   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.37\n","episode: 229   score: 0.0   memory length: 41973   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.35\n","episode: 230   score: 1.0   memory length: 42125   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.34\n","episode: 231   score: 1.0   memory length: 42297   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.34\n","episode: 232   score: 1.0   memory length: 42448   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.35\n","episode: 233   score: 0.0   memory length: 42572   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.35\n","episode: 234   score: 0.0   memory length: 42696   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.34\n","episode: 235   score: 0.0   memory length: 42820   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.31\n","episode: 236   score: 1.0   memory length: 42990   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.32\n","episode: 237   score: 4.0   memory length: 43269   epsilon: 1.0    steps: 279    lr: 0.0001     evaluation reward: 1.36\n","episode: 238   score: 0.0   memory length: 43393   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.36\n","episode: 239   score: 2.0   memory length: 43610   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.37\n","episode: 240   score: 3.0   memory length: 43855   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.39\n","episode: 241   score: 0.0   memory length: 43979   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.39\n","episode: 242   score: 3.0   memory length: 44251   epsilon: 1.0    steps: 272    lr: 0.0001     evaluation reward: 1.42\n","episode: 243   score: 3.0   memory length: 44499   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.44\n","episode: 244   score: 2.0   memory length: 44698   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.46\n","episode: 245   score: 0.0   memory length: 44822   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.44\n","episode: 246   score: 1.0   memory length: 44974   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.45\n","episode: 247   score: 2.0   memory length: 45173   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.45\n","episode: 248   score: 0.0   memory length: 45296   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\n","episode: 249   score: 2.0   memory length: 45495   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.44\n","episode: 250   score: 2.0   memory length: 45694   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.46\n","episode: 251   score: 4.0   memory length: 45969   epsilon: 1.0    steps: 275    lr: 0.0001     evaluation reward: 1.48\n","episode: 252   score: 3.0   memory length: 46217   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.5\n","episode: 253   score: 4.0   memory length: 46518   epsilon: 1.0    steps: 301    lr: 0.0001     evaluation reward: 1.5\n","episode: 254   score: 0.0   memory length: 46641   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\n","episode: 255   score: 2.0   memory length: 46857   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.5\n","episode: 256   score: 2.0   memory length: 47056   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.52\n","episode: 257   score: 3.0   memory length: 47269   epsilon: 1.0    steps: 213    lr: 0.0001     evaluation reward: 1.54\n","episode: 258   score: 1.0   memory length: 47439   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.54\n","episode: 259   score: 0.0   memory length: 47563   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.54\n","episode: 260   score: 3.0   memory length: 47830   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.56\n","episode: 261   score: 3.0   memory length: 48095   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.57\n","episode: 262   score: 3.0   memory length: 48342   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.58\n","episode: 263   score: 2.0   memory length: 48562   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.6\n","episode: 264   score: 1.0   memory length: 48714   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.58\n","episode: 265   score: 2.0   memory length: 48913   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.59\n","episode: 266   score: 0.0   memory length: 49037   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.57\n","episode: 267   score: 2.0   memory length: 49236   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.58\n","episode: 268   score: 2.0   memory length: 49452   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.6\n","episode: 269   score: 2.0   memory length: 49672   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.61\n","episode: 270   score: 1.0   memory length: 49842   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.61\n","episode: 271   score: 4.0   memory length: 50119   epsilon: 1.0    steps: 277    lr: 0.0001     evaluation reward: 1.65\n","episode: 272   score: 3.0   memory length: 50364   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.68\n","episode: 273   score: 2.0   memory length: 50562   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.67\n","episode: 274   score: 4.0   memory length: 50860   epsilon: 1.0    steps: 298    lr: 0.0001     evaluation reward: 1.7\n","episode: 275   score: 0.0   memory length: 50984   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.7\n","episode: 276   score: 1.0   memory length: 51135   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.68\n","episode: 277   score: 0.0   memory length: 51259   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.68\n","episode: 278   score: 2.0   memory length: 51481   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.7\n","episode: 279   score: 1.0   memory length: 51633   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.69\n","episode: 280   score: 3.0   memory length: 51878   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.71\n","episode: 281   score: 2.0   memory length: 52077   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.72\n","episode: 282   score: 0.0   memory length: 52201   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.71\n","episode: 283   score: 4.0   memory length: 52481   epsilon: 1.0    steps: 280    lr: 0.0001     evaluation reward: 1.69\n","episode: 284   score: 0.0   memory length: 52605   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.65\n","episode: 285   score: 0.0   memory length: 52729   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.64\n","episode: 286   score: 1.0   memory length: 52900   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.62\n","episode: 287   score: 1.0   memory length: 53052   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.61\n","episode: 288   score: 0.0   memory length: 53175   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.58\n","episode: 289   score: 6.0   memory length: 53507   epsilon: 1.0    steps: 332    lr: 0.0001     evaluation reward: 1.63\n","episode: 290   score: 2.0   memory length: 53687   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.63\n","episode: 291   score: 0.0   memory length: 53810   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.63\n","episode: 292   score: 0.0   memory length: 53933   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.62\n","episode: 293   score: 2.0   memory length: 54131   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.64\n","episode: 294   score: 1.0   memory length: 54300   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.63\n","episode: 295   score: 1.0   memory length: 54470   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.62\n","episode: 296   score: 1.0   memory length: 54641   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.61\n","episode: 297   score: 4.0   memory length: 54955   epsilon: 1.0    steps: 314    lr: 0.0001     evaluation reward: 1.61\n","episode: 298   score: 1.0   memory length: 55124   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.59\n","episode: 299   score: 3.0   memory length: 55372   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.59\n","episode: 300   score: 1.0   memory length: 55524   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.59\n","episode: 301   score: 0.0   memory length: 55647   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.57\n","episode: 302   score: 0.0   memory length: 55771   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.57\n","episode: 303   score: 0.0   memory length: 55895   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.55\n","episode: 304   score: 1.0   memory length: 56065   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.54\n","episode: 305   score: 2.0   memory length: 56246   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.56\n","episode: 306   score: 1.0   memory length: 56419   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.54\n","episode: 307   score: 2.0   memory length: 56641   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.56\n","episode: 308   score: 1.0   memory length: 56793   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.54\n","episode: 309   score: 1.0   memory length: 56963   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.55\n","episode: 310   score: 2.0   memory length: 57182   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.55\n","episode: 311   score: 3.0   memory length: 57432   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.58\n","episode: 312   score: 1.0   memory length: 57583   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.57\n","episode: 313   score: 2.0   memory length: 57766   epsilon: 1.0    steps: 183    lr: 0.0001     evaluation reward: 1.58\n","episode: 314   score: 1.0   memory length: 57935   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.59\n","episode: 315   score: 1.0   memory length: 58106   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.53\n","episode: 316   score: 2.0   memory length: 58325   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.54\n","episode: 317   score: 0.0   memory length: 58449   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.53\n","episode: 318   score: 2.0   memory length: 58648   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.53\n","episode: 319   score: 4.0   memory length: 58924   epsilon: 1.0    steps: 276    lr: 0.0001     evaluation reward: 1.54\n","episode: 320   score: 3.0   memory length: 59173   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.57\n","episode: 321   score: 3.0   memory length: 59403   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 1.6\n","episode: 322   score: 1.0   memory length: 59555   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.6\n","episode: 323   score: 2.0   memory length: 59754   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.6\n","episode: 324   score: 1.0   memory length: 59906   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.6\n","episode: 325   score: 0.0   memory length: 60029   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.57\n","episode: 326   score: 0.0   memory length: 60152   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.57\n","episode: 327   score: 3.0   memory length: 60383   epsilon: 1.0    steps: 231    lr: 0.0001     evaluation reward: 1.58\n","episode: 328   score: 4.0   memory length: 60663   epsilon: 1.0    steps: 280    lr: 0.0001     evaluation reward: 1.61\n","episode: 329   score: 3.0   memory length: 60890   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.64\n","episode: 330   score: 2.0   memory length: 61109   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.65\n","episode: 331   score: 0.0   memory length: 61233   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.64\n","episode: 332   score: 3.0   memory length: 61462   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.66\n","episode: 333   score: 0.0   memory length: 61586   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.66\n","episode: 334   score: 0.0   memory length: 61710   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.66\n","episode: 335   score: 2.0   memory length: 61930   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.68\n","episode: 336   score: 2.0   memory length: 62128   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.69\n","episode: 337   score: 0.0   memory length: 62252   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.65\n","episode: 338   score: 3.0   memory length: 62499   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.68\n","episode: 339   score: 0.0   memory length: 62623   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.66\n","episode: 340   score: 4.0   memory length: 62942   epsilon: 1.0    steps: 319    lr: 0.0001     evaluation reward: 1.67\n","episode: 341   score: 0.0   memory length: 63065   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.67\n","episode: 342   score: 3.0   memory length: 63313   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.67\n","episode: 343   score: 1.0   memory length: 63483   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.65\n","episode: 344   score: 0.0   memory length: 63607   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.63\n","episode: 345   score: 3.0   memory length: 63875   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.66\n","episode: 346   score: 0.0   memory length: 63999   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.65\n","episode: 347   score: 0.0   memory length: 64122   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.63\n","episode: 348   score: 0.0   memory length: 64245   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.63\n","episode: 349   score: 0.0   memory length: 64369   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.61\n","episode: 350   score: 1.0   memory length: 64541   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.6\n","episode: 351   score: 1.0   memory length: 64711   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.57\n","episode: 352   score: 1.0   memory length: 64863   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.55\n","episode: 353   score: 0.0   memory length: 64987   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.51\n","episode: 354   score: 4.0   memory length: 65264   epsilon: 1.0    steps: 277    lr: 0.0001     evaluation reward: 1.55\n","episode: 355   score: 1.0   memory length: 65434   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.54\n","episode: 356   score: 0.0   memory length: 65558   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.52\n","episode: 357   score: 3.0   memory length: 65806   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.52\n","episode: 358   score: 1.0   memory length: 65978   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.52\n","episode: 359   score: 2.0   memory length: 66159   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.54\n","episode: 360   score: 0.0   memory length: 66282   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\n","episode: 361   score: 2.0   memory length: 66503   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.5\n","episode: 362   score: 2.0   memory length: 66722   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.49\n","episode: 363   score: 1.0   memory length: 66874   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.48\n","episode: 364   score: 4.0   memory length: 67173   epsilon: 1.0    steps: 299    lr: 0.0001     evaluation reward: 1.51\n","episode: 365   score: 2.0   memory length: 67391   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.51\n","episode: 366   score: 3.0   memory length: 67657   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.54\n","episode: 367   score: 1.0   memory length: 67809   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.53\n","episode: 368   score: 2.0   memory length: 68027   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.53\n","episode: 369   score: 0.0   memory length: 68151   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.51\n","episode: 370   score: 0.0   memory length: 68274   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n","episode: 371   score: 1.0   memory length: 68446   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.47\n","episode: 372   score: 3.0   memory length: 68711   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.47\n","episode: 373   score: 2.0   memory length: 68909   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.47\n","episode: 374   score: 1.0   memory length: 69061   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.44\n","episode: 375   score: 3.0   memory length: 69306   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.47\n","episode: 376   score: 1.0   memory length: 69458   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.47\n","episode: 377   score: 0.0   memory length: 69581   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\n","episode: 378   score: 2.0   memory length: 69779   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.47\n","episode: 379   score: 2.0   memory length: 69979   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.48\n","episode: 380   score: 1.0   memory length: 70130   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.46\n","episode: 381   score: 2.0   memory length: 70329   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.46\n","episode: 382   score: 0.0   memory length: 70453   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.46\n","episode: 383   score: 2.0   memory length: 70651   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.44\n","episode: 384   score: 1.0   memory length: 70820   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.45\n","episode: 385   score: 3.0   memory length: 71086   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.48\n","episode: 386   score: 3.0   memory length: 71333   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.5\n","episode: 387   score: 3.0   memory length: 71580   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.52\n","episode: 388   score: 1.0   memory length: 71749   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.53\n","episode: 389   score: 0.0   memory length: 71873   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.47\n","episode: 390   score: 0.0   memory length: 71997   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.45\n","episode: 391   score: 2.0   memory length: 72195   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.47\n","episode: 392   score: 2.0   memory length: 72394   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.49\n","episode: 393   score: 0.0   memory length: 72518   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.47\n","episode: 394   score: 1.0   memory length: 72688   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.47\n","episode: 395   score: 2.0   memory length: 72869   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.48\n","episode: 396   score: 0.0   memory length: 72993   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.47\n","episode: 397   score: 1.0   memory length: 73162   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.44\n","episode: 398   score: 0.0   memory length: 73286   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.43\n","episode: 399   score: 3.0   memory length: 73554   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.43\n","episode: 400   score: 3.0   memory length: 73800   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.45\n","episode: 401   score: 0.0   memory length: 73924   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.45\n","episode: 402   score: 3.0   memory length: 74172   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.48\n","episode: 403   score: 3.0   memory length: 74436   epsilon: 1.0    steps: 264    lr: 0.0001     evaluation reward: 1.51\n","episode: 404   score: 1.0   memory length: 74588   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.51\n","episode: 405   score: 3.0   memory length: 74802   epsilon: 1.0    steps: 214    lr: 0.0001     evaluation reward: 1.52\n","episode: 406   score: 1.0   memory length: 74973   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.52\n","episode: 407   score: 0.0   memory length: 75097   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.5\n","episode: 408   score: 3.0   memory length: 75327   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 1.52\n","episode: 409   score: 2.0   memory length: 75545   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.53\n","episode: 410   score: 2.0   memory length: 75744   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.53\n","episode: 411   score: 1.0   memory length: 75896   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.51\n","episode: 412   score: 0.0   memory length: 76020   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.5\n","episode: 413   score: 1.0   memory length: 76190   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.49\n","episode: 414   score: 5.0   memory length: 76515   epsilon: 1.0    steps: 325    lr: 0.0001     evaluation reward: 1.53\n","episode: 415   score: 1.0   memory length: 76685   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.53\n","episode: 416   score: 2.0   memory length: 76903   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.53\n","episode: 417   score: 0.0   memory length: 77027   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.53\n","episode: 418   score: 0.0   memory length: 77151   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.51\n","episode: 419   score: 0.0   memory length: 77275   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.47\n","episode: 420   score: 2.0   memory length: 77457   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.46\n","episode: 421   score: 2.0   memory length: 77675   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.45\n","episode: 422   score: 1.0   memory length: 77848   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.45\n","episode: 423   score: 3.0   memory length: 78074   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.46\n","episode: 424   score: 2.0   memory length: 78275   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.47\n","episode: 425   score: 0.0   memory length: 78398   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.47\n","episode: 426   score: 1.0   memory length: 78569   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.48\n","episode: 427   score: 1.0   memory length: 78721   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.46\n","episode: 428   score: 0.0   memory length: 78845   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.42\n","episode: 429   score: 2.0   memory length: 79045   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.41\n","episode: 430   score: 0.0   memory length: 79169   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.39\n","episode: 431   score: 0.0   memory length: 79293   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.39\n","episode: 432   score: 1.0   memory length: 79463   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.37\n","episode: 433   score: 0.0   memory length: 79586   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.37\n","episode: 434   score: 2.0   memory length: 79805   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.39\n","episode: 435   score: 2.0   memory length: 80026   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.39\n","episode: 436   score: 2.0   memory length: 80225   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.39\n","episode: 437   score: 0.0   memory length: 80348   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n","episode: 438   score: 0.0   memory length: 80472   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.36\n","episode: 439   score: 0.0   memory length: 80596   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.36\n","episode: 440   score: 0.0   memory length: 80720   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.32\n","episode: 441   score: 1.0   memory length: 80872   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.33\n","episode: 442   score: 0.0   memory length: 80995   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3\n","episode: 443   score: 0.0   memory length: 81118   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.29\n","episode: 444   score: 0.0   memory length: 81242   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.29\n","episode: 445   score: 1.0   memory length: 81412   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.27\n","episode: 446   score: 2.0   memory length: 81611   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.29\n","episode: 447   score: 3.0   memory length: 81878   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.32\n","episode: 448   score: 2.0   memory length: 82060   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.34\n","episode: 449   score: 4.0   memory length: 82341   epsilon: 1.0    steps: 281    lr: 0.0001     evaluation reward: 1.38\n","episode: 450   score: 1.0   memory length: 82511   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.38\n","episode: 451   score: 1.0   memory length: 82664   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.38\n","episode: 452   score: 2.0   memory length: 82863   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.39\n","episode: 453   score: 1.0   memory length: 83034   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.4\n","episode: 454   score: 1.0   memory length: 83186   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.37\n","episode: 455   score: 1.0   memory length: 83337   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.37\n","episode: 456   score: 1.0   memory length: 83507   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.38\n","episode: 457   score: 1.0   memory length: 83677   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.36\n","episode: 458   score: 1.0   memory length: 83847   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.36\n","episode: 459   score: 1.0   memory length: 83998   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.35\n","episode: 460   score: 0.0   memory length: 84122   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.35\n","episode: 461   score: 0.0   memory length: 84245   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.33\n","episode: 462   score: 1.0   memory length: 84414   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.32\n","episode: 463   score: 2.0   memory length: 84613   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.33\n","episode: 464   score: 2.0   memory length: 84830   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.31\n","episode: 465   score: 2.0   memory length: 85049   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.31\n","episode: 466   score: 2.0   memory length: 85248   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.3\n","episode: 467   score: 2.0   memory length: 85467   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.31\n","episode: 468   score: 2.0   memory length: 85685   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.31\n","episode: 469   score: 1.0   memory length: 85857   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.32\n","episode: 470   score: 1.0   memory length: 86028   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.33\n","episode: 471   score: 1.0   memory length: 86179   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.33\n","episode: 472   score: 0.0   memory length: 86302   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3\n","episode: 473   score: 1.0   memory length: 86474   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.29\n","episode: 474   score: 4.0   memory length: 86755   epsilon: 1.0    steps: 281    lr: 0.0001     evaluation reward: 1.32\n","episode: 475   score: 4.0   memory length: 87043   epsilon: 1.0    steps: 288    lr: 0.0001     evaluation reward: 1.33\n","episode: 476   score: 1.0   memory length: 87216   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.33\n","episode: 477   score: 2.0   memory length: 87415   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.35\n","episode: 478   score: 2.0   memory length: 87614   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.35\n","episode: 479   score: 2.0   memory length: 87812   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.35\n","episode: 480   score: 1.0   memory length: 87985   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.35\n","episode: 481   score: 1.0   memory length: 88154   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.34\n","episode: 482   score: 2.0   memory length: 88371   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.36\n","episode: 483   score: 0.0   memory length: 88495   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.34\n","episode: 484   score: 0.0   memory length: 88618   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.33\n","episode: 485   score: 2.0   memory length: 88817   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.32\n","episode: 486   score: 0.0   memory length: 88941   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.29\n","episode: 487   score: 3.0   memory length: 89191   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.29\n","episode: 488   score: 1.0   memory length: 89362   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.29\n","episode: 489   score: 4.0   memory length: 89659   epsilon: 1.0    steps: 297    lr: 0.0001     evaluation reward: 1.33\n","episode: 490   score: 1.0   memory length: 89832   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.34\n","episode: 491   score: 0.0   memory length: 89956   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.32\n","episode: 492   score: 2.0   memory length: 90174   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.32\n","episode: 493   score: 0.0   memory length: 90297   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.32\n","episode: 494   score: 1.0   memory length: 90449   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.32\n","episode: 495   score: 0.0   memory length: 90573   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.3\n","episode: 496   score: 6.0   memory length: 90912   epsilon: 1.0    steps: 339    lr: 0.0001     evaluation reward: 1.36\n","episode: 497   score: 2.0   memory length: 91133   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.37\n","episode: 498   score: 0.0   memory length: 91257   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.37\n","episode: 499   score: 0.0   memory length: 91381   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.34\n","episode: 500   score: 3.0   memory length: 91648   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.34\n","episode: 501   score: 1.0   memory length: 91819   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.35\n","episode: 502   score: 1.0   memory length: 91989   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.33\n","episode: 503   score: 2.0   memory length: 92188   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.32\n","episode: 504   score: 1.0   memory length: 92341   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.32\n","episode: 505   score: 0.0   memory length: 92464   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.29\n","episode: 506   score: 2.0   memory length: 92663   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.3\n","episode: 507   score: 0.0   memory length: 92787   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.3\n","episode: 508   score: 0.0   memory length: 92911   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.27\n","episode: 509   score: 2.0   memory length: 93109   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.27\n","episode: 510   score: 1.0   memory length: 93279   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.26\n","episode: 511   score: 4.0   memory length: 93574   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.29\n","episode: 512   score: 0.0   memory length: 93698   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.29\n","episode: 513   score: 1.0   memory length: 93870   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.29\n","episode: 514   score: 0.0   memory length: 93994   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.24\n","episode: 515   score: 0.0   memory length: 94118   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.23\n","episode: 516   score: 0.0   memory length: 94241   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.21\n","episode: 517   score: 4.0   memory length: 94537   epsilon: 1.0    steps: 296    lr: 0.0001     evaluation reward: 1.25\n","episode: 518   score: 5.0   memory length: 94877   epsilon: 1.0    steps: 340    lr: 0.0001     evaluation reward: 1.3\n","episode: 519   score: 3.0   memory length: 95146   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.33\n","episode: 520   score: 0.0   memory length: 95269   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.31\n","episode: 521   score: 1.0   memory length: 95421   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.3\n","episode: 522   score: 2.0   memory length: 95620   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.31\n","episode: 523   score: 1.0   memory length: 95790   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.29\n","episode: 524   score: 4.0   memory length: 96104   epsilon: 1.0    steps: 314    lr: 0.0001     evaluation reward: 1.31\n","episode: 525   score: 0.0   memory length: 96228   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.31\n","episode: 526   score: 1.0   memory length: 96400   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.31\n","episode: 527   score: 0.0   memory length: 96523   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.3\n","episode: 528   score: 3.0   memory length: 96753   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 1.33\n","episode: 529   score: 1.0   memory length: 96905   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.32\n","episode: 530   score: 1.0   memory length: 97075   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.33\n","episode: 531   score: 0.0   memory length: 97199   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.33\n","episode: 532   score: 4.0   memory length: 97496   epsilon: 1.0    steps: 297    lr: 0.0001     evaluation reward: 1.36\n","episode: 533   score: 0.0   memory length: 97619   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.36\n","episode: 534   score: 3.0   memory length: 97845   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.37\n","episode: 535   score: 0.0   memory length: 97968   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.35\n","episode: 536   score: 5.0   memory length: 98292   epsilon: 1.0    steps: 324    lr: 0.0001     evaluation reward: 1.38\n","episode: 537   score: 2.0   memory length: 98473   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.4\n","episode: 538   score: 4.0   memory length: 98761   epsilon: 1.0    steps: 288    lr: 0.0001     evaluation reward: 1.44\n","episode: 539   score: 5.0   memory length: 99068   epsilon: 1.0    steps: 307    lr: 0.0001     evaluation reward: 1.49\n","episode: 540   score: 2.0   memory length: 99266   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.51\n","episode: 541   score: 2.0   memory length: 99485   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.52\n","episode: 542   score: 1.0   memory length: 99637   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.53\n","episode: 543   score: 1.0   memory length: 99810   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.54\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/CS444/assignment5_materials/memory.py:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  sample = np.array(sample)\n","/content/drive/MyDrive/CS444/assignment5_materials/agent.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  mini_batch = np.array(mini_batch).transpose()\n"]},{"output_type":"stream","name":"stdout","text":["episode: 544   score: 2.0   memory length: 100009   epsilon: 0.9999802000000004    steps: 199    lr: 0.0001     evaluation reward: 1.56\n","episode: 545   score: 2.0   memory length: 100208   epsilon: 0.999586180000009    steps: 199    lr: 0.0001     evaluation reward: 1.57\n","episode: 546   score: 0.0   memory length: 100332   epsilon: 0.9993406600000143    steps: 124    lr: 0.0001     evaluation reward: 1.55\n","episode: 547   score: 2.0   memory length: 100531   epsilon: 0.9989466400000229    steps: 199    lr: 0.0001     evaluation reward: 1.54\n","episode: 548   score: 1.0   memory length: 100701   epsilon: 0.9986100400000302    steps: 170    lr: 0.0001     evaluation reward: 1.53\n","episode: 549   score: 1.0   memory length: 100852   epsilon: 0.9983110600000367    steps: 151    lr: 0.0001     evaluation reward: 1.5\n","episode: 550   score: 4.0   memory length: 101154   epsilon: 0.9977131000000496    steps: 302    lr: 0.0001     evaluation reward: 1.53\n","episode: 551   score: 2.0   memory length: 101375   epsilon: 0.9972755200000591    steps: 221    lr: 0.0001     evaluation reward: 1.54\n","episode: 552   score: 2.0   memory length: 101594   epsilon: 0.9968419000000686    steps: 219    lr: 0.0001     evaluation reward: 1.54\n","episode: 553   score: 1.0   memory length: 101763   epsilon: 0.9965072800000758    steps: 169    lr: 0.0001     evaluation reward: 1.54\n","episode: 554   score: 2.0   memory length: 101962   epsilon: 0.9961132600000844    steps: 199    lr: 0.0001     evaluation reward: 1.55\n","episode: 555   score: 1.0   memory length: 102131   epsilon: 0.9957786400000916    steps: 169    lr: 0.0001     evaluation reward: 1.55\n","episode: 556   score: 3.0   memory length: 102378   epsilon: 0.9952895800001023    steps: 247    lr: 0.0001     evaluation reward: 1.57\n","episode: 557   score: 0.0   memory length: 102502   epsilon: 0.9950440600001076    steps: 124    lr: 0.0001     evaluation reward: 1.56\n","episode: 558   score: 0.0   memory length: 102626   epsilon: 0.9947985400001129    steps: 124    lr: 0.0001     evaluation reward: 1.55\n","episode: 559   score: 2.0   memory length: 102811   epsilon: 0.9944322400001209    steps: 185    lr: 0.0001     evaluation reward: 1.56\n","episode: 560   score: 4.0   memory length: 103113   epsilon: 0.9938342800001339    steps: 302    lr: 0.0001     evaluation reward: 1.6\n","episode: 561   score: 0.0   memory length: 103236   epsilon: 0.9935907400001391    steps: 123    lr: 0.0001     evaluation reward: 1.6\n","episode: 562   score: 0.0   memory length: 103360   epsilon: 0.9933452200001445    steps: 124    lr: 0.0001     evaluation reward: 1.59\n","episode: 563   score: 1.0   memory length: 103530   epsilon: 0.9930086200001518    steps: 170    lr: 0.0001     evaluation reward: 1.58\n","episode: 564   score: 0.0   memory length: 103653   epsilon: 0.9927650800001571    steps: 123    lr: 0.0001     evaluation reward: 1.56\n","episode: 565   score: 0.0   memory length: 103777   epsilon: 0.9925195600001624    steps: 124    lr: 0.0001     evaluation reward: 1.54\n","episode: 566   score: 2.0   memory length: 103975   epsilon: 0.9921275200001709    steps: 198    lr: 0.0001     evaluation reward: 1.54\n","episode: 567   score: 0.0   memory length: 104098   epsilon: 0.9918839800001762    steps: 123    lr: 0.0001     evaluation reward: 1.52\n","episode: 568   score: 1.0   memory length: 104269   epsilon: 0.9915454000001835    steps: 171    lr: 0.0001     evaluation reward: 1.51\n","episode: 569   score: 3.0   memory length: 104516   epsilon: 0.9910563400001942    steps: 247    lr: 0.0001     evaluation reward: 1.53\n","episode: 570   score: 2.0   memory length: 104715   epsilon: 0.9906623200002027    steps: 199    lr: 0.0001     evaluation reward: 1.54\n","episode: 571   score: 4.0   memory length: 105029   epsilon: 0.9900406000002162    steps: 314    lr: 0.0001     evaluation reward: 1.57\n","episode: 572   score: 1.0   memory length: 105199   epsilon: 0.9897040000002235    steps: 170    lr: 0.0001     evaluation reward: 1.58\n","episode: 573   score: 3.0   memory length: 105446   epsilon: 0.9892149400002341    steps: 247    lr: 0.0001     evaluation reward: 1.6\n","episode: 574   score: 3.0   memory length: 105693   epsilon: 0.9887258800002448    steps: 247    lr: 0.0001     evaluation reward: 1.59\n","episode: 575   score: 1.0   memory length: 105864   epsilon: 0.9883873000002521    steps: 171    lr: 0.0001     evaluation reward: 1.56\n","episode: 576   score: 0.0   memory length: 105988   epsilon: 0.9881417800002574    steps: 124    lr: 0.0001     evaluation reward: 1.55\n","episode: 577   score: 1.0   memory length: 106139   epsilon: 0.9878428000002639    steps: 151    lr: 0.0001     evaluation reward: 1.54\n","episode: 578   score: 1.0   memory length: 106309   epsilon: 0.9875062000002712    steps: 170    lr: 0.0001     evaluation reward: 1.53\n","episode: 579   score: 2.0   memory length: 106507   epsilon: 0.9871141600002797    steps: 198    lr: 0.0001     evaluation reward: 1.53\n","episode: 580   score: 1.0   memory length: 106679   epsilon: 0.9867736000002871    steps: 172    lr: 0.0001     evaluation reward: 1.53\n","episode: 581   score: 2.0   memory length: 106897   epsilon: 0.9863419600002965    steps: 218    lr: 0.0001     evaluation reward: 1.54\n","episode: 582   score: 1.0   memory length: 107048   epsilon: 0.986042980000303    steps: 151    lr: 0.0001     evaluation reward: 1.53\n","episode: 583   score: 3.0   memory length: 107277   epsilon: 0.9855895600003128    steps: 229    lr: 0.0001     evaluation reward: 1.56\n","episode: 584   score: 1.0   memory length: 107448   epsilon: 0.9852509800003202    steps: 171    lr: 0.0001     evaluation reward: 1.57\n","episode: 585   score: 5.0   memory length: 107755   epsilon: 0.9846431200003334    steps: 307    lr: 0.0001     evaluation reward: 1.6\n","episode: 586   score: 3.0   memory length: 107987   epsilon: 0.9841837600003434    steps: 232    lr: 0.0001     evaluation reward: 1.63\n","episode: 587   score: 4.0   memory length: 108265   epsilon: 0.9836333200003553    steps: 278    lr: 0.0001     evaluation reward: 1.64\n","episode: 588   score: 0.0   memory length: 108389   epsilon: 0.9833878000003606    steps: 124    lr: 0.0001     evaluation reward: 1.63\n","episode: 589   score: 1.0   memory length: 108559   epsilon: 0.9830512000003679    steps: 170    lr: 0.0001     evaluation reward: 1.6\n","episode: 590   score: 0.0   memory length: 108683   epsilon: 0.9828056800003733    steps: 124    lr: 0.0001     evaluation reward: 1.59\n","episode: 591   score: 1.0   memory length: 108835   epsilon: 0.9825047200003798    steps: 152    lr: 0.0001     evaluation reward: 1.6\n","episode: 592   score: 2.0   memory length: 109054   epsilon: 0.9820711000003892    steps: 219    lr: 0.0001     evaluation reward: 1.6\n","episode: 593   score: 2.0   memory length: 109253   epsilon: 0.9816770800003978    steps: 199    lr: 0.0001     evaluation reward: 1.62\n","episode: 594   score: 2.0   memory length: 109451   epsilon: 0.9812850400004063    steps: 198    lr: 0.0001     evaluation reward: 1.63\n","episode: 595   score: 3.0   memory length: 109699   epsilon: 0.9807940000004169    steps: 248    lr: 0.0001     evaluation reward: 1.66\n","episode: 596   score: 0.0   memory length: 109823   epsilon: 0.9805484800004223    steps: 124    lr: 0.0001     evaluation reward: 1.6\n","episode: 597   score: 1.0   memory length: 109993   epsilon: 0.9802118800004296    steps: 170    lr: 0.0001     evaluation reward: 1.59\n","episode: 598   score: 2.0   memory length: 110192   epsilon: 0.9798178600004381    steps: 199    lr: 0.0001     evaluation reward: 1.61\n","episode: 599   score: 3.0   memory length: 110458   epsilon: 0.9792911800004496    steps: 266    lr: 0.0001     evaluation reward: 1.64\n","episode: 600   score: 1.0   memory length: 110611   epsilon: 0.9789882400004561    steps: 153    lr: 0.0001     evaluation reward: 1.62\n","episode: 601   score: 2.0   memory length: 110809   epsilon: 0.9785962000004647    steps: 198    lr: 0.0001     evaluation reward: 1.63\n","episode: 602   score: 3.0   memory length: 111078   epsilon: 0.9780635800004762    steps: 269    lr: 0.0001     evaluation reward: 1.65\n","episode: 603   score: 1.0   memory length: 111250   epsilon: 0.9777230200004836    steps: 172    lr: 0.0001     evaluation reward: 1.64\n","episode: 604   score: 1.0   memory length: 111419   epsilon: 0.9773884000004909    steps: 169    lr: 0.0001     evaluation reward: 1.64\n","episode: 605   score: 2.0   memory length: 111618   epsilon: 0.9769943800004994    steps: 199    lr: 0.0001     evaluation reward: 1.66\n","episode: 606   score: 2.0   memory length: 111836   epsilon: 0.9765627400005088    steps: 218    lr: 0.0001     evaluation reward: 1.66\n","episode: 607   score: 0.0   memory length: 111959   epsilon: 0.9763192000005141    steps: 123    lr: 0.0001     evaluation reward: 1.66\n","episode: 608   score: 2.0   memory length: 112175   epsilon: 0.9758915200005234    steps: 216    lr: 0.0001     evaluation reward: 1.68\n","episode: 609   score: 4.0   memory length: 112454   epsilon: 0.9753391000005354    steps: 279    lr: 0.0001     evaluation reward: 1.7\n","episode: 610   score: 4.0   memory length: 112711   epsilon: 0.9748302400005464    steps: 257    lr: 0.0001     evaluation reward: 1.73\n","episode: 611   score: 1.0   memory length: 112882   epsilon: 0.9744916600005538    steps: 171    lr: 0.0001     evaluation reward: 1.7\n","episode: 612   score: 2.0   memory length: 113083   epsilon: 0.9740936800005624    steps: 201    lr: 0.0001     evaluation reward: 1.72\n","episode: 613   score: 0.0   memory length: 113206   epsilon: 0.9738501400005677    steps: 123    lr: 0.0001     evaluation reward: 1.71\n","episode: 614   score: 0.0   memory length: 113330   epsilon: 0.973604620000573    steps: 124    lr: 0.0001     evaluation reward: 1.71\n","episode: 615   score: 0.0   memory length: 113453   epsilon: 0.9733610800005783    steps: 123    lr: 0.0001     evaluation reward: 1.71\n","episode: 616   score: 1.0   memory length: 113604   epsilon: 0.9730621000005848    steps: 151    lr: 0.0001     evaluation reward: 1.72\n","episode: 617   score: 1.0   memory length: 113756   epsilon: 0.9727611400005913    steps: 152    lr: 0.0001     evaluation reward: 1.69\n","episode: 618   score: 0.0   memory length: 113879   epsilon: 0.9725176000005966    steps: 123    lr: 0.0001     evaluation reward: 1.64\n","episode: 619   score: 2.0   memory length: 114098   epsilon: 0.972083980000606    steps: 219    lr: 0.0001     evaluation reward: 1.63\n","episode: 620   score: 0.0   memory length: 114222   epsilon: 0.9718384600006114    steps: 124    lr: 0.0001     evaluation reward: 1.63\n","episode: 621   score: 7.0   memory length: 114649   epsilon: 0.9709930000006297    steps: 427    lr: 0.0001     evaluation reward: 1.69\n","episode: 622   score: 0.0   memory length: 114773   epsilon: 0.970747480000635    steps: 124    lr: 0.0001     evaluation reward: 1.67\n","episode: 623   score: 0.0   memory length: 114897   epsilon: 0.9705019600006404    steps: 124    lr: 0.0001     evaluation reward: 1.66\n","episode: 624   score: 0.0   memory length: 115021   epsilon: 0.9702564400006457    steps: 124    lr: 0.0001     evaluation reward: 1.62\n","episode: 625   score: 3.0   memory length: 115233   epsilon: 0.9698366800006548    steps: 212    lr: 0.0001     evaluation reward: 1.65\n","episode: 626   score: 2.0   memory length: 115450   epsilon: 0.9694070200006641    steps: 217    lr: 0.0001     evaluation reward: 1.66\n","episode: 627   score: 2.0   memory length: 115648   epsilon: 0.9690149800006727    steps: 198    lr: 0.0001     evaluation reward: 1.68\n","episode: 628   score: 0.0   memory length: 115772   epsilon: 0.968769460000678    steps: 124    lr: 0.0001     evaluation reward: 1.65\n","episode: 629   score: 2.0   memory length: 115971   epsilon: 0.9683754400006865    steps: 199    lr: 0.0001     evaluation reward: 1.66\n","episode: 630   score: 1.0   memory length: 116123   epsilon: 0.9680744800006931    steps: 152    lr: 0.0001     evaluation reward: 1.66\n","episode: 631   score: 5.0   memory length: 116427   epsilon: 0.9674725600007061    steps: 304    lr: 0.0001     evaluation reward: 1.71\n","episode: 632   score: 1.0   memory length: 116598   epsilon: 0.9671339800007135    steps: 171    lr: 0.0001     evaluation reward: 1.68\n","episode: 633   score: 1.0   memory length: 116770   epsilon: 0.9667934200007209    steps: 172    lr: 0.0001     evaluation reward: 1.69\n","episode: 634   score: 2.0   memory length: 116986   epsilon: 0.9663657400007302    steps: 216    lr: 0.0001     evaluation reward: 1.68\n","episode: 635   score: 4.0   memory length: 117275   epsilon: 0.9657935200007426    steps: 289    lr: 0.0001     evaluation reward: 1.72\n","episode: 636   score: 2.0   memory length: 117474   epsilon: 0.9653995000007511    steps: 199    lr: 0.0001     evaluation reward: 1.69\n","episode: 637   score: 1.0   memory length: 117647   epsilon: 0.9650569600007586    steps: 173    lr: 0.0001     evaluation reward: 1.68\n","episode: 638   score: 2.0   memory length: 117847   epsilon: 0.9646609600007672    steps: 200    lr: 0.0001     evaluation reward: 1.66\n","episode: 639   score: 4.0   memory length: 118120   epsilon: 0.9641204200007789    steps: 273    lr: 0.0001     evaluation reward: 1.65\n","episode: 640   score: 0.0   memory length: 118244   epsilon: 0.9638749000007842    steps: 124    lr: 0.0001     evaluation reward: 1.63\n","episode: 641   score: 2.0   memory length: 118464   epsilon: 0.9634393000007937    steps: 220    lr: 0.0001     evaluation reward: 1.63\n","episode: 642   score: 1.0   memory length: 118615   epsilon: 0.9631403200008002    steps: 151    lr: 0.0001     evaluation reward: 1.63\n","episode: 643   score: 4.0   memory length: 118892   epsilon: 0.9625918600008121    steps: 277    lr: 0.0001     evaluation reward: 1.66\n","episode: 644   score: 2.0   memory length: 119073   epsilon: 0.9622334800008199    steps: 181    lr: 0.0001     evaluation reward: 1.66\n","episode: 645   score: 2.0   memory length: 119296   epsilon: 0.9617919400008295    steps: 223    lr: 0.0001     evaluation reward: 1.66\n","episode: 646   score: 2.0   memory length: 119495   epsilon: 0.961397920000838    steps: 199    lr: 0.0001     evaluation reward: 1.68\n","episode: 647   score: 0.0   memory length: 119619   epsilon: 0.9611524000008433    steps: 124    lr: 0.0001     evaluation reward: 1.66\n","episode: 648   score: 2.0   memory length: 119818   epsilon: 0.9607583800008519    steps: 199    lr: 0.0001     evaluation reward: 1.67\n","episode: 649   score: 0.0   memory length: 119942   epsilon: 0.9605128600008572    steps: 124    lr: 0.0001     evaluation reward: 1.66\n","episode: 650   score: 2.0   memory length: 120144   epsilon: 0.9601129000008659    steps: 202    lr: 0.0001     evaluation reward: 1.64\n","episode: 651   score: 2.0   memory length: 120361   epsilon: 0.9596832400008752    steps: 217    lr: 0.0001     evaluation reward: 1.64\n","episode: 652   score: 4.0   memory length: 120657   epsilon: 0.959097160000888    steps: 296    lr: 0.0001     evaluation reward: 1.66\n","episode: 653   score: 0.0   memory length: 120780   epsilon: 0.9588536200008932    steps: 123    lr: 0.0001     evaluation reward: 1.65\n","episode: 654   score: 3.0   memory length: 120994   epsilon: 0.9584299000009024    steps: 214    lr: 0.0001     evaluation reward: 1.66\n","episode: 655   score: 4.0   memory length: 121291   epsilon: 0.9578418400009152    steps: 297    lr: 0.0001     evaluation reward: 1.69\n","episode: 656   score: 2.0   memory length: 121511   epsilon: 0.9574062400009247    steps: 220    lr: 0.0001     evaluation reward: 1.68\n","episode: 657   score: 1.0   memory length: 121663   epsilon: 0.9571052800009312    steps: 152    lr: 0.0001     evaluation reward: 1.69\n","episode: 658   score: 0.0   memory length: 121786   epsilon: 0.9568617400009365    steps: 123    lr: 0.0001     evaluation reward: 1.69\n","episode: 659   score: 0.0   memory length: 121909   epsilon: 0.9566182000009418    steps: 123    lr: 0.0001     evaluation reward: 1.67\n","episode: 660   score: 7.0   memory length: 122288   epsilon: 0.9558677800009581    steps: 379    lr: 0.0001     evaluation reward: 1.7\n","episode: 661   score: 2.0   memory length: 122490   epsilon: 0.9554678200009667    steps: 202    lr: 0.0001     evaluation reward: 1.72\n","episode: 662   score: 2.0   memory length: 122673   epsilon: 0.9551054800009746    steps: 183    lr: 0.0001     evaluation reward: 1.74\n","episode: 663   score: 1.0   memory length: 122825   epsilon: 0.9548045200009811    steps: 152    lr: 0.0001     evaluation reward: 1.74\n","episode: 664   score: 3.0   memory length: 123054   epsilon: 0.954351100000991    steps: 229    lr: 0.0001     evaluation reward: 1.77\n","episode: 665   score: 3.0   memory length: 123326   epsilon: 0.9538125400010027    steps: 272    lr: 0.0001     evaluation reward: 1.8\n","episode: 666   score: 1.0   memory length: 123495   epsilon: 0.95347792000101    steps: 169    lr: 0.0001     evaluation reward: 1.79\n","episode: 667   score: 0.0   memory length: 123619   epsilon: 0.9532324000010153    steps: 124    lr: 0.0001     evaluation reward: 1.79\n","episode: 668   score: 2.0   memory length: 123818   epsilon: 0.9528383800010238    steps: 199    lr: 0.0001     evaluation reward: 1.8\n","episode: 669   score: 4.0   memory length: 124133   epsilon: 0.9522146800010374    steps: 315    lr: 0.0001     evaluation reward: 1.81\n","episode: 670   score: 1.0   memory length: 124303   epsilon: 0.9518780800010447    steps: 170    lr: 0.0001     evaluation reward: 1.8\n","episode: 671   score: 2.0   memory length: 124526   epsilon: 0.9514365400010543    steps: 223    lr: 0.0001     evaluation reward: 1.78\n","episode: 672   score: 0.0   memory length: 124650   epsilon: 0.9511910200010596    steps: 124    lr: 0.0001     evaluation reward: 1.77\n","episode: 673   score: 1.0   memory length: 124819   epsilon: 0.9508564000010669    steps: 169    lr: 0.0001     evaluation reward: 1.75\n","episode: 674   score: 2.0   memory length: 125038   epsilon: 0.9504227800010763    steps: 219    lr: 0.0001     evaluation reward: 1.74\n","episode: 675   score: 1.0   memory length: 125210   epsilon: 0.9500822200010837    steps: 172    lr: 0.0001     evaluation reward: 1.74\n","episode: 676   score: 2.0   memory length: 125409   epsilon: 0.9496882000010922    steps: 199    lr: 0.0001     evaluation reward: 1.76\n","episode: 677   score: 2.0   memory length: 125608   epsilon: 0.9492941800011008    steps: 199    lr: 0.0001     evaluation reward: 1.77\n","episode: 678   score: 1.0   memory length: 125777   epsilon: 0.948959560001108    steps: 169    lr: 0.0001     evaluation reward: 1.77\n","episode: 679   score: 4.0   memory length: 126073   epsilon: 0.9483734800011208    steps: 296    lr: 0.0001     evaluation reward: 1.79\n","episode: 680   score: 0.0   memory length: 126196   epsilon: 0.948129940001126    steps: 123    lr: 0.0001     evaluation reward: 1.78\n","episode: 681   score: 2.0   memory length: 126395   epsilon: 0.9477359200011346    steps: 199    lr: 0.0001     evaluation reward: 1.78\n","episode: 682   score: 3.0   memory length: 126663   epsilon: 0.9472052800011461    steps: 268    lr: 0.0001     evaluation reward: 1.8\n","episode: 683   score: 1.0   memory length: 126833   epsilon: 0.9468686800011534    steps: 170    lr: 0.0001     evaluation reward: 1.78\n","episode: 684   score: 2.0   memory length: 127035   epsilon: 0.9464687200011621    steps: 202    lr: 0.0001     evaluation reward: 1.79\n","episode: 685   score: 1.0   memory length: 127187   epsilon: 0.9461677600011686    steps: 152    lr: 0.0001     evaluation reward: 1.75\n","episode: 686   score: 2.0   memory length: 127385   epsilon: 0.9457757200011772    steps: 198    lr: 0.0001     evaluation reward: 1.74\n","episode: 687   score: 4.0   memory length: 127685   epsilon: 0.94518172000119    steps: 300    lr: 0.0001     evaluation reward: 1.74\n","episode: 688   score: 2.0   memory length: 127904   epsilon: 0.9447481000011995    steps: 219    lr: 0.0001     evaluation reward: 1.76\n","episode: 689   score: 1.0   memory length: 128073   epsilon: 0.9444134800012067    steps: 169    lr: 0.0001     evaluation reward: 1.76\n","episode: 690   score: 3.0   memory length: 128323   epsilon: 0.9439184800012175    steps: 250    lr: 0.0001     evaluation reward: 1.79\n","episode: 691   score: 1.0   memory length: 128495   epsilon: 0.9435779200012249    steps: 172    lr: 0.0001     evaluation reward: 1.79\n","episode: 692   score: 3.0   memory length: 128746   epsilon: 0.9430809400012357    steps: 251    lr: 0.0001     evaluation reward: 1.8\n","episode: 693   score: 5.0   memory length: 129073   epsilon: 0.9424334800012497    steps: 327    lr: 0.0001     evaluation reward: 1.83\n","episode: 694   score: 2.0   memory length: 129274   epsilon: 0.9420355000012584    steps: 201    lr: 0.0001     evaluation reward: 1.83\n","episode: 695   score: 1.0   memory length: 129426   epsilon: 0.9417345400012649    steps: 152    lr: 0.0001     evaluation reward: 1.81\n","episode: 696   score: 1.0   memory length: 129599   epsilon: 0.9413920000012723    steps: 173    lr: 0.0001     evaluation reward: 1.82\n","episode: 697   score: 2.0   memory length: 129797   epsilon: 0.9409999600012808    steps: 198    lr: 0.0001     evaluation reward: 1.83\n","episode: 698   score: 0.0   memory length: 129920   epsilon: 0.9407564200012861    steps: 123    lr: 0.0001     evaluation reward: 1.81\n","episode: 699   score: 2.0   memory length: 130119   epsilon: 0.9403624000012947    steps: 199    lr: 0.0001     evaluation reward: 1.8\n","episode: 700   score: 0.0   memory length: 130243   epsilon: 0.9401168800013    steps: 124    lr: 0.0001     evaluation reward: 1.79\n","episode: 701   score: 1.0   memory length: 130413   epsilon: 0.9397802800013073    steps: 170    lr: 0.0001     evaluation reward: 1.78\n","episode: 702   score: 2.0   memory length: 130612   epsilon: 0.9393862600013159    steps: 199    lr: 0.0001     evaluation reward: 1.77\n","episode: 703   score: 1.0   memory length: 130763   epsilon: 0.9390872800013224    steps: 151    lr: 0.0001     evaluation reward: 1.77\n","episode: 704   score: 0.0   memory length: 130887   epsilon: 0.9388417600013277    steps: 124    lr: 0.0001     evaluation reward: 1.76\n","episode: 705   score: 2.0   memory length: 131087   epsilon: 0.9384457600013363    steps: 200    lr: 0.0001     evaluation reward: 1.76\n","episode: 706   score: 1.0   memory length: 131239   epsilon: 0.9381448000013428    steps: 152    lr: 0.0001     evaluation reward: 1.75\n","episode: 707   score: 0.0   memory length: 131362   epsilon: 0.9379012600013481    steps: 123    lr: 0.0001     evaluation reward: 1.75\n","episode: 708   score: 0.0   memory length: 131486   epsilon: 0.9376557400013534    steps: 124    lr: 0.0001     evaluation reward: 1.73\n","episode: 709   score: 0.0   memory length: 131610   epsilon: 0.9374102200013588    steps: 124    lr: 0.0001     evaluation reward: 1.69\n","episode: 710   score: 3.0   memory length: 131840   epsilon: 0.9369548200013686    steps: 230    lr: 0.0001     evaluation reward: 1.68\n","episode: 711   score: 1.0   memory length: 132009   epsilon: 0.9366202000013759    steps: 169    lr: 0.0001     evaluation reward: 1.68\n","episode: 712   score: 1.0   memory length: 132161   epsilon: 0.9363192400013824    steps: 152    lr: 0.0001     evaluation reward: 1.67\n","episode: 713   score: 1.0   memory length: 132331   epsilon: 0.9359826400013898    steps: 170    lr: 0.0001     evaluation reward: 1.68\n","episode: 714   score: 0.0   memory length: 132455   epsilon: 0.9357371200013951    steps: 124    lr: 0.0001     evaluation reward: 1.68\n","episode: 715   score: 2.0   memory length: 132654   epsilon: 0.9353431000014036    steps: 199    lr: 0.0001     evaluation reward: 1.7\n","episode: 716   score: 1.0   memory length: 132823   epsilon: 0.9350084800014109    steps: 169    lr: 0.0001     evaluation reward: 1.7\n","episode: 717   score: 1.0   memory length: 132994   epsilon: 0.9346699000014183    steps: 171    lr: 0.0001     evaluation reward: 1.7\n","episode: 718   score: 0.0   memory length: 133118   epsilon: 0.9344243800014236    steps: 124    lr: 0.0001     evaluation reward: 1.7\n","episode: 719   score: 0.0   memory length: 133242   epsilon: 0.9341788600014289    steps: 124    lr: 0.0001     evaluation reward: 1.68\n","episode: 720   score: 0.0   memory length: 133366   epsilon: 0.9339333400014342    steps: 124    lr: 0.0001     evaluation reward: 1.68\n","episode: 721   score: 3.0   memory length: 133594   epsilon: 0.933481900001444    steps: 228    lr: 0.0001     evaluation reward: 1.64\n","episode: 722   score: 3.0   memory length: 133857   epsilon: 0.9329611600014553    steps: 263    lr: 0.0001     evaluation reward: 1.67\n","episode: 723   score: 0.0   memory length: 133981   epsilon: 0.9327156400014607    steps: 124    lr: 0.0001     evaluation reward: 1.67\n","episode: 724   score: 2.0   memory length: 134179   epsilon: 0.9323236000014692    steps: 198    lr: 0.0001     evaluation reward: 1.69\n","episode: 725   score: 3.0   memory length: 134427   epsilon: 0.9318325600014798    steps: 248    lr: 0.0001     evaluation reward: 1.69\n","episode: 726   score: 0.0   memory length: 134551   epsilon: 0.9315870400014852    steps: 124    lr: 0.0001     evaluation reward: 1.67\n","episode: 727   score: 3.0   memory length: 134778   epsilon: 0.9311375800014949    steps: 227    lr: 0.0001     evaluation reward: 1.68\n","episode: 728   score: 0.0   memory length: 134902   epsilon: 0.9308920600015003    steps: 124    lr: 0.0001     evaluation reward: 1.68\n","episode: 729   score: 0.0   memory length: 135025   epsilon: 0.9306485200015056    steps: 123    lr: 0.0001     evaluation reward: 1.66\n","episode: 730   score: 0.0   memory length: 135149   epsilon: 0.9304030000015109    steps: 124    lr: 0.0001     evaluation reward: 1.65\n","episode: 731   score: 0.0   memory length: 135273   epsilon: 0.9301574800015162    steps: 124    lr: 0.0001     evaluation reward: 1.6\n","episode: 732   score: 1.0   memory length: 135425   epsilon: 0.9298565200015227    steps: 152    lr: 0.0001     evaluation reward: 1.6\n","episode: 733   score: 2.0   memory length: 135624   epsilon: 0.9294625000015313    steps: 199    lr: 0.0001     evaluation reward: 1.61\n","episode: 734   score: 2.0   memory length: 135826   epsilon: 0.92906254000154    steps: 202    lr: 0.0001     evaluation reward: 1.61\n","episode: 735   score: 2.0   memory length: 136043   epsilon: 0.9286328800015493    steps: 217    lr: 0.0001     evaluation reward: 1.59\n","episode: 736   score: 2.0   memory length: 136242   epsilon: 0.9282388600015579    steps: 199    lr: 0.0001     evaluation reward: 1.59\n","episode: 737   score: 1.0   memory length: 136394   epsilon: 0.9279379000015644    steps: 152    lr: 0.0001     evaluation reward: 1.59\n","episode: 738   score: 2.0   memory length: 136595   epsilon: 0.927539920001573    steps: 201    lr: 0.0001     evaluation reward: 1.59\n","episode: 739   score: 0.0   memory length: 136719   epsilon: 0.9272944000015784    steps: 124    lr: 0.0001     evaluation reward: 1.55\n","episode: 740   score: 1.0   memory length: 136889   epsilon: 0.9269578000015857    steps: 170    lr: 0.0001     evaluation reward: 1.56\n","episode: 741   score: 4.0   memory length: 137187   epsilon: 0.9263677600015985    steps: 298    lr: 0.0001     evaluation reward: 1.58\n","episode: 742   score: 0.0   memory length: 137311   epsilon: 0.9261222400016038    steps: 124    lr: 0.0001     evaluation reward: 1.57\n","episode: 743   score: 2.0   memory length: 137530   epsilon: 0.9256886200016132    steps: 219    lr: 0.0001     evaluation reward: 1.55\n","episode: 744   score: 0.0   memory length: 137654   epsilon: 0.9254431000016186    steps: 124    lr: 0.0001     evaluation reward: 1.53\n","episode: 745   score: 1.0   memory length: 137824   epsilon: 0.9251065000016259    steps: 170    lr: 0.0001     evaluation reward: 1.52\n","episode: 746   score: 0.0   memory length: 137948   epsilon: 0.9248609800016312    steps: 124    lr: 0.0001     evaluation reward: 1.5\n","episode: 747   score: 2.0   memory length: 138146   epsilon: 0.9244689400016397    steps: 198    lr: 0.0001     evaluation reward: 1.52\n","episode: 748   score: 0.0   memory length: 138270   epsilon: 0.924223420001645    steps: 124    lr: 0.0001     evaluation reward: 1.5\n","episode: 749   score: 2.0   memory length: 138470   epsilon: 0.9238274200016536    steps: 200    lr: 0.0001     evaluation reward: 1.52\n","episode: 750   score: 5.0   memory length: 138834   epsilon: 0.9231067000016693    steps: 364    lr: 0.0001     evaluation reward: 1.55\n","episode: 751   score: 0.0   memory length: 138958   epsilon: 0.9228611800016746    steps: 124    lr: 0.0001     evaluation reward: 1.53\n","episode: 752   score: 0.0   memory length: 139081   epsilon: 0.9226176400016799    steps: 123    lr: 0.0001     evaluation reward: 1.49\n","episode: 753   score: 1.0   memory length: 139233   epsilon: 0.9223166800016864    steps: 152    lr: 0.0001     evaluation reward: 1.5\n","episode: 754   score: 1.0   memory length: 139402   epsilon: 0.9219820600016937    steps: 169    lr: 0.0001     evaluation reward: 1.48\n","episode: 755   score: 1.0   memory length: 139572   epsilon: 0.921645460001701    steps: 170    lr: 0.0001     evaluation reward: 1.45\n","episode: 756   score: 0.0   memory length: 139695   epsilon: 0.9214019200017063    steps: 123    lr: 0.0001     evaluation reward: 1.43\n","episode: 757   score: 2.0   memory length: 139896   epsilon: 0.9210039400017149    steps: 201    lr: 0.0001     evaluation reward: 1.44\n","episode: 758   score: 1.0   memory length: 140069   epsilon: 0.9206614000017224    steps: 173    lr: 0.0001     evaluation reward: 1.45\n","episode: 759   score: 0.0   memory length: 140193   epsilon: 0.9204158800017277    steps: 124    lr: 0.0001     evaluation reward: 1.45\n","episode: 760   score: 0.0   memory length: 140317   epsilon: 0.920170360001733    steps: 124    lr: 0.0001     evaluation reward: 1.38\n","episode: 761   score: 2.0   memory length: 140516   epsilon: 0.9197763400017416    steps: 199    lr: 0.0001     evaluation reward: 1.38\n","episode: 762   score: 2.0   memory length: 140717   epsilon: 0.9193783600017502    steps: 201    lr: 0.0001     evaluation reward: 1.38\n","episode: 763   score: 0.0   memory length: 140841   epsilon: 0.9191328400017555    steps: 124    lr: 0.0001     evaluation reward: 1.37\n","episode: 764   score: 0.0   memory length: 140965   epsilon: 0.9188873200017609    steps: 124    lr: 0.0001     evaluation reward: 1.34\n","episode: 765   score: 1.0   memory length: 141116   epsilon: 0.9185883400017674    steps: 151    lr: 0.0001     evaluation reward: 1.32\n","episode: 766   score: 3.0   memory length: 141363   epsilon: 0.918099280001778    steps: 247    lr: 0.0001     evaluation reward: 1.34\n","episode: 767   score: 1.0   memory length: 141515   epsilon: 0.9177983200017845    steps: 152    lr: 0.0001     evaluation reward: 1.35\n","episode: 768   score: 0.0   memory length: 141638   epsilon: 0.9175547800017898    steps: 123    lr: 0.0001     evaluation reward: 1.33\n","episode: 769   score: 3.0   memory length: 141852   epsilon: 0.917131060001799    steps: 214    lr: 0.0001     evaluation reward: 1.32\n","episode: 770   score: 1.0   memory length: 142022   epsilon: 0.9167944600018063    steps: 170    lr: 0.0001     evaluation reward: 1.32\n","episode: 771   score: 1.0   memory length: 142192   epsilon: 0.9164578600018136    steps: 170    lr: 0.0001     evaluation reward: 1.31\n","episode: 772   score: 4.0   memory length: 142459   epsilon: 0.9159292000018251    steps: 267    lr: 0.0001     evaluation reward: 1.35\n","episode: 773   score: 0.0   memory length: 142583   epsilon: 0.9156836800018304    steps: 124    lr: 0.0001     evaluation reward: 1.34\n","episode: 774   score: 2.0   memory length: 142802   epsilon: 0.9152500600018398    steps: 219    lr: 0.0001     evaluation reward: 1.34\n","episode: 775   score: 0.0   memory length: 142925   epsilon: 0.9150065200018451    steps: 123    lr: 0.0001     evaluation reward: 1.33\n","episode: 776   score: 2.0   memory length: 143144   epsilon: 0.9145729000018545    steps: 219    lr: 0.0001     evaluation reward: 1.33\n","episode: 777   score: 1.0   memory length: 143296   epsilon: 0.9142719400018611    steps: 152    lr: 0.0001     evaluation reward: 1.32\n","episode: 778   score: 3.0   memory length: 143565   epsilon: 0.9137393200018726    steps: 269    lr: 0.0001     evaluation reward: 1.34\n","episode: 779   score: 2.0   memory length: 143784   epsilon: 0.913305700001882    steps: 219    lr: 0.0001     evaluation reward: 1.32\n","episode: 780   score: 0.0   memory length: 143908   epsilon: 0.9130601800018874    steps: 124    lr: 0.0001     evaluation reward: 1.32\n","episode: 781   score: 4.0   memory length: 144169   epsilon: 0.9125434000018986    steps: 261    lr: 0.0001     evaluation reward: 1.34\n","episode: 782   score: 2.0   memory length: 144386   epsilon: 0.9121137400019079    steps: 217    lr: 0.0001     evaluation reward: 1.33\n","episode: 783   score: 0.0   memory length: 144510   epsilon: 0.9118682200019133    steps: 124    lr: 0.0001     evaluation reward: 1.32\n","episode: 784   score: 6.0   memory length: 144881   epsilon: 0.9111336400019292    steps: 371    lr: 0.0001     evaluation reward: 1.36\n","episode: 785   score: 0.0   memory length: 145005   epsilon: 0.9108881200019345    steps: 124    lr: 0.0001     evaluation reward: 1.35\n","episode: 786   score: 1.0   memory length: 145156   epsilon: 0.910589140001941    steps: 151    lr: 0.0001     evaluation reward: 1.34\n","episode: 787   score: 2.0   memory length: 145375   epsilon: 0.9101555200019504    steps: 219    lr: 0.0001     evaluation reward: 1.32\n","episode: 788   score: 2.0   memory length: 145593   epsilon: 0.9097238800019598    steps: 218    lr: 0.0001     evaluation reward: 1.32\n","episode: 789   score: 3.0   memory length: 145820   epsilon: 0.9092744200019696    steps: 227    lr: 0.0001     evaluation reward: 1.34\n","episode: 790   score: 1.0   memory length: 145990   epsilon: 0.9089378200019769    steps: 170    lr: 0.0001     evaluation reward: 1.32\n","episode: 791   score: 0.0   memory length: 146114   epsilon: 0.9086923000019822    steps: 124    lr: 0.0001     evaluation reward: 1.31\n","episode: 792   score: 0.0   memory length: 146238   epsilon: 0.9084467800019875    steps: 124    lr: 0.0001     evaluation reward: 1.28\n","episode: 793   score: 0.0   memory length: 146362   epsilon: 0.9082012600019929    steps: 124    lr: 0.0001     evaluation reward: 1.23\n","episode: 794   score: 2.0   memory length: 146584   epsilon: 0.9077617000020024    steps: 222    lr: 0.0001     evaluation reward: 1.23\n","episode: 795   score: 1.0   memory length: 146736   epsilon: 0.9074607400020089    steps: 152    lr: 0.0001     evaluation reward: 1.23\n","episode: 796   score: 1.0   memory length: 146887   epsilon: 0.9071617600020154    steps: 151    lr: 0.0001     evaluation reward: 1.23\n","episode: 797   score: 3.0   memory length: 147134   epsilon: 0.906672700002026    steps: 247    lr: 0.0001     evaluation reward: 1.24\n","episode: 798   score: 4.0   memory length: 147451   epsilon: 0.9060450400020397    steps: 317    lr: 0.0001     evaluation reward: 1.28\n","episode: 799   score: 1.0   memory length: 147603   epsilon: 0.9057440800020462    steps: 152    lr: 0.0001     evaluation reward: 1.27\n","episode: 800   score: 2.0   memory length: 147802   epsilon: 0.9053500600020548    steps: 199    lr: 0.0001     evaluation reward: 1.29\n","episode: 801   score: 4.0   memory length: 148059   epsilon: 0.9048412000020658    steps: 257    lr: 0.0001     evaluation reward: 1.32\n","episode: 802   score: 1.0   memory length: 148229   epsilon: 0.9045046000020731    steps: 170    lr: 0.0001     evaluation reward: 1.31\n","episode: 803   score: 2.0   memory length: 148427   epsilon: 0.9041125600020816    steps: 198    lr: 0.0001     evaluation reward: 1.32\n","episode: 804   score: 2.0   memory length: 148626   epsilon: 0.9037185400020902    steps: 199    lr: 0.0001     evaluation reward: 1.34\n","episode: 805   score: 3.0   memory length: 148895   epsilon: 0.9031859200021017    steps: 269    lr: 0.0001     evaluation reward: 1.35\n","episode: 806   score: 0.0   memory length: 149018   epsilon: 0.902942380002107    steps: 123    lr: 0.0001     evaluation reward: 1.34\n","episode: 807   score: 0.0   memory length: 149142   epsilon: 0.9026968600021124    steps: 124    lr: 0.0001     evaluation reward: 1.34\n","episode: 808   score: 2.0   memory length: 149340   epsilon: 0.9023048200021209    steps: 198    lr: 0.0001     evaluation reward: 1.36\n","episode: 809   score: 0.0   memory length: 149464   epsilon: 0.9020593000021262    steps: 124    lr: 0.0001     evaluation reward: 1.36\n","episode: 810   score: 3.0   memory length: 149712   epsilon: 0.9015682600021369    steps: 248    lr: 0.0001     evaluation reward: 1.36\n","episode: 811   score: 0.0   memory length: 149836   epsilon: 0.9013227400021422    steps: 124    lr: 0.0001     evaluation reward: 1.35\n","episode: 812   score: 1.0   memory length: 150006   epsilon: 0.9009861400021495    steps: 170    lr: 0.0001     evaluation reward: 1.35\n","episode: 813   score: 0.0   memory length: 150130   epsilon: 0.9007406200021548    steps: 124    lr: 0.0001     evaluation reward: 1.34\n","episode: 814   score: 0.0   memory length: 150254   epsilon: 0.9004951000021602    steps: 124    lr: 0.0001     evaluation reward: 1.34\n","episode: 815   score: 3.0   memory length: 150480   epsilon: 0.9000476200021699    steps: 226    lr: 0.0001     evaluation reward: 1.35\n","episode: 816   score: 3.0   memory length: 150728   epsilon: 0.8995565800021805    steps: 248    lr: 0.0001     evaluation reward: 1.37\n","episode: 817   score: 1.0   memory length: 150900   epsilon: 0.8992160200021879    steps: 172    lr: 0.0001     evaluation reward: 1.37\n","episode: 818   score: 1.0   memory length: 151052   epsilon: 0.8989150600021945    steps: 152    lr: 0.0001     evaluation reward: 1.38\n","episode: 819   score: 2.0   memory length: 151251   epsilon: 0.898521040002203    steps: 199    lr: 0.0001     evaluation reward: 1.4\n","episode: 820   score: 1.0   memory length: 151403   epsilon: 0.8982200800022095    steps: 152    lr: 0.0001     evaluation reward: 1.41\n","episode: 821   score: 1.0   memory length: 151572   epsilon: 0.8978854600022168    steps: 169    lr: 0.0001     evaluation reward: 1.39\n","episode: 822   score: 0.0   memory length: 151695   epsilon: 0.8976419200022221    steps: 123    lr: 0.0001     evaluation reward: 1.36\n","episode: 823   score: 1.0   memory length: 151847   epsilon: 0.8973409600022286    steps: 152    lr: 0.0001     evaluation reward: 1.37\n","episode: 824   score: 1.0   memory length: 152017   epsilon: 0.8970043600022359    steps: 170    lr: 0.0001     evaluation reward: 1.36\n","episode: 825   score: 1.0   memory length: 152170   epsilon: 0.8967014200022425    steps: 153    lr: 0.0001     evaluation reward: 1.34\n","episode: 826   score: 0.0   memory length: 152294   epsilon: 0.8964559000022478    steps: 124    lr: 0.0001     evaluation reward: 1.34\n","episode: 827   score: 0.0   memory length: 152418   epsilon: 0.8962103800022532    steps: 124    lr: 0.0001     evaluation reward: 1.31\n","episode: 828   score: 1.0   memory length: 152569   epsilon: 0.8959114000022597    steps: 151    lr: 0.0001     evaluation reward: 1.32\n","episode: 829   score: 0.0   memory length: 152693   epsilon: 0.895665880002265    steps: 124    lr: 0.0001     evaluation reward: 1.32\n","episode: 830   score: 1.0   memory length: 152865   epsilon: 0.8953253200022724    steps: 172    lr: 0.0001     evaluation reward: 1.33\n","episode: 831   score: 1.0   memory length: 153037   epsilon: 0.8949847600022798    steps: 172    lr: 0.0001     evaluation reward: 1.34\n","episode: 832   score: 3.0   memory length: 153308   epsilon: 0.8944481800022914    steps: 271    lr: 0.0001     evaluation reward: 1.36\n","episode: 833   score: 0.0   memory length: 153432   epsilon: 0.8942026600022968    steps: 124    lr: 0.0001     evaluation reward: 1.34\n","episode: 834   score: 0.0   memory length: 153556   epsilon: 0.8939571400023021    steps: 124    lr: 0.0001     evaluation reward: 1.32\n","episode: 835   score: 0.0   memory length: 153680   epsilon: 0.8937116200023074    steps: 124    lr: 0.0001     evaluation reward: 1.3\n","episode: 836   score: 1.0   memory length: 153849   epsilon: 0.8933770000023147    steps: 169    lr: 0.0001     evaluation reward: 1.29\n","episode: 837   score: 2.0   memory length: 154048   epsilon: 0.8929829800023232    steps: 199    lr: 0.0001     evaluation reward: 1.3\n","episode: 838   score: 2.0   memory length: 154247   epsilon: 0.8925889600023318    steps: 199    lr: 0.0001     evaluation reward: 1.3\n","episode: 839   score: 2.0   memory length: 154447   epsilon: 0.8921929600023404    steps: 200    lr: 0.0001     evaluation reward: 1.32\n","episode: 840   score: 4.0   memory length: 154743   epsilon: 0.8916068800023531    steps: 296    lr: 0.0001     evaluation reward: 1.35\n","episode: 841   score: 2.0   memory length: 154964   epsilon: 0.8911693000023626    steps: 221    lr: 0.0001     evaluation reward: 1.33\n","episode: 842   score: 3.0   memory length: 155211   epsilon: 0.8906802400023732    steps: 247    lr: 0.0001     evaluation reward: 1.36\n","episode: 843   score: 0.0   memory length: 155335   epsilon: 0.8904347200023786    steps: 124    lr: 0.0001     evaluation reward: 1.34\n","episode: 844   score: 2.0   memory length: 155553   epsilon: 0.8900030800023879    steps: 218    lr: 0.0001     evaluation reward: 1.36\n","episode: 845   score: 3.0   memory length: 155780   epsilon: 0.8895536200023977    steps: 227    lr: 0.0001     evaluation reward: 1.38\n","episode: 846   score: 0.0   memory length: 155904   epsilon: 0.889308100002403    steps: 124    lr: 0.0001     evaluation reward: 1.38\n","episode: 847   score: 0.0   memory length: 156028   epsilon: 0.8890625800024083    steps: 124    lr: 0.0001     evaluation reward: 1.36\n","episode: 848   score: 1.0   memory length: 156198   epsilon: 0.8887259800024156    steps: 170    lr: 0.0001     evaluation reward: 1.37\n","episode: 849   score: 1.0   memory length: 156368   epsilon: 0.888389380002423    steps: 170    lr: 0.0001     evaluation reward: 1.36\n","episode: 850   score: 2.0   memory length: 156566   epsilon: 0.8879973400024315    steps: 198    lr: 0.0001     evaluation reward: 1.33\n","episode: 851   score: 3.0   memory length: 156796   epsilon: 0.8875419400024414    steps: 230    lr: 0.0001     evaluation reward: 1.36\n","episode: 852   score: 0.0   memory length: 156920   epsilon: 0.8872964200024467    steps: 124    lr: 0.0001     evaluation reward: 1.36\n","episode: 853   score: 5.0   memory length: 157246   epsilon: 0.8866509400024607    steps: 326    lr: 0.0001     evaluation reward: 1.4\n","episode: 854   score: 2.0   memory length: 157444   epsilon: 0.8862589000024692    steps: 198    lr: 0.0001     evaluation reward: 1.41\n","episode: 855   score: 0.0   memory length: 157568   epsilon: 0.8860133800024745    steps: 124    lr: 0.0001     evaluation reward: 1.4\n","episode: 856   score: 0.0   memory length: 157692   epsilon: 0.8857678600024799    steps: 124    lr: 0.0001     evaluation reward: 1.4\n","episode: 857   score: 2.0   memory length: 157914   epsilon: 0.8853283000024894    steps: 222    lr: 0.0001     evaluation reward: 1.4\n","episode: 858   score: 5.0   memory length: 158243   epsilon: 0.8846768800025036    steps: 329    lr: 0.0001     evaluation reward: 1.44\n","episode: 859   score: 2.0   memory length: 158459   epsilon: 0.8842492000025128    steps: 216    lr: 0.0001     evaluation reward: 1.46\n","episode: 860   score: 3.0   memory length: 158722   epsilon: 0.8837284600025241    steps: 263    lr: 0.0001     evaluation reward: 1.49\n","episode: 861   score: 1.0   memory length: 158874   epsilon: 0.8834275000025307    steps: 152    lr: 0.0001     evaluation reward: 1.48\n","episode: 862   score: 2.0   memory length: 159074   epsilon: 0.8830315000025393    steps: 200    lr: 0.0001     evaluation reward: 1.48\n","episode: 863   score: 1.0   memory length: 159244   epsilon: 0.8826949000025466    steps: 170    lr: 0.0001     evaluation reward: 1.49\n","episode: 864   score: 1.0   memory length: 159414   epsilon: 0.8823583000025539    steps: 170    lr: 0.0001     evaluation reward: 1.5\n","episode: 865   score: 0.0   memory length: 159537   epsilon: 0.8821147600025592    steps: 123    lr: 0.0001     evaluation reward: 1.49\n","episode: 866   score: 3.0   memory length: 159784   epsilon: 0.8816257000025698    steps: 247    lr: 0.0001     evaluation reward: 1.49\n","episode: 867   score: 2.0   memory length: 159983   epsilon: 0.8812316800025783    steps: 199    lr: 0.0001     evaluation reward: 1.5\n","episode: 868   score: 0.0   memory length: 160106   epsilon: 0.8809881400025836    steps: 123    lr: 0.0001     evaluation reward: 1.5\n","episode: 869   score: 2.0   memory length: 160325   epsilon: 0.880554520002593    steps: 219    lr: 0.0001     evaluation reward: 1.49\n","episode: 870   score: 5.0   memory length: 160666   epsilon: 0.8798793400026077    steps: 341    lr: 0.0001     evaluation reward: 1.53\n","episode: 871   score: 1.0   memory length: 160838   epsilon: 0.8795387800026151    steps: 172    lr: 0.0001     evaluation reward: 1.53\n","episode: 872   score: 0.0   memory length: 160962   epsilon: 0.8792932600026204    steps: 124    lr: 0.0001     evaluation reward: 1.49\n","episode: 873   score: 4.0   memory length: 161280   epsilon: 0.8786636200026341    steps: 318    lr: 0.0001     evaluation reward: 1.53\n","episode: 874   score: 4.0   memory length: 161568   epsilon: 0.8780933800026465    steps: 288    lr: 0.0001     evaluation reward: 1.55\n","episode: 875   score: 2.0   memory length: 161768   epsilon: 0.8776973800026551    steps: 200    lr: 0.0001     evaluation reward: 1.57\n","episode: 876   score: 2.0   memory length: 161967   epsilon: 0.8773033600026636    steps: 199    lr: 0.0001     evaluation reward: 1.57\n","episode: 877   score: 1.0   memory length: 162137   epsilon: 0.8769667600026709    steps: 170    lr: 0.0001     evaluation reward: 1.57\n","episode: 878   score: 4.0   memory length: 162413   epsilon: 0.8764202800026828    steps: 276    lr: 0.0001     evaluation reward: 1.58\n","episode: 879   score: 3.0   memory length: 162681   epsilon: 0.8758896400026943    steps: 268    lr: 0.0001     evaluation reward: 1.59\n","episode: 880   score: 1.0   memory length: 162832   epsilon: 0.8755906600027008    steps: 151    lr: 0.0001     evaluation reward: 1.6\n","episode: 881   score: 2.0   memory length: 163031   epsilon: 0.8751966400027094    steps: 199    lr: 0.0001     evaluation reward: 1.58\n","episode: 882   score: 1.0   memory length: 163183   epsilon: 0.8748956800027159    steps: 152    lr: 0.0001     evaluation reward: 1.57\n","episode: 883   score: 2.0   memory length: 163383   epsilon: 0.8744996800027245    steps: 200    lr: 0.0001     evaluation reward: 1.59\n","episode: 884   score: 0.0   memory length: 163506   epsilon: 0.8742561400027298    steps: 123    lr: 0.0001     evaluation reward: 1.53\n","episode: 885   score: 0.0   memory length: 163630   epsilon: 0.8740106200027351    steps: 124    lr: 0.0001     evaluation reward: 1.53\n","episode: 886   score: 2.0   memory length: 163829   epsilon: 0.8736166000027437    steps: 199    lr: 0.0001     evaluation reward: 1.54\n","episode: 887   score: 0.0   memory length: 163953   epsilon: 0.873371080002749    steps: 124    lr: 0.0001     evaluation reward: 1.52\n","episode: 888   score: 0.0   memory length: 164076   epsilon: 0.8731275400027543    steps: 123    lr: 0.0001     evaluation reward: 1.5\n","episode: 889   score: 2.0   memory length: 164294   epsilon: 0.8726959000027636    steps: 218    lr: 0.0001     evaluation reward: 1.49\n","episode: 890   score: 2.0   memory length: 164515   epsilon: 0.8722583200027731    steps: 221    lr: 0.0001     evaluation reward: 1.5\n","episode: 891   score: 1.0   memory length: 164667   epsilon: 0.8719573600027797    steps: 152    lr: 0.0001     evaluation reward: 1.51\n","episode: 892   score: 1.0   memory length: 164837   epsilon: 0.871620760002787    steps: 170    lr: 0.0001     evaluation reward: 1.52\n","episode: 893   score: 2.0   memory length: 165038   epsilon: 0.8712227800027956    steps: 201    lr: 0.0001     evaluation reward: 1.54\n","episode: 894   score: 1.0   memory length: 165211   epsilon: 0.8708802400028031    steps: 173    lr: 0.0001     evaluation reward: 1.53\n","episode: 895   score: 2.0   memory length: 165411   epsilon: 0.8704842400028117    steps: 200    lr: 0.0001     evaluation reward: 1.54\n","episode: 896   score: 1.0   memory length: 165563   epsilon: 0.8701832800028182    steps: 152    lr: 0.0001     evaluation reward: 1.54\n","episode: 897   score: 0.0   memory length: 165687   epsilon: 0.8699377600028235    steps: 124    lr: 0.0001     evaluation reward: 1.51\n","episode: 898   score: 0.0   memory length: 165810   epsilon: 0.8696942200028288    steps: 123    lr: 0.0001     evaluation reward: 1.47\n","episode: 899   score: 0.0   memory length: 165934   epsilon: 0.8694487000028341    steps: 124    lr: 0.0001     evaluation reward: 1.46\n","episode: 900   score: 5.0   memory length: 166269   epsilon: 0.8687854000028485    steps: 335    lr: 0.0001     evaluation reward: 1.49\n","episode: 901   score: 2.0   memory length: 166468   epsilon: 0.8683913800028571    steps: 199    lr: 0.0001     evaluation reward: 1.47\n","episode: 902   score: 3.0   memory length: 166715   epsilon: 0.8679023200028677    steps: 247    lr: 0.0001     evaluation reward: 1.49\n","episode: 903   score: 0.0   memory length: 166839   epsilon: 0.867656800002873    steps: 124    lr: 0.0001     evaluation reward: 1.47\n","episode: 904   score: 0.0   memory length: 166963   epsilon: 0.8674112800028784    steps: 124    lr: 0.0001     evaluation reward: 1.45\n","episode: 905   score: 0.0   memory length: 167086   epsilon: 0.8671677400028837    steps: 123    lr: 0.0001     evaluation reward: 1.42\n","episode: 906   score: 0.0   memory length: 167210   epsilon: 0.866922220002889    steps: 124    lr: 0.0001     evaluation reward: 1.42\n","episode: 907   score: 0.0   memory length: 167334   epsilon: 0.8666767000028943    steps: 124    lr: 0.0001     evaluation reward: 1.42\n","episode: 908   score: 1.0   memory length: 167486   epsilon: 0.8663757400029009    steps: 152    lr: 0.0001     evaluation reward: 1.41\n","episode: 909   score: 1.0   memory length: 167638   epsilon: 0.8660747800029074    steps: 152    lr: 0.0001     evaluation reward: 1.42\n","episode: 910   score: 1.0   memory length: 167809   epsilon: 0.8657362000029147    steps: 171    lr: 0.0001     evaluation reward: 1.4\n","episode: 911   score: 3.0   memory length: 168036   epsilon: 0.8652867400029245    steps: 227    lr: 0.0001     evaluation reward: 1.43\n","episode: 912   score: 1.0   memory length: 168208   epsilon: 0.8649461800029319    steps: 172    lr: 0.0001     evaluation reward: 1.43\n","episode: 913   score: 2.0   memory length: 168406   epsilon: 0.8645541400029404    steps: 198    lr: 0.0001     evaluation reward: 1.45\n","episode: 914   score: 0.0   memory length: 168529   epsilon: 0.8643106000029457    steps: 123    lr: 0.0001     evaluation reward: 1.45\n","episode: 915   score: 2.0   memory length: 168728   epsilon: 0.8639165800029542    steps: 199    lr: 0.0001     evaluation reward: 1.44\n","episode: 916   score: 0.0   memory length: 168852   epsilon: 0.8636710600029596    steps: 124    lr: 0.0001     evaluation reward: 1.41\n","episode: 917   score: 2.0   memory length: 169072   epsilon: 0.863235460002969    steps: 220    lr: 0.0001     evaluation reward: 1.42\n","episode: 918   score: 1.0   memory length: 169224   epsilon: 0.8629345000029756    steps: 152    lr: 0.0001     evaluation reward: 1.42\n","episode: 919   score: 0.0   memory length: 169348   epsilon: 0.8626889800029809    steps: 124    lr: 0.0001     evaluation reward: 1.4\n","episode: 920   score: 0.0   memory length: 169471   epsilon: 0.8624454400029862    steps: 123    lr: 0.0001     evaluation reward: 1.39\n","episode: 921   score: 4.0   memory length: 169764   epsilon: 0.8618653000029988    steps: 293    lr: 0.0001     evaluation reward: 1.42\n","episode: 922   score: 2.0   memory length: 169981   epsilon: 0.8614356400030081    steps: 217    lr: 0.0001     evaluation reward: 1.44\n","episode: 923   score: 0.0   memory length: 170105   epsilon: 0.8611901200030134    steps: 124    lr: 0.0001     evaluation reward: 1.43\n","episode: 924   score: 3.0   memory length: 170352   epsilon: 0.860701060003024    steps: 247    lr: 0.0001     evaluation reward: 1.45\n","episode: 925   score: 4.0   memory length: 170628   epsilon: 0.8601545800030359    steps: 276    lr: 0.0001     evaluation reward: 1.48\n","episode: 926   score: 1.0   memory length: 170797   epsilon: 0.8598199600030432    steps: 169    lr: 0.0001     evaluation reward: 1.49\n","episode: 927   score: 1.0   memory length: 170949   epsilon: 0.8595190000030497    steps: 152    lr: 0.0001     evaluation reward: 1.5\n","episode: 928   score: 2.0   memory length: 171166   epsilon: 0.859089340003059    steps: 217    lr: 0.0001     evaluation reward: 1.51\n","episode: 929   score: 3.0   memory length: 171413   epsilon: 0.8586002800030696    steps: 247    lr: 0.0001     evaluation reward: 1.54\n","episode: 930   score: 2.0   memory length: 171612   epsilon: 0.8582062600030782    steps: 199    lr: 0.0001     evaluation reward: 1.55\n","episode: 931   score: 0.0   memory length: 171736   epsilon: 0.8579607400030835    steps: 124    lr: 0.0001     evaluation reward: 1.54\n","episode: 932   score: 2.0   memory length: 171954   epsilon: 0.8575291000030929    steps: 218    lr: 0.0001     evaluation reward: 1.53\n","episode: 933   score: 0.0   memory length: 172078   epsilon: 0.8572835800030982    steps: 124    lr: 0.0001     evaluation reward: 1.53\n","episode: 934   score: 1.0   memory length: 172248   epsilon: 0.8569469800031055    steps: 170    lr: 0.0001     evaluation reward: 1.54\n","episode: 935   score: 4.0   memory length: 172566   epsilon: 0.8563173400031192    steps: 318    lr: 0.0001     evaluation reward: 1.58\n","episode: 936   score: 1.0   memory length: 172736   epsilon: 0.8559807400031265    steps: 170    lr: 0.0001     evaluation reward: 1.58\n","episode: 937   score: 2.0   memory length: 172935   epsilon: 0.8555867200031351    steps: 199    lr: 0.0001     evaluation reward: 1.58\n","episode: 938   score: 3.0   memory length: 173183   epsilon: 0.8550956800031457    steps: 248    lr: 0.0001     evaluation reward: 1.59\n","episode: 939   score: 2.0   memory length: 173402   epsilon: 0.8546620600031551    steps: 219    lr: 0.0001     evaluation reward: 1.59\n","episode: 940   score: 2.0   memory length: 173601   epsilon: 0.8542680400031637    steps: 199    lr: 0.0001     evaluation reward: 1.57\n","episode: 941   score: 4.0   memory length: 173896   epsilon: 0.8536839400031764    steps: 295    lr: 0.0001     evaluation reward: 1.59\n","episode: 942   score: 0.0   memory length: 174020   epsilon: 0.8534384200031817    steps: 124    lr: 0.0001     evaluation reward: 1.56\n","episode: 943   score: 4.0   memory length: 174338   epsilon: 0.8528087800031954    steps: 318    lr: 0.0001     evaluation reward: 1.6\n","episode: 944   score: 2.0   memory length: 174560   epsilon: 0.8523692200032049    steps: 222    lr: 0.0001     evaluation reward: 1.6\n","episode: 945   score: 1.0   memory length: 174730   epsilon: 0.8520326200032122    steps: 170    lr: 0.0001     evaluation reward: 1.58\n","episode: 946   score: 2.0   memory length: 174913   epsilon: 0.8516702800032201    steps: 183    lr: 0.0001     evaluation reward: 1.6\n","episode: 947   score: 2.0   memory length: 175112   epsilon: 0.8512762600032286    steps: 199    lr: 0.0001     evaluation reward: 1.62\n","episode: 948   score: 5.0   memory length: 175457   epsilon: 0.8505931600032435    steps: 345    lr: 0.0001     evaluation reward: 1.66\n","episode: 949   score: 3.0   memory length: 175704   epsilon: 0.8501041000032541    steps: 247    lr: 0.0001     evaluation reward: 1.68\n","episode: 950   score: 0.0   memory length: 175828   epsilon: 0.8498585800032594    steps: 124    lr: 0.0001     evaluation reward: 1.66\n","episode: 951   score: 2.0   memory length: 176027   epsilon: 0.849464560003268    steps: 199    lr: 0.0001     evaluation reward: 1.65\n","episode: 952   score: 1.0   memory length: 176198   epsilon: 0.8491259800032753    steps: 171    lr: 0.0001     evaluation reward: 1.66\n","episode: 953   score: 0.0   memory length: 176321   epsilon: 0.8488824400032806    steps: 123    lr: 0.0001     evaluation reward: 1.61\n","episode: 954   score: 2.0   memory length: 176540   epsilon: 0.84844882000329    steps: 219    lr: 0.0001     evaluation reward: 1.61\n","episode: 955   score: 2.0   memory length: 176760   epsilon: 0.8480132200032995    steps: 220    lr: 0.0001     evaluation reward: 1.63\n","episode: 956   score: 3.0   memory length: 176994   epsilon: 0.8475499000033095    steps: 234    lr: 0.0001     evaluation reward: 1.66\n","episode: 957   score: 2.0   memory length: 177194   epsilon: 0.8471539000033181    steps: 200    lr: 0.0001     evaluation reward: 1.66\n","episode: 958   score: 2.0   memory length: 177393   epsilon: 0.8467598800033267    steps: 199    lr: 0.0001     evaluation reward: 1.63\n","episode: 959   score: 2.0   memory length: 177613   epsilon: 0.8463242800033361    steps: 220    lr: 0.0001     evaluation reward: 1.63\n","episode: 960   score: 2.0   memory length: 177833   epsilon: 0.8458886800033456    steps: 220    lr: 0.0001     evaluation reward: 1.62\n","episode: 961   score: 0.0   memory length: 177957   epsilon: 0.8456431600033509    steps: 124    lr: 0.0001     evaluation reward: 1.61\n","episode: 962   score: 1.0   memory length: 178127   epsilon: 0.8453065600033582    steps: 170    lr: 0.0001     evaluation reward: 1.6\n","episode: 963   score: 2.0   memory length: 178345   epsilon: 0.8448749200033676    steps: 218    lr: 0.0001     evaluation reward: 1.61\n","episode: 964   score: 3.0   memory length: 178613   epsilon: 0.8443442800033791    steps: 268    lr: 0.0001     evaluation reward: 1.63\n","episode: 965   score: 0.0   memory length: 178737   epsilon: 0.8440987600033845    steps: 124    lr: 0.0001     evaluation reward: 1.63\n","episode: 966   score: 0.0   memory length: 178861   epsilon: 0.8438532400033898    steps: 124    lr: 0.0001     evaluation reward: 1.6\n","episode: 967   score: 0.0   memory length: 178985   epsilon: 0.8436077200033951    steps: 124    lr: 0.0001     evaluation reward: 1.58\n","episode: 968   score: 3.0   memory length: 179230   epsilon: 0.8431226200034057    steps: 245    lr: 0.0001     evaluation reward: 1.61\n","episode: 969   score: 1.0   memory length: 179399   epsilon: 0.8427880000034129    steps: 169    lr: 0.0001     evaluation reward: 1.6\n","episode: 970   score: 2.0   memory length: 179580   epsilon: 0.8424296200034207    steps: 181    lr: 0.0001     evaluation reward: 1.57\n","episode: 971   score: 0.0   memory length: 179704   epsilon: 0.842184100003426    steps: 124    lr: 0.0001     evaluation reward: 1.56\n","episode: 972   score: 4.0   memory length: 179998   epsilon: 0.8416019800034387    steps: 294    lr: 0.0001     evaluation reward: 1.6\n","episode: 973   score: 2.0   memory length: 180196   epsilon: 0.8412099400034472    steps: 198    lr: 0.0001     evaluation reward: 1.58\n","episode: 974   score: 1.0   memory length: 180347   epsilon: 0.8409109600034537    steps: 151    lr: 0.0001     evaluation reward: 1.55\n","episode: 975   score: 0.0   memory length: 180470   epsilon: 0.840667420003459    steps: 123    lr: 0.0001     evaluation reward: 1.53\n","episode: 976   score: 2.0   memory length: 180669   epsilon: 0.8402734000034675    steps: 199    lr: 0.0001     evaluation reward: 1.53\n","episode: 977   score: 2.0   memory length: 180867   epsilon: 0.839881360003476    steps: 198    lr: 0.0001     evaluation reward: 1.54\n","episode: 978   score: 2.0   memory length: 181065   epsilon: 0.8394893200034845    steps: 198    lr: 0.0001     evaluation reward: 1.52\n","episode: 979   score: 2.0   memory length: 181264   epsilon: 0.8390953000034931    steps: 199    lr: 0.0001     evaluation reward: 1.51\n","episode: 980   score: 2.0   memory length: 181482   epsilon: 0.8386636600035025    steps: 218    lr: 0.0001     evaluation reward: 1.52\n","episode: 981   score: 5.0   memory length: 181823   epsilon: 0.8379884800035171    steps: 341    lr: 0.0001     evaluation reward: 1.55\n","episode: 982   score: 2.0   memory length: 182021   epsilon: 0.8375964400035256    steps: 198    lr: 0.0001     evaluation reward: 1.56\n","episode: 983   score: 2.0   memory length: 182219   epsilon: 0.8372044000035341    steps: 198    lr: 0.0001     evaluation reward: 1.56\n","episode: 984   score: 2.0   memory length: 182438   epsilon: 0.8367707800035435    steps: 219    lr: 0.0001     evaluation reward: 1.58\n","episode: 985   score: 0.0   memory length: 182562   epsilon: 0.8365252600035489    steps: 124    lr: 0.0001     evaluation reward: 1.58\n","episode: 986   score: 0.0   memory length: 182686   epsilon: 0.8362797400035542    steps: 124    lr: 0.0001     evaluation reward: 1.56\n","episode: 987   score: 1.0   memory length: 182837   epsilon: 0.8359807600035607    steps: 151    lr: 0.0001     evaluation reward: 1.57\n","episode: 988   score: 2.0   memory length: 183057   epsilon: 0.8355451600035702    steps: 220    lr: 0.0001     evaluation reward: 1.59\n","episode: 989   score: 3.0   memory length: 183322   epsilon: 0.8350204600035815    steps: 265    lr: 0.0001     evaluation reward: 1.6\n","episode: 990   score: 2.0   memory length: 183521   epsilon: 0.8346264400035901    steps: 199    lr: 0.0001     evaluation reward: 1.6\n","episode: 991   score: 0.0   memory length: 183644   epsilon: 0.8343829000035954    steps: 123    lr: 0.0001     evaluation reward: 1.59\n","episode: 992   score: 2.0   memory length: 183843   epsilon: 0.8339888800036039    steps: 199    lr: 0.0001     evaluation reward: 1.6\n","episode: 993   score: 2.0   memory length: 184045   epsilon: 0.8335889200036126    steps: 202    lr: 0.0001     evaluation reward: 1.6\n","episode: 994   score: 1.0   memory length: 184197   epsilon: 0.8332879600036192    steps: 152    lr: 0.0001     evaluation reward: 1.6\n","episode: 995   score: 4.0   memory length: 184466   epsilon: 0.8327553400036307    steps: 269    lr: 0.0001     evaluation reward: 1.62\n","episode: 996   score: 0.0   memory length: 184589   epsilon: 0.832511800003636    steps: 123    lr: 0.0001     evaluation reward: 1.61\n","episode: 997   score: 1.0   memory length: 184759   epsilon: 0.8321752000036433    steps: 170    lr: 0.0001     evaluation reward: 1.62\n","episode: 998   score: 1.0   memory length: 184911   epsilon: 0.8318742400036498    steps: 152    lr: 0.0001     evaluation reward: 1.63\n","episode: 999   score: 2.0   memory length: 185113   epsilon: 0.8314742800036585    steps: 202    lr: 0.0001     evaluation reward: 1.65\n","episode: 1000   score: 7.0   memory length: 185544   epsilon: 0.830620900003677    steps: 431    lr: 0.0001     evaluation reward: 1.67\n","episode: 1001   score: 4.0   memory length: 185861   epsilon: 0.8299932400036907    steps: 317    lr: 0.0001     evaluation reward: 1.69\n","episode: 1002   score: 1.0   memory length: 186014   epsilon: 0.8296903000036973    steps: 153    lr: 0.0001     evaluation reward: 1.67\n","episode: 1003   score: 2.0   memory length: 186231   epsilon: 0.8292606400037066    steps: 217    lr: 0.0001     evaluation reward: 1.69\n","episode: 1004   score: 1.0   memory length: 186401   epsilon: 0.8289240400037139    steps: 170    lr: 0.0001     evaluation reward: 1.7\n","episode: 1005   score: 0.0   memory length: 186525   epsilon: 0.8286785200037192    steps: 124    lr: 0.0001     evaluation reward: 1.7\n","episode: 1006   score: 2.0   memory length: 186724   epsilon: 0.8282845000037278    steps: 199    lr: 0.0001     evaluation reward: 1.72\n","episode: 1007   score: 3.0   memory length: 186994   epsilon: 0.8277499000037394    steps: 270    lr: 0.0001     evaluation reward: 1.75\n","episode: 1008   score: 4.0   memory length: 187292   epsilon: 0.8271598600037522    steps: 298    lr: 0.0001     evaluation reward: 1.78\n","episode: 1009   score: 2.0   memory length: 187491   epsilon: 0.8267658400037607    steps: 199    lr: 0.0001     evaluation reward: 1.79\n","episode: 1010   score: 2.0   memory length: 187711   epsilon: 0.8263302400037702    steps: 220    lr: 0.0001     evaluation reward: 1.8\n","episode: 1011   score: 2.0   memory length: 187910   epsilon: 0.8259362200037788    steps: 199    lr: 0.0001     evaluation reward: 1.79\n","episode: 1012   score: 2.0   memory length: 188109   epsilon: 0.8255422000037873    steps: 199    lr: 0.0001     evaluation reward: 1.8\n","episode: 1013   score: 2.0   memory length: 188307   epsilon: 0.8251501600037958    steps: 198    lr: 0.0001     evaluation reward: 1.8\n","episode: 1014   score: 3.0   memory length: 188555   epsilon: 0.8246591200038065    steps: 248    lr: 0.0001     evaluation reward: 1.83\n","episode: 1015   score: 2.0   memory length: 188774   epsilon: 0.8242255000038159    steps: 219    lr: 0.0001     evaluation reward: 1.83\n","episode: 1016   score: 2.0   memory length: 188972   epsilon: 0.8238334600038244    steps: 198    lr: 0.0001     evaluation reward: 1.85\n","episode: 1017   score: 0.0   memory length: 189095   epsilon: 0.8235899200038297    steps: 123    lr: 0.0001     evaluation reward: 1.83\n","episode: 1018   score: 1.0   memory length: 189247   epsilon: 0.8232889600038362    steps: 152    lr: 0.0001     evaluation reward: 1.83\n","episode: 1019   score: 1.0   memory length: 189399   epsilon: 0.8229880000038428    steps: 152    lr: 0.0001     evaluation reward: 1.84\n","episode: 1020   score: 3.0   memory length: 189648   epsilon: 0.8224949800038535    steps: 249    lr: 0.0001     evaluation reward: 1.87\n","episode: 1021   score: 2.0   memory length: 189866   epsilon: 0.8220633400038628    steps: 218    lr: 0.0001     evaluation reward: 1.85\n","episode: 1022   score: 2.0   memory length: 190068   epsilon: 0.8216633800038715    steps: 202    lr: 0.0001     evaluation reward: 1.85\n","episode: 1023   score: 3.0   memory length: 190281   epsilon: 0.8212416400038807    steps: 213    lr: 0.0001     evaluation reward: 1.88\n","episode: 1024   score: 1.0   memory length: 190433   epsilon: 0.8209406800038872    steps: 152    lr: 0.0001     evaluation reward: 1.86\n","episode: 1025   score: 2.0   memory length: 190632   epsilon: 0.8205466600038958    steps: 199    lr: 0.0001     evaluation reward: 1.84\n","episode: 1026   score: 2.0   memory length: 190830   epsilon: 0.8201546200039043    steps: 198    lr: 0.0001     evaluation reward: 1.85\n","episode: 1027   score: 2.0   memory length: 191029   epsilon: 0.8197606000039128    steps: 199    lr: 0.0001     evaluation reward: 1.86\n","episode: 1028   score: 2.0   memory length: 191228   epsilon: 0.8193665800039214    steps: 199    lr: 0.0001     evaluation reward: 1.86\n","episode: 1029   score: 1.0   memory length: 191401   epsilon: 0.8190240400039288    steps: 173    lr: 0.0001     evaluation reward: 1.84\n","episode: 1030   score: 3.0   memory length: 191627   epsilon: 0.8185765600039385    steps: 226    lr: 0.0001     evaluation reward: 1.85\n","episode: 1031   score: 0.0   memory length: 191751   epsilon: 0.8183310400039439    steps: 124    lr: 0.0001     evaluation reward: 1.85\n","episode: 1032   score: 4.0   memory length: 192049   epsilon: 0.8177410000039567    steps: 298    lr: 0.0001     evaluation reward: 1.87\n","episode: 1033   score: 0.0   memory length: 192172   epsilon: 0.817497460003962    steps: 123    lr: 0.0001     evaluation reward: 1.87\n","episode: 1034   score: 2.0   memory length: 192371   epsilon: 0.8171034400039705    steps: 199    lr: 0.0001     evaluation reward: 1.88\n","episode: 1035   score: 5.0   memory length: 192715   epsilon: 0.8164223200039853    steps: 344    lr: 0.0001     evaluation reward: 1.89\n","episode: 1036   score: 1.0   memory length: 192867   epsilon: 0.8161213600039918    steps: 152    lr: 0.0001     evaluation reward: 1.89\n","episode: 1037   score: 1.0   memory length: 193019   epsilon: 0.8158204000039984    steps: 152    lr: 0.0001     evaluation reward: 1.88\n","episode: 1038   score: 2.0   memory length: 193218   epsilon: 0.8154263800040069    steps: 199    lr: 0.0001     evaluation reward: 1.87\n","episode: 1039   score: 0.0   memory length: 193342   epsilon: 0.8151808600040122    steps: 124    lr: 0.0001     evaluation reward: 1.85\n","episode: 1040   score: 0.0   memory length: 193466   epsilon: 0.8149353400040176    steps: 124    lr: 0.0001     evaluation reward: 1.83\n","episode: 1041   score: 2.0   memory length: 193665   epsilon: 0.8145413200040261    steps: 199    lr: 0.0001     evaluation reward: 1.81\n","episode: 1042   score: 0.0   memory length: 193789   epsilon: 0.8142958000040315    steps: 124    lr: 0.0001     evaluation reward: 1.81\n","episode: 1043   score: 3.0   memory length: 194019   epsilon: 0.8138404000040413    steps: 230    lr: 0.0001     evaluation reward: 1.8\n","episode: 1044   score: 2.0   memory length: 194218   epsilon: 0.8134463800040499    steps: 199    lr: 0.0001     evaluation reward: 1.8\n","episode: 1045   score: 0.0   memory length: 194342   epsilon: 0.8132008600040552    steps: 124    lr: 0.0001     evaluation reward: 1.79\n","episode: 1046   score: 3.0   memory length: 194569   epsilon: 0.812751400004065    steps: 227    lr: 0.0001     evaluation reward: 1.8\n","episode: 1047   score: 2.0   memory length: 194768   epsilon: 0.8123573800040735    steps: 199    lr: 0.0001     evaluation reward: 1.8\n","episode: 1048   score: 2.0   memory length: 194951   epsilon: 0.8119950400040814    steps: 183    lr: 0.0001     evaluation reward: 1.77\n","episode: 1049   score: 5.0   memory length: 195318   epsilon: 0.8112683800040972    steps: 367    lr: 0.0001     evaluation reward: 1.79\n","episode: 1050   score: 0.0   memory length: 195442   epsilon: 0.8110228600041025    steps: 124    lr: 0.0001     evaluation reward: 1.79\n","episode: 1051   score: 0.0   memory length: 195566   epsilon: 0.8107773400041078    steps: 124    lr: 0.0001     evaluation reward: 1.77\n","episode: 1052   score: 4.0   memory length: 195839   epsilon: 0.8102368000041196    steps: 273    lr: 0.0001     evaluation reward: 1.8\n","episode: 1053   score: 2.0   memory length: 196038   epsilon: 0.8098427800041281    steps: 199    lr: 0.0001     evaluation reward: 1.82\n","episode: 1054   score: 2.0   memory length: 196237   epsilon: 0.8094487600041367    steps: 199    lr: 0.0001     evaluation reward: 1.82\n","episode: 1055   score: 0.0   memory length: 196360   epsilon: 0.809205220004142    steps: 123    lr: 0.0001     evaluation reward: 1.8\n","episode: 1056   score: 0.0   memory length: 196483   epsilon: 0.8089616800041473    steps: 123    lr: 0.0001     evaluation reward: 1.77\n","episode: 1057   score: 3.0   memory length: 196753   epsilon: 0.8084270800041589    steps: 270    lr: 0.0001     evaluation reward: 1.78\n","episode: 1058   score: 3.0   memory length: 196985   epsilon: 0.8079677200041688    steps: 232    lr: 0.0001     evaluation reward: 1.79\n","episode: 1059   score: 0.0   memory length: 197109   epsilon: 0.8077222000041742    steps: 124    lr: 0.0001     evaluation reward: 1.77\n","episode: 1060   score: 7.0   memory length: 197514   epsilon: 0.8069203000041916    steps: 405    lr: 0.0001     evaluation reward: 1.82\n","episode: 1061   score: 1.0   memory length: 197665   epsilon: 0.8066213200041981    steps: 151    lr: 0.0001     evaluation reward: 1.83\n","episode: 1062   score: 2.0   memory length: 197884   epsilon: 0.8061877000042075    steps: 219    lr: 0.0001     evaluation reward: 1.84\n","episode: 1063   score: 1.0   memory length: 198054   epsilon: 0.8058511000042148    steps: 170    lr: 0.0001     evaluation reward: 1.83\n","episode: 1064   score: 5.0   memory length: 198383   epsilon: 0.8051996800042289    steps: 329    lr: 0.0001     evaluation reward: 1.85\n","episode: 1065   score: 4.0   memory length: 198656   epsilon: 0.8046591400042407    steps: 273    lr: 0.0001     evaluation reward: 1.89\n","episode: 1066   score: 2.0   memory length: 198839   epsilon: 0.8042968000042485    steps: 183    lr: 0.0001     evaluation reward: 1.91\n","episode: 1067   score: 2.0   memory length: 199063   epsilon: 0.8038532800042582    steps: 224    lr: 0.0001     evaluation reward: 1.93\n","episode: 1068   score: 0.0   memory length: 199186   epsilon: 0.8036097400042634    steps: 123    lr: 0.0001     evaluation reward: 1.9\n","episode: 1069   score: 2.0   memory length: 199385   epsilon: 0.803215720004272    steps: 199    lr: 0.0001     evaluation reward: 1.91\n","episode: 1070   score: 2.0   memory length: 199602   epsilon: 0.8027860600042813    steps: 217    lr: 0.0001     evaluation reward: 1.91\n","episode: 1071   score: 0.0   memory length: 199726   epsilon: 0.8025405400042867    steps: 124    lr: 0.0001     evaluation reward: 1.91\n","episode: 1072   score: 2.0   memory length: 199907   epsilon: 0.8021821600042944    steps: 181    lr: 0.0001     evaluation reward: 1.89\n","episode: 1073   score: 1.0   memory length: 200059   epsilon: 0.801881200004301    steps: 152    lr: 4e-05     evaluation reward: 1.88\n","episode: 1074   score: 2.0   memory length: 200258   epsilon: 0.8014871800043095    steps: 199    lr: 4e-05     evaluation reward: 1.89\n","episode: 1075   score: 3.0   memory length: 200469   epsilon: 0.8010694000043186    steps: 211    lr: 4e-05     evaluation reward: 1.92\n","episode: 1076   score: 1.0   memory length: 200621   epsilon: 0.8007684400043251    steps: 152    lr: 4e-05     evaluation reward: 1.91\n","episode: 1077   score: 3.0   memory length: 200848   epsilon: 0.8003189800043349    steps: 227    lr: 4e-05     evaluation reward: 1.92\n","episode: 1078   score: 2.0   memory length: 201066   epsilon: 0.7998873400043442    steps: 218    lr: 4e-05     evaluation reward: 1.92\n","episode: 1079   score: 2.0   memory length: 201265   epsilon: 0.7994933200043528    steps: 199    lr: 4e-05     evaluation reward: 1.92\n","episode: 1080   score: 0.0   memory length: 201389   epsilon: 0.7992478000043581    steps: 124    lr: 4e-05     evaluation reward: 1.9\n","episode: 1081   score: 1.0   memory length: 201541   epsilon: 0.7989468400043647    steps: 152    lr: 4e-05     evaluation reward: 1.86\n","episode: 1082   score: 2.0   memory length: 201760   epsilon: 0.7985132200043741    steps: 219    lr: 4e-05     evaluation reward: 1.86\n","episode: 1083   score: 2.0   memory length: 201959   epsilon: 0.7981192000043826    steps: 199    lr: 4e-05     evaluation reward: 1.86\n","episode: 1084   score: 1.0   memory length: 202112   epsilon: 0.7978162600043892    steps: 153    lr: 4e-05     evaluation reward: 1.85\n","episode: 1085   score: 3.0   memory length: 202338   epsilon: 0.7973687800043989    steps: 226    lr: 4e-05     evaluation reward: 1.88\n","episode: 1086   score: 0.0   memory length: 202462   epsilon: 0.7971232600044043    steps: 124    lr: 4e-05     evaluation reward: 1.88\n","episode: 1087   score: 1.0   memory length: 202614   epsilon: 0.7968223000044108    steps: 152    lr: 4e-05     evaluation reward: 1.88\n","episode: 1088   score: 4.0   memory length: 202890   epsilon: 0.7962758200044227    steps: 276    lr: 4e-05     evaluation reward: 1.9\n","episode: 1089   score: 0.0   memory length: 203013   epsilon: 0.7960322800044279    steps: 123    lr: 4e-05     evaluation reward: 1.87\n","episode: 1090   score: 0.0   memory length: 203137   epsilon: 0.7957867600044333    steps: 124    lr: 4e-05     evaluation reward: 1.85\n","episode: 1091   score: 3.0   memory length: 203383   epsilon: 0.7952996800044438    steps: 246    lr: 4e-05     evaluation reward: 1.88\n","episode: 1092   score: 3.0   memory length: 203594   epsilon: 0.7948819000044529    steps: 211    lr: 4e-05     evaluation reward: 1.89\n","episode: 1093   score: 4.0   memory length: 203854   epsilon: 0.7943671000044641    steps: 260    lr: 4e-05     evaluation reward: 1.91\n","episode: 1094   score: 1.0   memory length: 204023   epsilon: 0.7940324800044714    steps: 169    lr: 4e-05     evaluation reward: 1.91\n","episode: 1095   score: 1.0   memory length: 204193   epsilon: 0.7936958800044787    steps: 170    lr: 4e-05     evaluation reward: 1.88\n","episode: 1096   score: 1.0   memory length: 204345   epsilon: 0.7933949200044852    steps: 152    lr: 4e-05     evaluation reward: 1.89\n","episode: 1097   score: 0.0   memory length: 204469   epsilon: 0.7931494000044905    steps: 124    lr: 4e-05     evaluation reward: 1.88\n","episode: 1098   score: 4.0   memory length: 204766   epsilon: 0.7925613400045033    steps: 297    lr: 4e-05     evaluation reward: 1.91\n","episode: 1099   score: 4.0   memory length: 205064   epsilon: 0.7919713000045161    steps: 298    lr: 4e-05     evaluation reward: 1.93\n","episode: 1100   score: 2.0   memory length: 205249   epsilon: 0.791605000004524    steps: 185    lr: 4e-05     evaluation reward: 1.88\n","episode: 1101   score: 2.0   memory length: 205449   epsilon: 0.7912090000045326    steps: 200    lr: 4e-05     evaluation reward: 1.86\n","episode: 1102   score: 0.0   memory length: 205573   epsilon: 0.790963480004538    steps: 124    lr: 4e-05     evaluation reward: 1.85\n","episode: 1103   score: 1.0   memory length: 205746   epsilon: 0.7906209400045454    steps: 173    lr: 4e-05     evaluation reward: 1.84\n","episode: 1104   score: 0.0   memory length: 205869   epsilon: 0.7903774000045507    steps: 123    lr: 4e-05     evaluation reward: 1.83\n","episode: 1105   score: 2.0   memory length: 206068   epsilon: 0.7899833800045593    steps: 199    lr: 4e-05     evaluation reward: 1.85\n","episode: 1106   score: 0.0   memory length: 206191   epsilon: 0.7897398400045645    steps: 123    lr: 4e-05     evaluation reward: 1.83\n","episode: 1107   score: 3.0   memory length: 206423   epsilon: 0.7892804800045745    steps: 232    lr: 4e-05     evaluation reward: 1.83\n","episode: 1108   score: 2.0   memory length: 206621   epsilon: 0.788888440004583    steps: 198    lr: 4e-05     evaluation reward: 1.81\n","episode: 1109   score: 0.0   memory length: 206744   epsilon: 0.7886449000045883    steps: 123    lr: 4e-05     evaluation reward: 1.79\n","episode: 1110   score: 4.0   memory length: 207062   epsilon: 0.788015260004602    steps: 318    lr: 4e-05     evaluation reward: 1.81\n","episode: 1111   score: 3.0   memory length: 207309   epsilon: 0.7875262000046126    steps: 247    lr: 4e-05     evaluation reward: 1.82\n","episode: 1112   score: 0.0   memory length: 207433   epsilon: 0.7872806800046179    steps: 124    lr: 4e-05     evaluation reward: 1.8\n","episode: 1113   score: 4.0   memory length: 207732   epsilon: 0.7866886600046308    steps: 299    lr: 4e-05     evaluation reward: 1.82\n","episode: 1114   score: 3.0   memory length: 207979   epsilon: 0.7861996000046414    steps: 247    lr: 4e-05     evaluation reward: 1.82\n","episode: 1115   score: 4.0   memory length: 208255   epsilon: 0.7856531200046533    steps: 276    lr: 4e-05     evaluation reward: 1.84\n","episode: 1116   score: 1.0   memory length: 208406   epsilon: 0.7853541400046598    steps: 151    lr: 4e-05     evaluation reward: 1.83\n","episode: 1117   score: 2.0   memory length: 208605   epsilon: 0.7849601200046683    steps: 199    lr: 4e-05     evaluation reward: 1.85\n","episode: 1118   score: 0.0   memory length: 208729   epsilon: 0.7847146000046736    steps: 124    lr: 4e-05     evaluation reward: 1.84\n","episode: 1119   score: 0.0   memory length: 208852   epsilon: 0.7844710600046789    steps: 123    lr: 4e-05     evaluation reward: 1.83\n","episode: 1120   score: 1.0   memory length: 209022   epsilon: 0.7841344600046862    steps: 170    lr: 4e-05     evaluation reward: 1.81\n","episode: 1121   score: 1.0   memory length: 209193   epsilon: 0.7837958800046936    steps: 171    lr: 4e-05     evaluation reward: 1.8\n","episode: 1122   score: 3.0   memory length: 209439   epsilon: 0.7833088000047042    steps: 246    lr: 4e-05     evaluation reward: 1.81\n","episode: 1123   score: 3.0   memory length: 209666   epsilon: 0.7828593400047139    steps: 227    lr: 4e-05     evaluation reward: 1.81\n","episode: 1124   score: 1.0   memory length: 209836   epsilon: 0.7825227400047212    steps: 170    lr: 4e-05     evaluation reward: 1.81\n","episode: 1125   score: 5.0   memory length: 210180   epsilon: 0.781841620004736    steps: 344    lr: 4e-05     evaluation reward: 1.84\n","episode: 1126   score: 1.0   memory length: 210332   epsilon: 0.7815406600047425    steps: 152    lr: 4e-05     evaluation reward: 1.83\n","episode: 1127   score: 3.0   memory length: 210558   epsilon: 0.7810931800047523    steps: 226    lr: 4e-05     evaluation reward: 1.84\n","episode: 1128   score: 4.0   memory length: 210855   epsilon: 0.780505120004765    steps: 297    lr: 4e-05     evaluation reward: 1.86\n","episode: 1129   score: 6.0   memory length: 211192   epsilon: 0.7798378600047795    steps: 337    lr: 4e-05     evaluation reward: 1.91\n","episode: 1130   score: 2.0   memory length: 211391   epsilon: 0.7794438400047881    steps: 199    lr: 4e-05     evaluation reward: 1.9\n","episode: 1131   score: 1.0   memory length: 211543   epsilon: 0.7791428800047946    steps: 152    lr: 4e-05     evaluation reward: 1.91\n","episode: 1132   score: 3.0   memory length: 211770   epsilon: 0.7786934200048043    steps: 227    lr: 4e-05     evaluation reward: 1.9\n","episode: 1133   score: 1.0   memory length: 211940   epsilon: 0.7783568200048117    steps: 170    lr: 4e-05     evaluation reward: 1.91\n","episode: 1134   score: 1.0   memory length: 212092   epsilon: 0.7780558600048182    steps: 152    lr: 4e-05     evaluation reward: 1.9\n","episode: 1135   score: 6.0   memory length: 212485   epsilon: 0.7772777200048351    steps: 393    lr: 4e-05     evaluation reward: 1.91\n","episode: 1136   score: 1.0   memory length: 212656   epsilon: 0.7769391400048424    steps: 171    lr: 4e-05     evaluation reward: 1.91\n","episode: 1137   score: 2.0   memory length: 212857   epsilon: 0.7765411600048511    steps: 201    lr: 4e-05     evaluation reward: 1.92\n","episode: 1138   score: 2.0   memory length: 213057   epsilon: 0.7761451600048597    steps: 200    lr: 4e-05     evaluation reward: 1.92\n","episode: 1139   score: 3.0   memory length: 213306   epsilon: 0.7756521400048704    steps: 249    lr: 4e-05     evaluation reward: 1.95\n","episode: 1140   score: 4.0   memory length: 213605   epsilon: 0.7750601200048832    steps: 299    lr: 4e-05     evaluation reward: 1.99\n","episode: 1141   score: 3.0   memory length: 213831   epsilon: 0.7746126400048929    steps: 226    lr: 4e-05     evaluation reward: 2.0\n","episode: 1142   score: 0.0   memory length: 213955   epsilon: 0.7743671200048983    steps: 124    lr: 4e-05     evaluation reward: 2.0\n","episode: 1143   score: 1.0   memory length: 214106   epsilon: 0.7740681400049048    steps: 151    lr: 4e-05     evaluation reward: 1.98\n","episode: 1144   score: 3.0   memory length: 214317   epsilon: 0.7736503600049138    steps: 211    lr: 4e-05     evaluation reward: 1.99\n","episode: 1145   score: 0.0   memory length: 214440   epsilon: 0.7734068200049191    steps: 123    lr: 4e-05     evaluation reward: 1.99\n","episode: 1146   score: 3.0   memory length: 214667   epsilon: 0.7729573600049289    steps: 227    lr: 4e-05     evaluation reward: 1.99\n","episode: 1147   score: 1.0   memory length: 214819   epsilon: 0.7726564000049354    steps: 152    lr: 4e-05     evaluation reward: 1.98\n","episode: 1148   score: 1.0   memory length: 214971   epsilon: 0.7723554400049419    steps: 152    lr: 4e-05     evaluation reward: 1.97\n","episode: 1149   score: 4.0   memory length: 215289   epsilon: 0.7717258000049556    steps: 318    lr: 4e-05     evaluation reward: 1.96\n","episode: 1150   score: 3.0   memory length: 215516   epsilon: 0.7712763400049654    steps: 227    lr: 4e-05     evaluation reward: 1.99\n","episode: 1151   score: 2.0   memory length: 215715   epsilon: 0.7708823200049739    steps: 199    lr: 4e-05     evaluation reward: 2.01\n","episode: 1152   score: 4.0   memory length: 216015   epsilon: 0.7702883200049868    steps: 300    lr: 4e-05     evaluation reward: 2.01\n","episode: 1153   score: 2.0   memory length: 216213   epsilon: 0.7698962800049953    steps: 198    lr: 4e-05     evaluation reward: 2.01\n","episode: 1154   score: 1.0   memory length: 216382   epsilon: 0.7695616600050026    steps: 169    lr: 4e-05     evaluation reward: 2.0\n","episode: 1155   score: 3.0   memory length: 216649   epsilon: 0.7690330000050141    steps: 267    lr: 4e-05     evaluation reward: 2.03\n","episode: 1156   score: 4.0   memory length: 216967   epsilon: 0.7684033600050277    steps: 318    lr: 4e-05     evaluation reward: 2.07\n","episode: 1157   score: 6.0   memory length: 217283   epsilon: 0.7677776800050413    steps: 316    lr: 4e-05     evaluation reward: 2.1\n","episode: 1158   score: 2.0   memory length: 217484   epsilon: 0.76737970000505    steps: 201    lr: 4e-05     evaluation reward: 2.09\n","episode: 1159   score: 2.0   memory length: 217682   epsilon: 0.7669876600050585    steps: 198    lr: 4e-05     evaluation reward: 2.11\n","episode: 1160   score: 0.0   memory length: 217806   epsilon: 0.7667421400050638    steps: 124    lr: 4e-05     evaluation reward: 2.04\n","episode: 1161   score: 2.0   memory length: 218009   epsilon: 0.7663402000050725    steps: 203    lr: 4e-05     evaluation reward: 2.05\n","episode: 1162   score: 3.0   memory length: 218220   epsilon: 0.7659224200050816    steps: 211    lr: 4e-05     evaluation reward: 2.06\n","episode: 1163   score: 1.0   memory length: 218393   epsilon: 0.765579880005089    steps: 173    lr: 4e-05     evaluation reward: 2.06\n","episode: 1164   score: 2.0   memory length: 218592   epsilon: 0.7651858600050976    steps: 199    lr: 4e-05     evaluation reward: 2.03\n","episode: 1165   score: 1.0   memory length: 218744   epsilon: 0.7648849000051041    steps: 152    lr: 4e-05     evaluation reward: 2.0\n","episode: 1166   score: 2.0   memory length: 218964   epsilon: 0.7644493000051136    steps: 220    lr: 4e-05     evaluation reward: 2.0\n","episode: 1167   score: 4.0   memory length: 219262   epsilon: 0.7638592600051264    steps: 298    lr: 4e-05     evaluation reward: 2.02\n","episode: 1168   score: 2.0   memory length: 219464   epsilon: 0.7634593000051351    steps: 202    lr: 4e-05     evaluation reward: 2.04\n","episode: 1169   score: 2.0   memory length: 219665   epsilon: 0.7630613200051437    steps: 201    lr: 4e-05     evaluation reward: 2.04\n","episode: 1170   score: 1.0   memory length: 219817   epsilon: 0.7627603600051502    steps: 152    lr: 4e-05     evaluation reward: 2.03\n","episode: 1171   score: 2.0   memory length: 220037   epsilon: 0.7623247600051597    steps: 220    lr: 4e-05     evaluation reward: 2.05\n","episode: 1172   score: 4.0   memory length: 220335   epsilon: 0.7617347200051725    steps: 298    lr: 4e-05     evaluation reward: 2.07\n","episode: 1173   score: 1.0   memory length: 220505   epsilon: 0.7613981200051798    steps: 170    lr: 4e-05     evaluation reward: 2.07\n","episode: 1174   score: 0.0   memory length: 220628   epsilon: 0.7611545800051851    steps: 123    lr: 4e-05     evaluation reward: 2.05\n","episode: 1175   score: 3.0   memory length: 220855   epsilon: 0.7607051200051949    steps: 227    lr: 4e-05     evaluation reward: 2.05\n","episode: 1176   score: 0.0   memory length: 220979   epsilon: 0.7604596000052002    steps: 124    lr: 4e-05     evaluation reward: 2.04\n","episode: 1177   score: 8.0   memory length: 221435   epsilon: 0.7595567200052198    steps: 456    lr: 4e-05     evaluation reward: 2.09\n","episode: 1178   score: 2.0   memory length: 221634   epsilon: 0.7591627000052283    steps: 199    lr: 4e-05     evaluation reward: 2.09\n","episode: 1179   score: 2.0   memory length: 221833   epsilon: 0.7587686800052369    steps: 199    lr: 4e-05     evaluation reward: 2.09\n","episode: 1180   score: 7.0   memory length: 222261   epsilon: 0.7579212400052553    steps: 428    lr: 4e-05     evaluation reward: 2.16\n","episode: 1181   score: 2.0   memory length: 222459   epsilon: 0.7575292000052638    steps: 198    lr: 4e-05     evaluation reward: 2.17\n","episode: 1182   score: 3.0   memory length: 222709   epsilon: 0.7570342000052745    steps: 250    lr: 4e-05     evaluation reward: 2.18\n","episode: 1183   score: 0.0   memory length: 222833   epsilon: 0.7567886800052799    steps: 124    lr: 4e-05     evaluation reward: 2.16\n","episode: 1184   score: 0.0   memory length: 222956   epsilon: 0.7565451400052852    steps: 123    lr: 4e-05     evaluation reward: 2.15\n","episode: 1185   score: 0.0   memory length: 223079   epsilon: 0.7563016000052905    steps: 123    lr: 4e-05     evaluation reward: 2.12\n","episode: 1186   score: 4.0   memory length: 223397   epsilon: 0.7556719600053041    steps: 318    lr: 4e-05     evaluation reward: 2.16\n","episode: 1187   score: 3.0   memory length: 223627   epsilon: 0.755216560005314    steps: 230    lr: 4e-05     evaluation reward: 2.18\n","episode: 1188   score: 3.0   memory length: 223853   epsilon: 0.7547690800053237    steps: 226    lr: 4e-05     evaluation reward: 2.17\n","episode: 1189   score: 4.0   memory length: 224149   epsilon: 0.7541830000053364    steps: 296    lr: 4e-05     evaluation reward: 2.21\n","episode: 1190   score: 2.0   memory length: 224368   epsilon: 0.7537493800053459    steps: 219    lr: 4e-05     evaluation reward: 2.23\n","episode: 1191   score: 1.0   memory length: 224520   epsilon: 0.7534484200053524    steps: 152    lr: 4e-05     evaluation reward: 2.21\n","episode: 1192   score: 5.0   memory length: 224887   epsilon: 0.7527217600053682    steps: 367    lr: 4e-05     evaluation reward: 2.23\n","episode: 1193   score: 5.0   memory length: 225214   epsilon: 0.7520743000053822    steps: 327    lr: 4e-05     evaluation reward: 2.24\n","episode: 1194   score: 3.0   memory length: 225482   epsilon: 0.7515436600053937    steps: 268    lr: 4e-05     evaluation reward: 2.26\n","episode: 1195   score: 4.0   memory length: 225739   epsilon: 0.7510348000054048    steps: 257    lr: 4e-05     evaluation reward: 2.29\n","episode: 1196   score: 2.0   memory length: 225939   epsilon: 0.7506388000054134    steps: 200    lr: 4e-05     evaluation reward: 2.3\n","episode: 1197   score: 4.0   memory length: 226215   epsilon: 0.7500923200054253    steps: 276    lr: 4e-05     evaluation reward: 2.34\n","episode: 1198   score: 3.0   memory length: 226461   epsilon: 0.7496052400054358    steps: 246    lr: 4e-05     evaluation reward: 2.33\n","episode: 1199   score: 3.0   memory length: 226690   epsilon: 0.7491518200054457    steps: 229    lr: 4e-05     evaluation reward: 2.32\n","episode: 1200   score: 4.0   memory length: 226965   epsilon: 0.7486073200054575    steps: 275    lr: 4e-05     evaluation reward: 2.34\n","episode: 1201   score: 2.0   memory length: 227163   epsilon: 0.748215280005466    steps: 198    lr: 4e-05     evaluation reward: 2.34\n","episode: 1202   score: 4.0   memory length: 227462   epsilon: 0.7476232600054789    steps: 299    lr: 4e-05     evaluation reward: 2.38\n","episode: 1203   score: 2.0   memory length: 227661   epsilon: 0.7472292400054874    steps: 199    lr: 4e-05     evaluation reward: 2.39\n","episode: 1204   score: 3.0   memory length: 227907   epsilon: 0.746742160005498    steps: 246    lr: 4e-05     evaluation reward: 2.42\n","episode: 1205   score: 3.0   memory length: 228154   epsilon: 0.7462531000055086    steps: 247    lr: 4e-05     evaluation reward: 2.43\n","episode: 1206   score: 2.0   memory length: 228353   epsilon: 0.7458590800055171    steps: 199    lr: 4e-05     evaluation reward: 2.45\n","episode: 1207   score: 0.0   memory length: 228476   epsilon: 0.7456155400055224    steps: 123    lr: 4e-05     evaluation reward: 2.42\n","episode: 1208   score: 3.0   memory length: 228724   epsilon: 0.7451245000055331    steps: 248    lr: 4e-05     evaluation reward: 2.43\n","episode: 1209   score: 0.0   memory length: 228848   epsilon: 0.7448789800055384    steps: 124    lr: 4e-05     evaluation reward: 2.43\n","episode: 1210   score: 5.0   memory length: 229149   epsilon: 0.7442830000055514    steps: 301    lr: 4e-05     evaluation reward: 2.44\n","episode: 1211   score: 3.0   memory length: 229400   epsilon: 0.7437860200055622    steps: 251    lr: 4e-05     evaluation reward: 2.44\n","episode: 1212   score: 3.0   memory length: 229653   epsilon: 0.743285080005573    steps: 253    lr: 4e-05     evaluation reward: 2.47\n","episode: 1213   score: 3.0   memory length: 229865   epsilon: 0.7428653200055821    steps: 212    lr: 4e-05     evaluation reward: 2.46\n","episode: 1214   score: 3.0   memory length: 230094   epsilon: 0.742411900005592    steps: 229    lr: 4e-05     evaluation reward: 2.46\n","episode: 1215   score: 3.0   memory length: 230364   epsilon: 0.7418773000056036    steps: 270    lr: 4e-05     evaluation reward: 2.45\n","episode: 1216   score: 2.0   memory length: 230563   epsilon: 0.7414832800056121    steps: 199    lr: 4e-05     evaluation reward: 2.46\n","episode: 1217   score: 1.0   memory length: 230734   epsilon: 0.7411447000056195    steps: 171    lr: 4e-05     evaluation reward: 2.45\n","episode: 1218   score: 3.0   memory length: 230946   epsilon: 0.7407249400056286    steps: 212    lr: 4e-05     evaluation reward: 2.48\n","episode: 1219   score: 0.0   memory length: 231070   epsilon: 0.7404794200056339    steps: 124    lr: 4e-05     evaluation reward: 2.48\n","episode: 1220   score: 0.0   memory length: 231194   epsilon: 0.7402339000056393    steps: 124    lr: 4e-05     evaluation reward: 2.47\n","episode: 1221   score: 3.0   memory length: 231444   epsilon: 0.73973890000565    steps: 250    lr: 4e-05     evaluation reward: 2.49\n","episode: 1222   score: 5.0   memory length: 231790   epsilon: 0.7390538200056649    steps: 346    lr: 4e-05     evaluation reward: 2.51\n","episode: 1223   score: 3.0   memory length: 232042   epsilon: 0.7385548600056757    steps: 252    lr: 4e-05     evaluation reward: 2.51\n","episode: 1224   score: 1.0   memory length: 232213   epsilon: 0.7382162800056831    steps: 171    lr: 4e-05     evaluation reward: 2.51\n","episode: 1225   score: 5.0   memory length: 232522   epsilon: 0.7376044600056963    steps: 309    lr: 4e-05     evaluation reward: 2.51\n","episode: 1226   score: 2.0   memory length: 232720   epsilon: 0.7372124200057049    steps: 198    lr: 4e-05     evaluation reward: 2.52\n","episode: 1227   score: 3.0   memory length: 232949   epsilon: 0.7367590000057147    steps: 229    lr: 4e-05     evaluation reward: 2.52\n","episode: 1228   score: 3.0   memory length: 233179   epsilon: 0.7363036000057246    steps: 230    lr: 4e-05     evaluation reward: 2.51\n","episode: 1229   score: 1.0   memory length: 233350   epsilon: 0.7359650200057319    steps: 171    lr: 4e-05     evaluation reward: 2.46\n","episode: 1230   score: 2.0   memory length: 233549   epsilon: 0.7355710000057405    steps: 199    lr: 4e-05     evaluation reward: 2.46\n","episode: 1231   score: 2.0   memory length: 233748   epsilon: 0.735176980005749    steps: 199    lr: 4e-05     evaluation reward: 2.47\n","episode: 1232   score: 3.0   memory length: 233995   epsilon: 0.7346879200057597    steps: 247    lr: 4e-05     evaluation reward: 2.47\n","episode: 1233   score: 2.0   memory length: 234194   epsilon: 0.7342939000057682    steps: 199    lr: 4e-05     evaluation reward: 2.48\n","episode: 1234   score: 2.0   memory length: 234412   epsilon: 0.7338622600057776    steps: 218    lr: 4e-05     evaluation reward: 2.49\n","episode: 1235   score: 2.0   memory length: 234611   epsilon: 0.7334682400057861    steps: 199    lr: 4e-05     evaluation reward: 2.45\n","episode: 1236   score: 3.0   memory length: 234841   epsilon: 0.733012840005796    steps: 230    lr: 4e-05     evaluation reward: 2.47\n","episode: 1237   score: 1.0   memory length: 235011   epsilon: 0.7326762400058033    steps: 170    lr: 4e-05     evaluation reward: 2.46\n","episode: 1238   score: 3.0   memory length: 235242   epsilon: 0.7322188600058133    steps: 231    lr: 4e-05     evaluation reward: 2.47\n","episode: 1239   score: 0.0   memory length: 235366   epsilon: 0.7319733400058186    steps: 124    lr: 4e-05     evaluation reward: 2.44\n","episode: 1240   score: 0.0   memory length: 235490   epsilon: 0.7317278200058239    steps: 124    lr: 4e-05     evaluation reward: 2.4\n","episode: 1241   score: 1.0   memory length: 235660   epsilon: 0.7313912200058312    steps: 170    lr: 4e-05     evaluation reward: 2.38\n","episode: 1242   score: 4.0   memory length: 235953   epsilon: 0.7308110800058438    steps: 293    lr: 4e-05     evaluation reward: 2.42\n","episode: 1243   score: 3.0   memory length: 236184   epsilon: 0.7303537000058538    steps: 231    lr: 4e-05     evaluation reward: 2.44\n","episode: 1244   score: 2.0   memory length: 236383   epsilon: 0.7299596800058623    steps: 199    lr: 4e-05     evaluation reward: 2.43\n","episode: 1245   score: 1.0   memory length: 236535   epsilon: 0.7296587200058688    steps: 152    lr: 4e-05     evaluation reward: 2.44\n","episode: 1246   score: 1.0   memory length: 236708   epsilon: 0.7293161800058763    steps: 173    lr: 4e-05     evaluation reward: 2.42\n","episode: 1247   score: 2.0   memory length: 236907   epsilon: 0.7289221600058848    steps: 199    lr: 4e-05     evaluation reward: 2.43\n","episode: 1248   score: 4.0   memory length: 237149   epsilon: 0.7284430000058952    steps: 242    lr: 4e-05     evaluation reward: 2.46\n","episode: 1249   score: 3.0   memory length: 237379   epsilon: 0.7279876000059051    steps: 230    lr: 4e-05     evaluation reward: 2.45\n","episode: 1250   score: 2.0   memory length: 237582   epsilon: 0.7275856600059138    steps: 203    lr: 4e-05     evaluation reward: 2.44\n","episode: 1251   score: 2.0   memory length: 237781   epsilon: 0.7271916400059224    steps: 199    lr: 4e-05     evaluation reward: 2.44\n","episode: 1252   score: 3.0   memory length: 238030   epsilon: 0.7266986200059331    steps: 249    lr: 4e-05     evaluation reward: 2.43\n","episode: 1253   score: 2.0   memory length: 238249   epsilon: 0.7262650000059425    steps: 219    lr: 4e-05     evaluation reward: 2.43\n","episode: 1254   score: 0.0   memory length: 238372   epsilon: 0.7260214600059478    steps: 123    lr: 4e-05     evaluation reward: 2.42\n","episode: 1255   score: 1.0   memory length: 238544   epsilon: 0.7256809000059552    steps: 172    lr: 4e-05     evaluation reward: 2.4\n","episode: 1256   score: 2.0   memory length: 238743   epsilon: 0.7252868800059638    steps: 199    lr: 4e-05     evaluation reward: 2.38\n","episode: 1257   score: 4.0   memory length: 239022   epsilon: 0.7247344600059757    steps: 279    lr: 4e-05     evaluation reward: 2.36\n","episode: 1258   score: 5.0   memory length: 239367   epsilon: 0.7240513600059906    steps: 345    lr: 4e-05     evaluation reward: 2.39\n","episode: 1259   score: 1.0   memory length: 239537   epsilon: 0.7237147600059979    steps: 170    lr: 4e-05     evaluation reward: 2.38\n","episode: 1260   score: 2.0   memory length: 239756   epsilon: 0.7232811400060073    steps: 219    lr: 4e-05     evaluation reward: 2.4\n","episode: 1261   score: 0.0   memory length: 239880   epsilon: 0.7230356200060126    steps: 124    lr: 4e-05     evaluation reward: 2.38\n","episode: 1262   score: 1.0   memory length: 240050   epsilon: 0.7226990200060199    steps: 170    lr: 4e-05     evaluation reward: 2.36\n","episode: 1263   score: 5.0   memory length: 240359   epsilon: 0.7220872000060332    steps: 309    lr: 4e-05     evaluation reward: 2.4\n","episode: 1264   score: 6.0   memory length: 240679   epsilon: 0.721453600006047    steps: 320    lr: 4e-05     evaluation reward: 2.44\n","episode: 1265   score: 2.0   memory length: 240898   epsilon: 0.7210199800060564    steps: 219    lr: 4e-05     evaluation reward: 2.45\n","episode: 1266   score: 4.0   memory length: 241194   epsilon: 0.7204339000060691    steps: 296    lr: 4e-05     evaluation reward: 2.47\n","episode: 1267   score: 1.0   memory length: 241345   epsilon: 0.7201349200060756    steps: 151    lr: 4e-05     evaluation reward: 2.44\n","episode: 1268   score: 1.0   memory length: 241517   epsilon: 0.719794360006083    steps: 172    lr: 4e-05     evaluation reward: 2.43\n","episode: 1269   score: 3.0   memory length: 241785   epsilon: 0.7192637200060945    steps: 268    lr: 4e-05     evaluation reward: 2.44\n","episode: 1270   score: 3.0   memory length: 242056   epsilon: 0.7187271400061062    steps: 271    lr: 4e-05     evaluation reward: 2.46\n","episode: 1271   score: 1.0   memory length: 242207   epsilon: 0.7184281600061126    steps: 151    lr: 4e-05     evaluation reward: 2.45\n","episode: 1272   score: 1.0   memory length: 242359   epsilon: 0.7181272000061192    steps: 152    lr: 4e-05     evaluation reward: 2.42\n","episode: 1273   score: 3.0   memory length: 242605   epsilon: 0.7176401200061298    steps: 246    lr: 4e-05     evaluation reward: 2.44\n","episode: 1274   score: 4.0   memory length: 242899   epsilon: 0.7170580000061424    steps: 294    lr: 4e-05     evaluation reward: 2.48\n","episode: 1275   score: 1.0   memory length: 243071   epsilon: 0.7167174400061498    steps: 172    lr: 4e-05     evaluation reward: 2.46\n","episode: 1276   score: 2.0   memory length: 243270   epsilon: 0.7163234200061583    steps: 199    lr: 4e-05     evaluation reward: 2.48\n","episode: 1277   score: 5.0   memory length: 243612   epsilon: 0.715646260006173    steps: 342    lr: 4e-05     evaluation reward: 2.45\n","episode: 1278   score: 2.0   memory length: 243811   epsilon: 0.7152522400061816    steps: 199    lr: 4e-05     evaluation reward: 2.45\n","episode: 1279   score: 2.0   memory length: 244010   epsilon: 0.7148582200061901    steps: 199    lr: 4e-05     evaluation reward: 2.45\n","episode: 1280   score: 3.0   memory length: 244239   epsilon: 0.7144048000062    steps: 229    lr: 4e-05     evaluation reward: 2.41\n","episode: 1281   score: 2.0   memory length: 244438   epsilon: 0.7140107800062085    steps: 199    lr: 4e-05     evaluation reward: 2.41\n","episode: 1282   score: 10.0   memory length: 244933   epsilon: 0.7130306800062298    steps: 495    lr: 4e-05     evaluation reward: 2.48\n","episode: 1283   score: 1.0   memory length: 245084   epsilon: 0.7127317000062363    steps: 151    lr: 4e-05     evaluation reward: 2.49\n","episode: 1284   score: 5.0   memory length: 245406   epsilon: 0.7120941400062502    steps: 322    lr: 4e-05     evaluation reward: 2.54\n","episode: 1285   score: 3.0   memory length: 245652   epsilon: 0.7116070600062607    steps: 246    lr: 4e-05     evaluation reward: 2.57\n","episode: 1286   score: 1.0   memory length: 245804   epsilon: 0.7113061000062673    steps: 152    lr: 4e-05     evaluation reward: 2.54\n","episode: 1287   score: 2.0   memory length: 246021   epsilon: 0.7108764400062766    steps: 217    lr: 4e-05     evaluation reward: 2.53\n","episode: 1288   score: 1.0   memory length: 246194   epsilon: 0.710533900006284    steps: 173    lr: 4e-05     evaluation reward: 2.51\n","episode: 1289   score: 1.0   memory length: 246364   epsilon: 0.7101973000062913    steps: 170    lr: 4e-05     evaluation reward: 2.48\n","episode: 1290   score: 1.0   memory length: 246516   epsilon: 0.7098963400062979    steps: 152    lr: 4e-05     evaluation reward: 2.47\n","episode: 1291   score: 2.0   memory length: 246715   epsilon: 0.7095023200063064    steps: 199    lr: 4e-05     evaluation reward: 2.48\n","episode: 1292   score: 1.0   memory length: 246867   epsilon: 0.709201360006313    steps: 152    lr: 4e-05     evaluation reward: 2.44\n","episode: 1293   score: 3.0   memory length: 247113   epsilon: 0.7087142800063235    steps: 246    lr: 4e-05     evaluation reward: 2.42\n","episode: 1294   score: 1.0   memory length: 247282   epsilon: 0.7083796600063308    steps: 169    lr: 4e-05     evaluation reward: 2.4\n","episode: 1295   score: 3.0   memory length: 247509   epsilon: 0.7079302000063405    steps: 227    lr: 4e-05     evaluation reward: 2.39\n","episode: 1296   score: 0.0   memory length: 247632   epsilon: 0.7076866600063458    steps: 123    lr: 4e-05     evaluation reward: 2.37\n","episode: 1297   score: 4.0   memory length: 247910   epsilon: 0.7071362200063578    steps: 278    lr: 4e-05     evaluation reward: 2.37\n","episode: 1298   score: 1.0   memory length: 248080   epsilon: 0.7067996200063651    steps: 170    lr: 4e-05     evaluation reward: 2.35\n","episode: 1299   score: 3.0   memory length: 248327   epsilon: 0.7063105600063757    steps: 247    lr: 4e-05     evaluation reward: 2.35\n","episode: 1300   score: 0.0   memory length: 248451   epsilon: 0.706065040006381    steps: 124    lr: 4e-05     evaluation reward: 2.31\n","episode: 1301   score: 3.0   memory length: 248682   epsilon: 0.705607660006391    steps: 231    lr: 4e-05     evaluation reward: 2.32\n","episode: 1302   score: 3.0   memory length: 248929   epsilon: 0.7051186000064016    steps: 247    lr: 4e-05     evaluation reward: 2.31\n","episode: 1303   score: 2.0   memory length: 249127   epsilon: 0.7047265600064101    steps: 198    lr: 4e-05     evaluation reward: 2.31\n","episode: 1304   score: 4.0   memory length: 249424   epsilon: 0.7041385000064229    steps: 297    lr: 4e-05     evaluation reward: 2.32\n","episode: 1305   score: 3.0   memory length: 249690   epsilon: 0.7036118200064343    steps: 266    lr: 4e-05     evaluation reward: 2.32\n","episode: 1306   score: 4.0   memory length: 249949   epsilon: 0.7030990000064454    steps: 259    lr: 4e-05     evaluation reward: 2.34\n","episode: 1307   score: 3.0   memory length: 250176   epsilon: 0.7026495400064552    steps: 227    lr: 4e-05     evaluation reward: 2.37\n","episode: 1308   score: 2.0   memory length: 250357   epsilon: 0.702291160006463    steps: 181    lr: 4e-05     evaluation reward: 2.36\n","episode: 1309   score: 1.0   memory length: 250509   epsilon: 0.7019902000064695    steps: 152    lr: 4e-05     evaluation reward: 2.37\n","episode: 1310   score: 4.0   memory length: 250786   epsilon: 0.7014417400064814    steps: 277    lr: 4e-05     evaluation reward: 2.36\n","episode: 1311   score: 3.0   memory length: 251037   epsilon: 0.7009447600064922    steps: 251    lr: 4e-05     evaluation reward: 2.36\n","episode: 1312   score: 6.0   memory length: 251392   epsilon: 0.7002418600065075    steps: 355    lr: 4e-05     evaluation reward: 2.39\n","episode: 1313   score: 1.0   memory length: 251562   epsilon: 0.6999052600065148    steps: 170    lr: 4e-05     evaluation reward: 2.37\n","episode: 1314   score: 7.0   memory length: 251811   epsilon: 0.6994122400065255    steps: 249    lr: 4e-05     evaluation reward: 2.41\n","episode: 1315   score: 4.0   memory length: 252089   epsilon: 0.6988618000065374    steps: 278    lr: 4e-05     evaluation reward: 2.42\n","episode: 1316   score: 4.0   memory length: 252363   epsilon: 0.6983192800065492    steps: 274    lr: 4e-05     evaluation reward: 2.44\n","episode: 1317   score: 5.0   memory length: 252693   epsilon: 0.6976658800065634    steps: 330    lr: 4e-05     evaluation reward: 2.48\n","episode: 1318   score: 2.0   memory length: 252894   epsilon: 0.697267900006572    steps: 201    lr: 4e-05     evaluation reward: 2.47\n","episode: 1319   score: 2.0   memory length: 253095   epsilon: 0.6968699200065807    steps: 201    lr: 4e-05     evaluation reward: 2.49\n","episode: 1320   score: 1.0   memory length: 253247   epsilon: 0.6965689600065872    steps: 152    lr: 4e-05     evaluation reward: 2.5\n","episode: 1321   score: 6.0   memory length: 253599   epsilon: 0.6958720000066023    steps: 352    lr: 4e-05     evaluation reward: 2.53\n","episode: 1322   score: 3.0   memory length: 253848   epsilon: 0.695378980006613    steps: 249    lr: 4e-05     evaluation reward: 2.51\n","episode: 1323   score: 3.0   memory length: 254077   epsilon: 0.6949255600066229    steps: 229    lr: 4e-05     evaluation reward: 2.51\n","episode: 1324   score: 8.0   memory length: 254502   epsilon: 0.6940840600066411    steps: 425    lr: 4e-05     evaluation reward: 2.58\n","episode: 1325   score: 2.0   memory length: 254703   epsilon: 0.6936860800066498    steps: 201    lr: 4e-05     evaluation reward: 2.55\n","episode: 1326   score: 6.0   memory length: 255059   epsilon: 0.6929812000066651    steps: 356    lr: 4e-05     evaluation reward: 2.59\n","episode: 1327   score: 1.0   memory length: 255232   epsilon: 0.6926386600066725    steps: 173    lr: 4e-05     evaluation reward: 2.57\n","episode: 1328   score: 2.0   memory length: 255430   epsilon: 0.692246620006681    steps: 198    lr: 4e-05     evaluation reward: 2.56\n","episode: 1329   score: 1.0   memory length: 255581   epsilon: 0.6919476400066875    steps: 151    lr: 4e-05     evaluation reward: 2.56\n","episode: 1330   score: 5.0   memory length: 255890   epsilon: 0.6913358200067008    steps: 309    lr: 4e-05     evaluation reward: 2.59\n","episode: 1331   score: 3.0   memory length: 256101   epsilon: 0.6909180400067099    steps: 211    lr: 4e-05     evaluation reward: 2.6\n","episode: 1332   score: 1.0   memory length: 256253   epsilon: 0.6906170800067164    steps: 152    lr: 4e-05     evaluation reward: 2.58\n","episode: 1333   score: 5.0   memory length: 256617   epsilon: 0.689896360006732    steps: 364    lr: 4e-05     evaluation reward: 2.61\n","episode: 1334   score: 2.0   memory length: 256799   epsilon: 0.6895360000067399    steps: 182    lr: 4e-05     evaluation reward: 2.61\n","episode: 1335   score: 1.0   memory length: 256951   epsilon: 0.6892350400067464    steps: 152    lr: 4e-05     evaluation reward: 2.6\n","episode: 1336   score: 1.0   memory length: 257121   epsilon: 0.6888984400067537    steps: 170    lr: 4e-05     evaluation reward: 2.58\n","episode: 1337   score: 6.0   memory length: 257502   epsilon: 0.6881440600067701    steps: 381    lr: 4e-05     evaluation reward: 2.63\n","episode: 1338   score: 5.0   memory length: 257810   epsilon: 0.6875342200067833    steps: 308    lr: 4e-05     evaluation reward: 2.65\n","episode: 1339   score: 1.0   memory length: 257962   epsilon: 0.6872332600067899    steps: 152    lr: 4e-05     evaluation reward: 2.66\n","episode: 1340   score: 3.0   memory length: 258207   epsilon: 0.6867481600068004    steps: 245    lr: 4e-05     evaluation reward: 2.69\n","episode: 1341   score: 5.0   memory length: 258517   epsilon: 0.6861343600068137    steps: 310    lr: 4e-05     evaluation reward: 2.73\n","episode: 1342   score: 3.0   memory length: 258746   epsilon: 0.6856809400068236    steps: 229    lr: 4e-05     evaluation reward: 2.72\n","episode: 1343   score: 4.0   memory length: 259002   epsilon: 0.6851740600068346    steps: 256    lr: 4e-05     evaluation reward: 2.73\n","episode: 1344   score: 2.0   memory length: 259200   epsilon: 0.6847820200068431    steps: 198    lr: 4e-05     evaluation reward: 2.73\n","episode: 1345   score: 3.0   memory length: 259448   epsilon: 0.6842909800068537    steps: 248    lr: 4e-05     evaluation reward: 2.75\n","episode: 1346   score: 2.0   memory length: 259667   epsilon: 0.6838573600068631    steps: 219    lr: 4e-05     evaluation reward: 2.76\n","episode: 1347   score: 3.0   memory length: 259914   epsilon: 0.6833683000068738    steps: 247    lr: 4e-05     evaluation reward: 2.77\n","episode: 1348   score: 1.0   memory length: 260066   epsilon: 0.6830673400068803    steps: 152    lr: 4e-05     evaluation reward: 2.74\n","episode: 1349   score: 4.0   memory length: 260360   epsilon: 0.6824852200068929    steps: 294    lr: 4e-05     evaluation reward: 2.75\n","episode: 1350   score: 2.0   memory length: 260542   epsilon: 0.6821248600069008    steps: 182    lr: 4e-05     evaluation reward: 2.75\n","episode: 1351   score: 2.0   memory length: 260762   epsilon: 0.6816892600069102    steps: 220    lr: 4e-05     evaluation reward: 2.75\n","episode: 1352   score: 2.0   memory length: 260962   epsilon: 0.6812932600069188    steps: 200    lr: 4e-05     evaluation reward: 2.74\n","episode: 1353   score: 4.0   memory length: 261220   epsilon: 0.6807824200069299    steps: 258    lr: 4e-05     evaluation reward: 2.76\n","episode: 1354   score: 0.0   memory length: 261344   epsilon: 0.6805369000069352    steps: 124    lr: 4e-05     evaluation reward: 2.76\n","episode: 1355   score: 1.0   memory length: 261516   epsilon: 0.6801963400069426    steps: 172    lr: 4e-05     evaluation reward: 2.76\n","episode: 1356   score: 6.0   memory length: 261913   epsilon: 0.6794102800069597    steps: 397    lr: 4e-05     evaluation reward: 2.8\n","episode: 1357   score: 2.0   memory length: 262132   epsilon: 0.6789766600069691    steps: 219    lr: 4e-05     evaluation reward: 2.78\n","episode: 1358   score: 3.0   memory length: 262383   epsilon: 0.6784796800069799    steps: 251    lr: 4e-05     evaluation reward: 2.76\n","episode: 1359   score: 3.0   memory length: 262616   epsilon: 0.6780183400069899    steps: 233    lr: 4e-05     evaluation reward: 2.78\n","episode: 1360   score: 1.0   memory length: 262788   epsilon: 0.6776777800069973    steps: 172    lr: 4e-05     evaluation reward: 2.77\n","episode: 1361   score: 4.0   memory length: 263045   epsilon: 0.6771689200070083    steps: 257    lr: 4e-05     evaluation reward: 2.81\n","episode: 1362   score: 3.0   memory length: 263278   epsilon: 0.6767075800070184    steps: 233    lr: 4e-05     evaluation reward: 2.83\n","episode: 1363   score: 4.0   memory length: 263536   epsilon: 0.6761967400070295    steps: 258    lr: 4e-05     evaluation reward: 2.82\n","episode: 1364   score: 2.0   memory length: 263735   epsilon: 0.675802720007038    steps: 199    lr: 4e-05     evaluation reward: 2.78\n","episode: 1365   score: 3.0   memory length: 263985   epsilon: 0.6753077200070488    steps: 250    lr: 4e-05     evaluation reward: 2.79\n","episode: 1366   score: 4.0   memory length: 264262   epsilon: 0.6747592600070607    steps: 277    lr: 4e-05     evaluation reward: 2.79\n","episode: 1367   score: 4.0   memory length: 264540   epsilon: 0.6742088200070726    steps: 278    lr: 4e-05     evaluation reward: 2.82\n","episode: 1368   score: 4.0   memory length: 264822   epsilon: 0.6736504600070847    steps: 282    lr: 4e-05     evaluation reward: 2.85\n","episode: 1369   score: 4.0   memory length: 265078   epsilon: 0.6731435800070957    steps: 256    lr: 4e-05     evaluation reward: 2.86\n","episode: 1370   score: 2.0   memory length: 265279   epsilon: 0.6727456000071044    steps: 201    lr: 4e-05     evaluation reward: 2.85\n","episode: 1371   score: 5.0   memory length: 265623   epsilon: 0.6720644800071192    steps: 344    lr: 4e-05     evaluation reward: 2.89\n","episode: 1372   score: 3.0   memory length: 265832   epsilon: 0.6716506600071281    steps: 209    lr: 4e-05     evaluation reward: 2.91\n","episode: 1373   score: 6.0   memory length: 266187   epsilon: 0.6709477600071434    steps: 355    lr: 4e-05     evaluation reward: 2.94\n","episode: 1374   score: 3.0   memory length: 266434   epsilon: 0.670458700007154    steps: 247    lr: 4e-05     evaluation reward: 2.93\n","episode: 1375   score: 4.0   memory length: 266710   epsilon: 0.6699122200071659    steps: 276    lr: 4e-05     evaluation reward: 2.96\n","episode: 1376   score: 2.0   memory length: 266932   epsilon: 0.6694726600071754    steps: 222    lr: 4e-05     evaluation reward: 2.96\n","episode: 1377   score: 3.0   memory length: 267164   epsilon: 0.6690133000071854    steps: 232    lr: 4e-05     evaluation reward: 2.94\n","episode: 1378   score: 3.0   memory length: 267411   epsilon: 0.668524240007196    steps: 247    lr: 4e-05     evaluation reward: 2.95\n","episode: 1379   score: 4.0   memory length: 267705   epsilon: 0.6679421200072087    steps: 294    lr: 4e-05     evaluation reward: 2.97\n","episode: 1380   score: 3.0   memory length: 267952   epsilon: 0.6674530600072193    steps: 247    lr: 4e-05     evaluation reward: 2.97\n","episode: 1381   score: 5.0   memory length: 268261   epsilon: 0.6668412400072325    steps: 309    lr: 4e-05     evaluation reward: 3.0\n","episode: 1382   score: 2.0   memory length: 268460   epsilon: 0.6664472200072411    steps: 199    lr: 4e-05     evaluation reward: 2.92\n","episode: 1383   score: 2.0   memory length: 268658   epsilon: 0.6660551800072496    steps: 198    lr: 4e-05     evaluation reward: 2.93\n","episode: 1384   score: 4.0   memory length: 268970   epsilon: 0.665437420007263    steps: 312    lr: 4e-05     evaluation reward: 2.92\n","episode: 1385   score: 0.0   memory length: 269093   epsilon: 0.6651938800072683    steps: 123    lr: 4e-05     evaluation reward: 2.89\n","episode: 1386   score: 2.0   memory length: 269275   epsilon: 0.6648335200072761    steps: 182    lr: 4e-05     evaluation reward: 2.9\n","episode: 1387   score: 1.0   memory length: 269427   epsilon: 0.6645325600072827    steps: 152    lr: 4e-05     evaluation reward: 2.89\n","episode: 1388   score: 5.0   memory length: 269753   epsilon: 0.6638870800072967    steps: 326    lr: 4e-05     evaluation reward: 2.93\n","episode: 1389   score: 3.0   memory length: 269982   epsilon: 0.6634336600073065    steps: 229    lr: 4e-05     evaluation reward: 2.95\n","episode: 1390   score: 2.0   memory length: 270183   epsilon: 0.6630356800073152    steps: 201    lr: 4e-05     evaluation reward: 2.96\n","episode: 1391   score: 4.0   memory length: 270462   epsilon: 0.6624832600073272    steps: 279    lr: 4e-05     evaluation reward: 2.98\n","episode: 1392   score: 1.0   memory length: 270614   epsilon: 0.6621823000073337    steps: 152    lr: 4e-05     evaluation reward: 2.98\n","episode: 1393   score: 2.0   memory length: 270813   epsilon: 0.6617882800073422    steps: 199    lr: 4e-05     evaluation reward: 2.97\n","episode: 1394   score: 3.0   memory length: 271047   epsilon: 0.6613249600073523    steps: 234    lr: 4e-05     evaluation reward: 2.99\n","episode: 1395   score: 1.0   memory length: 271218   epsilon: 0.6609863800073597    steps: 171    lr: 4e-05     evaluation reward: 2.97\n","episode: 1396   score: 7.0   memory length: 271617   epsilon: 0.6601963600073768    steps: 399    lr: 4e-05     evaluation reward: 3.04\n","episode: 1397   score: 4.0   memory length: 271933   epsilon: 0.6595706800073904    steps: 316    lr: 4e-05     evaluation reward: 3.04\n","episode: 1398   score: 3.0   memory length: 272163   epsilon: 0.6591152800074003    steps: 230    lr: 4e-05     evaluation reward: 3.06\n","episode: 1399   score: 2.0   memory length: 272362   epsilon: 0.6587212600074088    steps: 199    lr: 4e-05     evaluation reward: 3.05\n","episode: 1400   score: 5.0   memory length: 272668   epsilon: 0.658115380007422    steps: 306    lr: 4e-05     evaluation reward: 3.1\n","episode: 1401   score: 0.0   memory length: 272792   epsilon: 0.6578698600074273    steps: 124    lr: 4e-05     evaluation reward: 3.07\n","episode: 1402   score: 2.0   memory length: 272992   epsilon: 0.6574738600074359    steps: 200    lr: 4e-05     evaluation reward: 3.06\n","episode: 1403   score: 3.0   memory length: 273258   epsilon: 0.6569471800074473    steps: 266    lr: 4e-05     evaluation reward: 3.07\n","episode: 1404   score: 3.0   memory length: 273472   epsilon: 0.6565234600074565    steps: 214    lr: 4e-05     evaluation reward: 3.06\n","episode: 1405   score: 1.0   memory length: 273643   epsilon: 0.6561848800074639    steps: 171    lr: 4e-05     evaluation reward: 3.04\n","episode: 1406   score: 3.0   memory length: 273857   epsilon: 0.6557611600074731    steps: 214    lr: 4e-05     evaluation reward: 3.03\n","episode: 1407   score: 1.0   memory length: 274009   epsilon: 0.6554602000074796    steps: 152    lr: 4e-05     evaluation reward: 3.01\n","episode: 1408   score: 3.0   memory length: 274218   epsilon: 0.6550463800074886    steps: 209    lr: 4e-05     evaluation reward: 3.02\n","episode: 1409   score: 6.0   memory length: 274612   epsilon: 0.6542662600075055    steps: 394    lr: 4e-05     evaluation reward: 3.07\n","episode: 1410   score: 2.0   memory length: 274813   epsilon: 0.6538682800075142    steps: 201    lr: 4e-05     evaluation reward: 3.05\n","episode: 1411   score: 1.0   memory length: 274983   epsilon: 0.6535316800075215    steps: 170    lr: 4e-05     evaluation reward: 3.03\n","episode: 1412   score: 8.0   memory length: 275457   epsilon: 0.6525931600075419    steps: 474    lr: 4e-05     evaluation reward: 3.05\n","episode: 1413   score: 2.0   memory length: 275640   epsilon: 0.6522308200075497    steps: 183    lr: 4e-05     evaluation reward: 3.06\n","episode: 1414   score: 4.0   memory length: 275937   epsilon: 0.6516427600075625    steps: 297    lr: 4e-05     evaluation reward: 3.03\n","episode: 1415   score: 7.0   memory length: 276318   epsilon: 0.6508883800075789    steps: 381    lr: 4e-05     evaluation reward: 3.06\n","episode: 1416   score: 1.0   memory length: 276489   epsilon: 0.6505498000075862    steps: 171    lr: 4e-05     evaluation reward: 3.03\n","episode: 1417   score: 3.0   memory length: 276735   epsilon: 0.6500627200075968    steps: 246    lr: 4e-05     evaluation reward: 3.01\n","episode: 1418   score: 5.0   memory length: 277060   epsilon: 0.6494192200076108    steps: 325    lr: 4e-05     evaluation reward: 3.04\n","episode: 1419   score: 3.0   memory length: 277290   epsilon: 0.6489638200076207    steps: 230    lr: 4e-05     evaluation reward: 3.05\n","episode: 1420   score: 3.0   memory length: 277518   epsilon: 0.6485123800076305    steps: 228    lr: 4e-05     evaluation reward: 3.07\n","episode: 1421   score: 4.0   memory length: 277815   epsilon: 0.6479243200076432    steps: 297    lr: 4e-05     evaluation reward: 3.05\n","episode: 1422   score: 3.0   memory length: 278061   epsilon: 0.6474372400076538    steps: 246    lr: 4e-05     evaluation reward: 3.05\n","episode: 1423   score: 2.0   memory length: 278280   epsilon: 0.6470036200076632    steps: 219    lr: 4e-05     evaluation reward: 3.04\n","episode: 1424   score: 1.0   memory length: 278453   epsilon: 0.6466610800076706    steps: 173    lr: 4e-05     evaluation reward: 2.97\n","episode: 1425   score: 2.0   memory length: 278652   epsilon: 0.6462670600076792    steps: 199    lr: 4e-05     evaluation reward: 2.97\n","episode: 1426   score: 2.0   memory length: 278853   epsilon: 0.6458690800076878    steps: 201    lr: 4e-05     evaluation reward: 2.93\n","episode: 1427   score: 0.0   memory length: 278977   epsilon: 0.6456235600076932    steps: 124    lr: 4e-05     evaluation reward: 2.92\n","episode: 1428   score: 4.0   memory length: 279237   epsilon: 0.6451087600077043    steps: 260    lr: 4e-05     evaluation reward: 2.94\n","episode: 1429   score: 8.0   memory length: 279655   epsilon: 0.6442811200077223    steps: 418    lr: 4e-05     evaluation reward: 3.01\n","episode: 1430   score: 4.0   memory length: 279914   epsilon: 0.6437683000077334    steps: 259    lr: 4e-05     evaluation reward: 3.0\n","episode: 1431   score: 2.0   memory length: 280112   epsilon: 0.643376260007742    steps: 198    lr: 4e-05     evaluation reward: 2.99\n","episode: 1432   score: 6.0   memory length: 280482   epsilon: 0.6426436600077579    steps: 370    lr: 4e-05     evaluation reward: 3.04\n","episode: 1433   score: 2.0   memory length: 280701   epsilon: 0.6422100400077673    steps: 219    lr: 4e-05     evaluation reward: 3.01\n","episode: 1434   score: 4.0   memory length: 280996   epsilon: 0.64162594000778    steps: 295    lr: 4e-05     evaluation reward: 3.03\n","episode: 1435   score: 4.0   memory length: 281293   epsilon: 0.6410378800077927    steps: 297    lr: 4e-05     evaluation reward: 3.06\n","episode: 1436   score: 5.0   memory length: 281611   epsilon: 0.6404082400078064    steps: 318    lr: 4e-05     evaluation reward: 3.1\n","episode: 1437   score: 4.0   memory length: 281905   epsilon: 0.639826120007819    steps: 294    lr: 4e-05     evaluation reward: 3.08\n","episode: 1438   score: 4.0   memory length: 282181   epsilon: 0.6392796400078309    steps: 276    lr: 4e-05     evaluation reward: 3.07\n","episode: 1439   score: 3.0   memory length: 282392   epsilon: 0.63886186000784    steps: 211    lr: 4e-05     evaluation reward: 3.09\n","episode: 1440   score: 4.0   memory length: 282668   epsilon: 0.6383153800078518    steps: 276    lr: 4e-05     evaluation reward: 3.1\n","episode: 1441   score: 2.0   memory length: 282850   epsilon: 0.6379550200078596    steps: 182    lr: 4e-05     evaluation reward: 3.07\n","episode: 1442   score: 2.0   memory length: 283048   epsilon: 0.6375629800078682    steps: 198    lr: 4e-05     evaluation reward: 3.06\n","episode: 1443   score: 4.0   memory length: 283325   epsilon: 0.6370145200078801    steps: 277    lr: 4e-05     evaluation reward: 3.06\n","episode: 1444   score: 5.0   memory length: 283689   epsilon: 0.6362938000078957    steps: 364    lr: 4e-05     evaluation reward: 3.09\n","episode: 1445   score: 8.0   memory length: 284070   epsilon: 0.6355394200079121    steps: 381    lr: 4e-05     evaluation reward: 3.14\n","episode: 1446   score: 1.0   memory length: 284240   epsilon: 0.6352028200079194    steps: 170    lr: 4e-05     evaluation reward: 3.13\n","episode: 1447   score: 0.0   memory length: 284364   epsilon: 0.6349573000079247    steps: 124    lr: 4e-05     evaluation reward: 3.1\n","episode: 1448   score: 0.0   memory length: 284488   epsilon: 0.63471178000793    steps: 124    lr: 4e-05     evaluation reward: 3.09\n","episode: 1449   score: 5.0   memory length: 284820   epsilon: 0.6340544200079443    steps: 332    lr: 4e-05     evaluation reward: 3.1\n","episode: 1450   score: 3.0   memory length: 285071   epsilon: 0.6335574400079551    steps: 251    lr: 4e-05     evaluation reward: 3.11\n","episode: 1451   score: 6.0   memory length: 285424   epsilon: 0.6328585000079703    steps: 353    lr: 4e-05     evaluation reward: 3.15\n","episode: 1452   score: 4.0   memory length: 285720   epsilon: 0.632272420007983    steps: 296    lr: 4e-05     evaluation reward: 3.17\n","episode: 1453   score: 3.0   memory length: 285967   epsilon: 0.6317833600079936    steps: 247    lr: 4e-05     evaluation reward: 3.16\n","episode: 1454   score: 2.0   memory length: 286166   epsilon: 0.6313893400080022    steps: 199    lr: 4e-05     evaluation reward: 3.18\n","episode: 1455   score: 6.0   memory length: 286521   epsilon: 0.6306864400080174    steps: 355    lr: 4e-05     evaluation reward: 3.23\n","episode: 1456   score: 10.0   memory length: 287047   epsilon: 0.62964496000804    steps: 526    lr: 4e-05     evaluation reward: 3.27\n","episode: 1457   score: 5.0   memory length: 287354   epsilon: 0.6290371000080532    steps: 307    lr: 4e-05     evaluation reward: 3.3\n","episode: 1458   score: 1.0   memory length: 287524   epsilon: 0.6287005000080605    steps: 170    lr: 4e-05     evaluation reward: 3.28\n","episode: 1459   score: 3.0   memory length: 287772   epsilon: 0.6282094600080712    steps: 248    lr: 4e-05     evaluation reward: 3.28\n","episode: 1460   score: 4.0   memory length: 288070   epsilon: 0.627619420008084    steps: 298    lr: 4e-05     evaluation reward: 3.31\n","episode: 1461   score: 4.0   memory length: 288364   epsilon: 0.6270373000080967    steps: 294    lr: 4e-05     evaluation reward: 3.31\n","episode: 1462   score: 3.0   memory length: 288613   epsilon: 0.6265442800081074    steps: 249    lr: 4e-05     evaluation reward: 3.31\n","episode: 1463   score: 3.0   memory length: 288860   epsilon: 0.626055220008118    steps: 247    lr: 4e-05     evaluation reward: 3.3\n","episode: 1464   score: 4.0   memory length: 289155   epsilon: 0.6254711200081307    steps: 295    lr: 4e-05     evaluation reward: 3.32\n","episode: 1465   score: 1.0   memory length: 289328   epsilon: 0.6251285800081381    steps: 173    lr: 4e-05     evaluation reward: 3.3\n","episode: 1466   score: 2.0   memory length: 289527   epsilon: 0.6247345600081466    steps: 199    lr: 4e-05     evaluation reward: 3.28\n","episode: 1467   score: 2.0   memory length: 289726   epsilon: 0.6243405400081552    steps: 199    lr: 4e-05     evaluation reward: 3.26\n","episode: 1468   score: 1.0   memory length: 289878   epsilon: 0.6240395800081617    steps: 152    lr: 4e-05     evaluation reward: 3.23\n","episode: 1469   score: 7.0   memory length: 290267   epsilon: 0.6232693600081785    steps: 389    lr: 4e-05     evaluation reward: 3.26\n","episode: 1470   score: 3.0   memory length: 290496   epsilon: 0.6228159400081883    steps: 229    lr: 4e-05     evaluation reward: 3.27\n","episode: 1471   score: 4.0   memory length: 290771   epsilon: 0.6222714400082001    steps: 275    lr: 4e-05     evaluation reward: 3.26\n","episode: 1472   score: 3.0   memory length: 291019   epsilon: 0.6217804000082108    steps: 248    lr: 4e-05     evaluation reward: 3.26\n","episode: 1473   score: 3.0   memory length: 291285   epsilon: 0.6212537200082222    steps: 266    lr: 4e-05     evaluation reward: 3.23\n","episode: 1474   score: 8.0   memory length: 291714   epsilon: 0.6204043000082407    steps: 429    lr: 4e-05     evaluation reward: 3.28\n","episode: 1475   score: 1.0   memory length: 291866   epsilon: 0.6201033400082472    steps: 152    lr: 4e-05     evaluation reward: 3.25\n","episode: 1476   score: 3.0   memory length: 292122   epsilon: 0.6195964600082582    steps: 256    lr: 4e-05     evaluation reward: 3.26\n","episode: 1477   score: 3.0   memory length: 292349   epsilon: 0.619147000008268    steps: 227    lr: 4e-05     evaluation reward: 3.26\n","episode: 1478   score: 2.0   memory length: 292550   epsilon: 0.6187490200082766    steps: 201    lr: 4e-05     evaluation reward: 3.25\n","episode: 1479   score: 2.0   memory length: 292748   epsilon: 0.6183569800082851    steps: 198    lr: 4e-05     evaluation reward: 3.23\n","episode: 1480   score: 3.0   memory length: 292960   epsilon: 0.6179372200082942    steps: 212    lr: 4e-05     evaluation reward: 3.23\n","episode: 1481   score: 4.0   memory length: 293236   epsilon: 0.6173907400083061    steps: 276    lr: 4e-05     evaluation reward: 3.22\n","episode: 1482   score: 3.0   memory length: 293504   epsilon: 0.6168601000083176    steps: 268    lr: 4e-05     evaluation reward: 3.23\n","episode: 1483   score: 4.0   memory length: 293801   epsilon: 0.6162720400083304    steps: 297    lr: 4e-05     evaluation reward: 3.25\n","episode: 1484   score: 4.0   memory length: 294081   epsilon: 0.6157176400083424    steps: 280    lr: 4e-05     evaluation reward: 3.25\n","episode: 1485   score: 4.0   memory length: 294376   epsilon: 0.6151335400083551    steps: 295    lr: 4e-05     evaluation reward: 3.29\n","episode: 1486   score: 5.0   memory length: 294707   epsilon: 0.6144781600083693    steps: 331    lr: 4e-05     evaluation reward: 3.32\n","episode: 1487   score: 8.0   memory length: 295124   epsilon: 0.6136525000083872    steps: 417    lr: 4e-05     evaluation reward: 3.39\n","episode: 1488   score: 6.0   memory length: 295473   epsilon: 0.6129614800084022    steps: 349    lr: 4e-05     evaluation reward: 3.4\n","episode: 1489   score: 3.0   memory length: 295740   epsilon: 0.6124328200084137    steps: 267    lr: 4e-05     evaluation reward: 3.4\n","episode: 1490   score: 6.0   memory length: 296094   epsilon: 0.6117319000084289    steps: 354    lr: 4e-05     evaluation reward: 3.44\n","episode: 1491   score: 6.0   memory length: 296450   epsilon: 0.6110270200084442    steps: 356    lr: 4e-05     evaluation reward: 3.46\n","episode: 1492   score: 3.0   memory length: 296662   epsilon: 0.6106072600084533    steps: 212    lr: 4e-05     evaluation reward: 3.48\n","episode: 1493   score: 7.0   memory length: 297053   epsilon: 0.6098330800084701    steps: 391    lr: 4e-05     evaluation reward: 3.53\n","episode: 1494   score: 5.0   memory length: 297378   epsilon: 0.6091895800084841    steps: 325    lr: 4e-05     evaluation reward: 3.55\n","episode: 1495   score: 3.0   memory length: 297591   epsilon: 0.6087678400084933    steps: 213    lr: 4e-05     evaluation reward: 3.57\n","episode: 1496   score: 2.0   memory length: 297792   epsilon: 0.6083698600085019    steps: 201    lr: 4e-05     evaluation reward: 3.52\n","episode: 1497   score: 3.0   memory length: 298038   epsilon: 0.6078827800085125    steps: 246    lr: 4e-05     evaluation reward: 3.51\n","episode: 1498   score: 7.0   memory length: 298442   epsilon: 0.6070828600085298    steps: 404    lr: 4e-05     evaluation reward: 3.55\n","episode: 1499   score: 6.0   memory length: 298799   epsilon: 0.6063760000085452    steps: 357    lr: 4e-05     evaluation reward: 3.59\n","episode: 1500   score: 2.0   memory length: 298986   epsilon: 0.6060057400085532    steps: 187    lr: 4e-05     evaluation reward: 3.56\n","episode: 1501   score: 5.0   memory length: 299278   epsilon: 0.6054275800085658    steps: 292    lr: 4e-05     evaluation reward: 3.61\n","episode: 1502   score: 3.0   memory length: 299525   epsilon: 0.6049385200085764    steps: 247    lr: 4e-05     evaluation reward: 3.62\n","episode: 1503   score: 10.0   memory length: 300066   epsilon: 0.6038673400085997    steps: 541    lr: 1.6000000000000003e-05     evaluation reward: 3.69\n","episode: 1504   score: 2.0   memory length: 300265   epsilon: 0.6034733200086082    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.68\n","episode: 1505   score: 5.0   memory length: 300583   epsilon: 0.6028436800086219    steps: 318    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n","episode: 1506   score: 3.0   memory length: 300793   epsilon: 0.6024278800086309    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n","episode: 1507   score: 4.0   memory length: 301069   epsilon: 0.6018814000086428    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.75\n","episode: 1508   score: 3.0   memory length: 301319   epsilon: 0.6013864000086535    steps: 250    lr: 1.6000000000000003e-05     evaluation reward: 3.75\n","episode: 1509   score: 2.0   memory length: 301519   epsilon: 0.6009904000086621    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n","episode: 1510   score: 2.0   memory length: 301717   epsilon: 0.6005983600086706    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n","episode: 1511   score: 3.0   memory length: 301968   epsilon: 0.6001013800086814    steps: 251    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n","episode: 1512   score: 7.0   memory length: 302412   epsilon: 0.5992222600087005    steps: 444    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n","episode: 1513   score: 6.0   memory length: 302790   epsilon: 0.5984738200087167    steps: 378    lr: 1.6000000000000003e-05     evaluation reward: 3.76\n","episode: 1514   score: 6.0   memory length: 303185   epsilon: 0.5976917200087337    steps: 395    lr: 1.6000000000000003e-05     evaluation reward: 3.78\n","episode: 1515   score: 6.0   memory length: 303541   epsilon: 0.596986840008749    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n","episode: 1516   score: 7.0   memory length: 303921   epsilon: 0.5962344400087654    steps: 380    lr: 1.6000000000000003e-05     evaluation reward: 3.83\n","episode: 1517   score: 6.0   memory length: 304318   epsilon: 0.5954483800087824    steps: 397    lr: 1.6000000000000003e-05     evaluation reward: 3.86\n","episode: 1518   score: 2.0   memory length: 304517   epsilon: 0.595054360008791    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.83\n","episode: 1519   score: 6.0   memory length: 304858   epsilon: 0.5943791800088056    steps: 341    lr: 1.6000000000000003e-05     evaluation reward: 3.86\n","episode: 1520   score: 5.0   memory length: 305184   epsilon: 0.5937337000088196    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 3.88\n","episode: 1521   score: 6.0   memory length: 305543   epsilon: 0.5930228800088351    steps: 359    lr: 1.6000000000000003e-05     evaluation reward: 3.9\n","episode: 1522   score: 2.0   memory length: 305726   epsilon: 0.5926605400088429    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 3.89\n","episode: 1523   score: 6.0   memory length: 306100   epsilon: 0.591920020008859    steps: 374    lr: 1.6000000000000003e-05     evaluation reward: 3.93\n","episode: 1524   score: 4.0   memory length: 306377   epsilon: 0.5913715600088709    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.96\n","episode: 1525   score: 4.0   memory length: 306633   epsilon: 0.5908646800088819    steps: 256    lr: 1.6000000000000003e-05     evaluation reward: 3.98\n","episode: 1526   score: 4.0   memory length: 306896   epsilon: 0.5903439400088932    steps: 263    lr: 1.6000000000000003e-05     evaluation reward: 4.0\n","episode: 1527   score: 7.0   memory length: 307269   epsilon: 0.5896054000089093    steps: 373    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n","episode: 1528   score: 6.0   memory length: 307614   epsilon: 0.5889223000089241    steps: 345    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n","episode: 1529   score: 7.0   memory length: 308015   epsilon: 0.5881283200089413    steps: 401    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n","episode: 1530   score: 1.0   memory length: 308167   epsilon: 0.5878273600089479    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 4.05\n","episode: 1531   score: 8.0   memory length: 308597   epsilon: 0.5869759600089663    steps: 430    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n","episode: 1532   score: 9.0   memory length: 308998   epsilon: 0.5861819800089836    steps: 401    lr: 1.6000000000000003e-05     evaluation reward: 4.14\n","episode: 1533   score: 3.0   memory length: 309226   epsilon: 0.5857305400089934    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n","episode: 1534   score: 6.0   memory length: 309565   epsilon: 0.585059320009008    steps: 339    lr: 1.6000000000000003e-05     evaluation reward: 4.17\n","episode: 1535   score: 6.0   memory length: 309939   epsilon: 0.584318800009024    steps: 374    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n","episode: 1536   score: 3.0   memory length: 310206   epsilon: 0.5837901400090355    steps: 267    lr: 1.6000000000000003e-05     evaluation reward: 4.17\n","episode: 1537   score: 6.0   memory length: 310549   epsilon: 0.5831110000090503    steps: 343    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n","episode: 1538   score: 5.0   memory length: 310878   epsilon: 0.5824595800090644    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 4.2\n","episode: 1539   score: 5.0   memory length: 311222   epsilon: 0.5817784600090792    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n","episode: 1540   score: 3.0   memory length: 311471   epsilon: 0.5812854400090899    steps: 249    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n","episode: 1541   score: 4.0   memory length: 311733   epsilon: 0.5807666800091011    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 4.23\n","episode: 1542   score: 6.0   memory length: 312071   epsilon: 0.5800974400091157    steps: 338    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n","episode: 1543   score: 3.0   memory length: 312320   epsilon: 0.5796044200091264    steps: 249    lr: 1.6000000000000003e-05     evaluation reward: 4.26\n","episode: 1544   score: 6.0   memory length: 312658   epsilon: 0.5789351800091409    steps: 338    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n","episode: 1545   score: 4.0   memory length: 312918   epsilon: 0.5784203800091521    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.23\n","episode: 1546   score: 6.0   memory length: 313256   epsilon: 0.5777511400091666    steps: 338    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n","episode: 1547   score: 3.0   memory length: 313485   epsilon: 0.5772977200091765    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n","episode: 1548   score: 2.0   memory length: 313684   epsilon: 0.576903700009185    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 4.33\n","episode: 1549   score: 1.0   memory length: 313836   epsilon: 0.5766027400091915    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 4.29\n","episode: 1550   score: 6.0   memory length: 314180   epsilon: 0.5759216200092063    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n","episode: 1551   score: 4.0   memory length: 314477   epsilon: 0.5753335600092191    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n","episode: 1552   score: 3.0   memory length: 314686   epsilon: 0.5749197400092281    steps: 209    lr: 1.6000000000000003e-05     evaluation reward: 4.29\n","episode: 1553   score: 4.0   memory length: 314964   epsilon: 0.57436930000924    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n","episode: 1554   score: 4.0   memory length: 315227   epsilon: 0.5738485600092513    steps: 263    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n","episode: 1555   score: 2.0   memory length: 315410   epsilon: 0.5734862200092592    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n","episode: 1556   score: 9.0   memory length: 315829   epsilon: 0.5726566000092772    steps: 419    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n","episode: 1557   score: 2.0   memory length: 316030   epsilon: 0.5722586200092858    steps: 201    lr: 1.6000000000000003e-05     evaluation reward: 4.24\n","episode: 1558   score: 7.0   memory length: 316404   epsilon: 0.5715181000093019    steps: 374    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n","episode: 1559   score: 5.0   memory length: 316729   epsilon: 0.5708746000093159    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n","episode: 1560   score: 5.0   memory length: 317057   epsilon: 0.57022516000933    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 4.33\n","episode: 1561   score: 4.0   memory length: 317335   epsilon: 0.5696747200093419    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.33\n","episode: 1562   score: 9.0   memory length: 317833   epsilon: 0.5686886800093633    steps: 498    lr: 1.6000000000000003e-05     evaluation reward: 4.39\n","episode: 1563   score: 9.0   memory length: 318311   epsilon: 0.5677422400093839    steps: 478    lr: 1.6000000000000003e-05     evaluation reward: 4.45\n","episode: 1564   score: 6.0   memory length: 318653   epsilon: 0.5670650800093986    steps: 342    lr: 1.6000000000000003e-05     evaluation reward: 4.47\n","episode: 1565   score: 5.0   memory length: 318944   epsilon: 0.5664889000094111    steps: 291    lr: 1.6000000000000003e-05     evaluation reward: 4.51\n","episode: 1566   score: 6.0   memory length: 319318   epsilon: 0.5657483800094272    steps: 374    lr: 1.6000000000000003e-05     evaluation reward: 4.55\n","episode: 1567   score: 5.0   memory length: 319626   epsilon: 0.5651385400094404    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 4.58\n","episode: 1568   score: 8.0   memory length: 320053   epsilon: 0.5642930800094588    steps: 427    lr: 1.6000000000000003e-05     evaluation reward: 4.65\n","episode: 1569   score: 9.0   memory length: 320541   epsilon: 0.5633268400094797    steps: 488    lr: 1.6000000000000003e-05     evaluation reward: 4.67\n","episode: 1570   score: 4.0   memory length: 320838   epsilon: 0.5627387800094925    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 4.68\n","episode: 1571   score: 7.0   memory length: 321261   epsilon: 0.5619012400095107    steps: 423    lr: 1.6000000000000003e-05     evaluation reward: 4.71\n","episode: 1572   score: 2.0   memory length: 321463   epsilon: 0.5615012800095194    steps: 202    lr: 1.6000000000000003e-05     evaluation reward: 4.7\n","episode: 1573   score: 3.0   memory length: 321710   epsilon: 0.56101222000953    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 4.7\n","episode: 1574   score: 6.0   memory length: 322085   epsilon: 0.5602697200095461    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 4.68\n","episode: 1575   score: 3.0   memory length: 322315   epsilon: 0.559814320009556    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.7\n","episode: 1576   score: 5.0   memory length: 322622   epsilon: 0.5592064600095692    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 4.72\n","episode: 1577   score: 10.0   memory length: 323116   epsilon: 0.5582283400095904    steps: 494    lr: 1.6000000000000003e-05     evaluation reward: 4.79\n","episode: 1578   score: 5.0   memory length: 323426   epsilon: 0.5576145400096038    steps: 310    lr: 1.6000000000000003e-05     evaluation reward: 4.82\n","episode: 1579   score: 3.0   memory length: 323638   epsilon: 0.5571947800096129    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 4.83\n","episode: 1580   score: 3.0   memory length: 323887   epsilon: 0.5567017600096236    steps: 249    lr: 1.6000000000000003e-05     evaluation reward: 4.83\n","episode: 1581   score: 2.0   memory length: 324091   epsilon: 0.5562978400096323    steps: 204    lr: 1.6000000000000003e-05     evaluation reward: 4.81\n","episode: 1582   score: 4.0   memory length: 324349   epsilon: 0.5557870000096434    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 4.82\n","episode: 1583   score: 6.0   memory length: 324745   epsilon: 0.5550029200096604    steps: 396    lr: 1.6000000000000003e-05     evaluation reward: 4.84\n","episode: 1584   score: 2.0   memory length: 324926   epsilon: 0.5546445400096682    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 4.82\n","episode: 1585   score: 3.0   memory length: 325175   epsilon: 0.5541515200096789    steps: 249    lr: 1.6000000000000003e-05     evaluation reward: 4.81\n","episode: 1586   score: 8.0   memory length: 325602   epsilon: 0.5533060600096973    steps: 427    lr: 1.6000000000000003e-05     evaluation reward: 4.84\n","episode: 1587   score: 4.0   memory length: 325862   epsilon: 0.5527912600097085    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.8\n","episode: 1588   score: 6.0   memory length: 326217   epsilon: 0.5520883600097237    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 4.8\n","episode: 1589   score: 4.0   memory length: 326478   epsilon: 0.5515715800097349    steps: 261    lr: 1.6000000000000003e-05     evaluation reward: 4.81\n","episode: 1590   score: 7.0   memory length: 326858   epsilon: 0.5508191800097513    steps: 380    lr: 1.6000000000000003e-05     evaluation reward: 4.82\n","episode: 1591   score: 4.0   memory length: 327138   epsilon: 0.5502647800097633    steps: 280    lr: 1.6000000000000003e-05     evaluation reward: 4.8\n","episode: 1592   score: 4.0   memory length: 327437   epsilon: 0.5496727600097762    steps: 299    lr: 1.6000000000000003e-05     evaluation reward: 4.81\n","episode: 1593   score: 10.0   memory length: 327943   epsilon: 0.5486708800097979    steps: 506    lr: 1.6000000000000003e-05     evaluation reward: 4.84\n","episode: 1594   score: 5.0   memory length: 328248   epsilon: 0.548066980009811    steps: 305    lr: 1.6000000000000003e-05     evaluation reward: 4.84\n","episode: 1595   score: 3.0   memory length: 328478   epsilon: 0.5476115800098209    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.84\n","episode: 1596   score: 3.0   memory length: 328707   epsilon: 0.5471581600098308    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.85\n","episode: 1597   score: 4.0   memory length: 328985   epsilon: 0.5466077200098427    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 4.86\n","episode: 1598   score: 4.0   memory length: 329266   epsilon: 0.5460513400098548    steps: 281    lr: 1.6000000000000003e-05     evaluation reward: 4.83\n","episode: 1599   score: 5.0   memory length: 329579   epsilon: 0.5454316000098682    steps: 313    lr: 1.6000000000000003e-05     evaluation reward: 4.82\n","episode: 1600   score: 6.0   memory length: 329953   epsilon: 0.5446910800098843    steps: 374    lr: 1.6000000000000003e-05     evaluation reward: 4.86\n","episode: 1601   score: 4.0   memory length: 330214   epsilon: 0.5441743000098955    steps: 261    lr: 1.6000000000000003e-05     evaluation reward: 4.85\n","episode: 1602   score: 5.0   memory length: 330488   epsilon: 0.5436317800099073    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 4.87\n","episode: 1603   score: 7.0   memory length: 330884   epsilon: 0.5428477000099243    steps: 396    lr: 1.6000000000000003e-05     evaluation reward: 4.84\n","episode: 1604   score: 4.0   memory length: 331164   epsilon: 0.5422933000099364    steps: 280    lr: 1.6000000000000003e-05     evaluation reward: 4.86\n","episode: 1605   score: 2.0   memory length: 331347   epsilon: 0.5419309600099442    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 4.83\n","episode: 1606   score: 4.0   memory length: 331622   epsilon: 0.541386460009956    steps: 275    lr: 1.6000000000000003e-05     evaluation reward: 4.84\n","episode: 1607   score: 6.0   memory length: 332014   epsilon: 0.5406103000099729    steps: 392    lr: 1.6000000000000003e-05     evaluation reward: 4.86\n","episode: 1608   score: 3.0   memory length: 332281   epsilon: 0.5400816400099844    steps: 267    lr: 1.6000000000000003e-05     evaluation reward: 4.86\n","episode: 1609   score: 6.0   memory length: 332622   epsilon: 0.539406460009999    steps: 341    lr: 1.6000000000000003e-05     evaluation reward: 4.9\n","episode: 1610   score: 3.0   memory length: 332832   epsilon: 0.5389906600100081    steps: 210    lr: 1.6000000000000003e-05     evaluation reward: 4.91\n","episode: 1611   score: 9.0   memory length: 333190   epsilon: 0.5382818200100234    steps: 358    lr: 1.6000000000000003e-05     evaluation reward: 4.97\n","episode: 1612   score: 5.0   memory length: 333500   epsilon: 0.5376680200100368    steps: 310    lr: 1.6000000000000003e-05     evaluation reward: 4.95\n","episode: 1613   score: 3.0   memory length: 333730   epsilon: 0.5372126200100467    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.92\n","episode: 1614   score: 3.0   memory length: 333957   epsilon: 0.5367631600100564    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 4.89\n","episode: 1615   score: 9.0   memory length: 334305   epsilon: 0.5360741200100714    steps: 348    lr: 1.6000000000000003e-05     evaluation reward: 4.92\n","episode: 1616   score: 3.0   memory length: 334554   epsilon: 0.5355811000100821    steps: 249    lr: 1.6000000000000003e-05     evaluation reward: 4.88\n","episode: 1617   score: 10.0   memory length: 335095   epsilon: 0.5345099200101053    steps: 541    lr: 1.6000000000000003e-05     evaluation reward: 4.92\n","episode: 1618   score: 8.0   memory length: 335505   epsilon: 0.533698120010123    steps: 410    lr: 1.6000000000000003e-05     evaluation reward: 4.98\n","episode: 1619   score: 3.0   memory length: 335737   epsilon: 0.5332387600101329    steps: 232    lr: 1.6000000000000003e-05     evaluation reward: 4.95\n","episode: 1620   score: 3.0   memory length: 335948   epsilon: 0.532820980010142    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.93\n","episode: 1621   score: 5.0   memory length: 336222   epsilon: 0.5322784600101538    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 4.92\n","episode: 1622   score: 8.0   memory length: 336617   epsilon: 0.5314963600101708    steps: 395    lr: 1.6000000000000003e-05     evaluation reward: 4.98\n","episode: 1623   score: 4.0   memory length: 336896   epsilon: 0.5309439400101827    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 4.96\n","episode: 1624   score: 8.0   memory length: 337337   epsilon: 0.5300707600102017    steps: 441    lr: 1.6000000000000003e-05     evaluation reward: 5.0\n","episode: 1625   score: 11.0   memory length: 337733   epsilon: 0.5292866800102187    steps: 396    lr: 1.6000000000000003e-05     evaluation reward: 5.07\n","episode: 1626   score: 8.0   memory length: 338186   epsilon: 0.5283897400102382    steps: 453    lr: 1.6000000000000003e-05     evaluation reward: 5.11\n","episode: 1627   score: 5.0   memory length: 338516   epsilon: 0.5277363400102524    steps: 330    lr: 1.6000000000000003e-05     evaluation reward: 5.09\n","episode: 1628   score: 4.0   memory length: 338757   epsilon: 0.5272591600102627    steps: 241    lr: 1.6000000000000003e-05     evaluation reward: 5.07\n","episode: 1629   score: 5.0   memory length: 339067   epsilon: 0.5266453600102761    steps: 310    lr: 1.6000000000000003e-05     evaluation reward: 5.05\n","episode: 1630   score: 5.0   memory length: 339396   epsilon: 0.5259939400102902    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 5.09\n","episode: 1631   score: 4.0   memory length: 339675   epsilon: 0.5254415200103022    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 5.05\n","episode: 1632   score: 6.0   memory length: 340033   epsilon: 0.5247326800103176    steps: 358    lr: 1.6000000000000003e-05     evaluation reward: 5.02\n","episode: 1633   score: 7.0   memory length: 340424   epsilon: 0.5239585000103344    steps: 391    lr: 1.6000000000000003e-05     evaluation reward: 5.06\n","episode: 1634   score: 5.0   memory length: 340755   epsilon: 0.5233031200103486    steps: 331    lr: 1.6000000000000003e-05     evaluation reward: 5.05\n","episode: 1635   score: 7.0   memory length: 341130   epsilon: 0.5225606200103647    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 5.06\n","episode: 1636   score: 6.0   memory length: 341434   epsilon: 0.5219587000103778    steps: 304    lr: 1.6000000000000003e-05     evaluation reward: 5.09\n","episode: 1637   score: 4.0   memory length: 341679   epsilon: 0.5214736000103883    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 5.07\n","episode: 1638   score: 5.0   memory length: 341987   epsilon: 0.5208637600104016    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 5.07\n","episode: 1639   score: 8.0   memory length: 342459   epsilon: 0.5199292000104219    steps: 472    lr: 1.6000000000000003e-05     evaluation reward: 5.1\n","episode: 1640   score: 4.0   memory length: 342740   epsilon: 0.5193728200104339    steps: 281    lr: 1.6000000000000003e-05     evaluation reward: 5.11\n","episode: 1641   score: 7.0   memory length: 343117   epsilon: 0.5186263600104501    steps: 377    lr: 1.6000000000000003e-05     evaluation reward: 5.14\n","episode: 1642   score: 4.0   memory length: 343397   epsilon: 0.5180719600104622    steps: 280    lr: 1.6000000000000003e-05     evaluation reward: 5.12\n","episode: 1643   score: 3.0   memory length: 343628   epsilon: 0.5176145800104721    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 5.12\n","episode: 1644   score: 6.0   memory length: 343948   epsilon: 0.5169809800104859    steps: 320    lr: 1.6000000000000003e-05     evaluation reward: 5.12\n","episode: 1645   score: 5.0   memory length: 344257   epsilon: 0.5163691600104992    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 5.13\n","episode: 1646   score: 3.0   memory length: 344509   epsilon: 0.51587020001051    steps: 252    lr: 1.6000000000000003e-05     evaluation reward: 5.1\n","episode: 1647   score: 6.0   memory length: 344864   epsilon: 0.5151673000105252    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 5.13\n","episode: 1648   score: 3.0   memory length: 345078   epsilon: 0.5147435800105344    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 5.14\n","episode: 1649   score: 4.0   memory length: 345321   epsilon: 0.5142624400105449    steps: 243    lr: 1.6000000000000003e-05     evaluation reward: 5.17\n","episode: 1650   score: 2.0   memory length: 345519   epsilon: 0.5138704000105534    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 5.13\n","episode: 1651   score: 5.0   memory length: 345812   epsilon: 0.513290260010566    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 5.14\n","episode: 1652   score: 7.0   memory length: 346239   epsilon: 0.5124448000105843    steps: 427    lr: 1.6000000000000003e-05     evaluation reward: 5.18\n","episode: 1653   score: 7.0   memory length: 346644   epsilon: 0.5116429000106018    steps: 405    lr: 1.6000000000000003e-05     evaluation reward: 5.21\n","episode: 1654   score: 6.0   memory length: 347023   epsilon: 0.510892480010618    steps: 379    lr: 1.6000000000000003e-05     evaluation reward: 5.23\n","episode: 1655   score: 7.0   memory length: 347377   epsilon: 0.5101915600106333    steps: 354    lr: 1.6000000000000003e-05     evaluation reward: 5.28\n","episode: 1656   score: 5.0   memory length: 347722   epsilon: 0.5095084600106481    steps: 345    lr: 1.6000000000000003e-05     evaluation reward: 5.24\n","episode: 1657   score: 7.0   memory length: 348110   epsilon: 0.5087402200106648    steps: 388    lr: 1.6000000000000003e-05     evaluation reward: 5.29\n","episode: 1658   score: 5.0   memory length: 348426   epsilon: 0.5081145400106784    steps: 316    lr: 1.6000000000000003e-05     evaluation reward: 5.27\n","episode: 1659   score: 6.0   memory length: 348805   epsilon: 0.5073641200106946    steps: 379    lr: 1.6000000000000003e-05     evaluation reward: 5.28\n","episode: 1660   score: 5.0   memory length: 349114   epsilon: 0.5067523000107079    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 5.28\n","episode: 1661   score: 7.0   memory length: 349523   epsilon: 0.5059424800107255    steps: 409    lr: 1.6000000000000003e-05     evaluation reward: 5.31\n","episode: 1662   score: 8.0   memory length: 349963   epsilon: 0.5050712800107444    steps: 440    lr: 1.6000000000000003e-05     evaluation reward: 5.3\n","episode: 1663   score: 4.0   memory length: 350241   epsilon: 0.5045208400107564    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 5.25\n","episode: 1664   score: 4.0   memory length: 350502   epsilon: 0.5040040600107676    steps: 261    lr: 1.6000000000000003e-05     evaluation reward: 5.23\n","episode: 1665   score: 6.0   memory length: 350857   epsilon: 0.5033011600107828    steps: 355    lr: 1.6000000000000003e-05     evaluation reward: 5.24\n","episode: 1666   score: 3.0   memory length: 351086   epsilon: 0.5028477400107927    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 5.21\n","episode: 1667   score: 3.0   memory length: 351317   epsilon: 0.5023903600108026    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 5.19\n","episode: 1668   score: 3.0   memory length: 351531   epsilon: 0.5019666400108118    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 5.14\n","episode: 1669   score: 7.0   memory length: 351959   epsilon: 0.5011192000108302    steps: 428    lr: 1.6000000000000003e-05     evaluation reward: 5.12\n","episode: 1670   score: 5.0   memory length: 352284   epsilon: 0.5004757000108442    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 5.13\n","episode: 1671   score: 6.0   memory length: 352648   epsilon: 0.49975498001085294    steps: 364    lr: 1.6000000000000003e-05     evaluation reward: 5.12\n","episode: 1672   score: 7.0   memory length: 353033   epsilon: 0.4989926800108481    steps: 385    lr: 1.6000000000000003e-05     evaluation reward: 5.17\n","episode: 1673   score: 7.0   memory length: 353442   epsilon: 0.498182860010843    steps: 409    lr: 1.6000000000000003e-05     evaluation reward: 5.21\n","episode: 1674   score: 11.0   memory length: 353986   epsilon: 0.4971057400108362    steps: 544    lr: 1.6000000000000003e-05     evaluation reward: 5.26\n","episode: 1675   score: 7.0   memory length: 354394   epsilon: 0.4962979000108311    steps: 408    lr: 1.6000000000000003e-05     evaluation reward: 5.3\n","episode: 1676   score: 6.0   memory length: 354750   epsilon: 0.4955930200108266    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 5.31\n","episode: 1677   score: 5.0   memory length: 355061   epsilon: 0.4949772400108227    steps: 311    lr: 1.6000000000000003e-05     evaluation reward: 5.26\n","episode: 1678   score: 5.0   memory length: 355352   epsilon: 0.49440106001081907    steps: 291    lr: 1.6000000000000003e-05     evaluation reward: 5.26\n","episode: 1679   score: 6.0   memory length: 355693   epsilon: 0.4937258800108148    steps: 341    lr: 1.6000000000000003e-05     evaluation reward: 5.29\n","episode: 1680   score: 7.0   memory length: 356095   epsilon: 0.49292992001080976    steps: 402    lr: 1.6000000000000003e-05     evaluation reward: 5.33\n","episode: 1681   score: 5.0   memory length: 356420   epsilon: 0.4922864200108057    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 5.36\n","episode: 1682   score: 5.0   memory length: 356730   epsilon: 0.4916726200108018    steps: 310    lr: 1.6000000000000003e-05     evaluation reward: 5.37\n","episode: 1683   score: 5.0   memory length: 357040   epsilon: 0.4910588200107979    steps: 310    lr: 1.6000000000000003e-05     evaluation reward: 5.36\n","episode: 1684   score: 7.0   memory length: 357429   epsilon: 0.49028860001079305    steps: 389    lr: 1.6000000000000003e-05     evaluation reward: 5.41\n","episode: 1685   score: 6.0   memory length: 357788   epsilon: 0.48957778001078855    steps: 359    lr: 1.6000000000000003e-05     evaluation reward: 5.44\n","episode: 1686   score: 2.0   memory length: 358008   epsilon: 0.4891421800107858    steps: 220    lr: 1.6000000000000003e-05     evaluation reward: 5.38\n","episode: 1687   score: 5.0   memory length: 358334   epsilon: 0.4884967000107817    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 5.39\n","episode: 1688   score: 5.0   memory length: 358660   epsilon: 0.48785122001077763    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 5.38\n","episode: 1689   score: 5.0   memory length: 358985   epsilon: 0.48720772001077356    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 5.39\n","episode: 1690   score: 4.0   memory length: 359278   epsilon: 0.4866275800107699    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 5.36\n","episode: 1691   score: 8.0   memory length: 359688   epsilon: 0.48581578001076475    steps: 410    lr: 1.6000000000000003e-05     evaluation reward: 5.4\n","episode: 1692   score: 3.0   memory length: 359938   epsilon: 0.4853207800107616    steps: 250    lr: 1.6000000000000003e-05     evaluation reward: 5.39\n","episode: 1693   score: 5.0   memory length: 360261   epsilon: 0.4846812400107576    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 5.34\n","episode: 1694   score: 9.0   memory length: 360755   epsilon: 0.4837031200107514    steps: 494    lr: 1.6000000000000003e-05     evaluation reward: 5.38\n","episode: 1695   score: 5.0   memory length: 361044   epsilon: 0.48313090001074777    steps: 289    lr: 1.6000000000000003e-05     evaluation reward: 5.4\n","episode: 1696   score: 7.0   memory length: 361470   epsilon: 0.48228742001074243    steps: 426    lr: 1.6000000000000003e-05     evaluation reward: 5.44\n","episode: 1697   score: 6.0   memory length: 361821   epsilon: 0.48159244001073803    steps: 351    lr: 1.6000000000000003e-05     evaluation reward: 5.46\n","episode: 1698   score: 10.0   memory length: 362332   epsilon: 0.48058066001073163    steps: 511    lr: 1.6000000000000003e-05     evaluation reward: 5.52\n","episode: 1699   score: 5.0   memory length: 362661   epsilon: 0.4799292400107275    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 5.52\n","episode: 1700   score: 13.0   memory length: 363164   epsilon: 0.4789333000107212    steps: 503    lr: 1.6000000000000003e-05     evaluation reward: 5.59\n","episode: 1701   score: 10.0   memory length: 363683   epsilon: 0.4779056800107147    steps: 519    lr: 1.6000000000000003e-05     evaluation reward: 5.65\n","episode: 1702   score: 9.0   memory length: 364027   epsilon: 0.4772245600107104    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 5.69\n","episode: 1703   score: 5.0   memory length: 364332   epsilon: 0.4766206600107066    steps: 305    lr: 1.6000000000000003e-05     evaluation reward: 5.67\n","episode: 1704   score: 5.0   memory length: 364662   epsilon: 0.47596726001070244    steps: 330    lr: 1.6000000000000003e-05     evaluation reward: 5.68\n","episode: 1705   score: 10.0   memory length: 365053   epsilon: 0.47519308001069754    steps: 391    lr: 1.6000000000000003e-05     evaluation reward: 5.76\n","episode: 1706   score: 4.0   memory length: 365315   epsilon: 0.47467432001069426    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 5.76\n","episode: 1707   score: 4.0   memory length: 365591   epsilon: 0.4741278400106908    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 5.74\n","episode: 1708   score: 4.0   memory length: 365871   epsilon: 0.4735734400106873    steps: 280    lr: 1.6000000000000003e-05     evaluation reward: 5.75\n","episode: 1709   score: 6.0   memory length: 366236   epsilon: 0.4728507400106827    steps: 365    lr: 1.6000000000000003e-05     evaluation reward: 5.75\n","episode: 1710   score: 7.0   memory length: 366663   epsilon: 0.4720052800106774    steps: 427    lr: 1.6000000000000003e-05     evaluation reward: 5.79\n","episode: 1711   score: 5.0   memory length: 366971   epsilon: 0.4713954400106735    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 5.75\n","episode: 1712   score: 6.0   memory length: 367364   epsilon: 0.4706173000106686    steps: 393    lr: 1.6000000000000003e-05     evaluation reward: 5.76\n","episode: 1713   score: 4.0   memory length: 367643   epsilon: 0.4700648800106651    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 5.77\n","episode: 1714   score: 9.0   memory length: 368095   epsilon: 0.46916992001065944    steps: 452    lr: 1.6000000000000003e-05     evaluation reward: 5.83\n","episode: 1715   score: 2.0   memory length: 368278   epsilon: 0.46880758001065714    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 5.76\n","episode: 1716   score: 6.0   memory length: 368637   epsilon: 0.46809676001065265    steps: 359    lr: 1.6000000000000003e-05     evaluation reward: 5.79\n","episode: 1717   score: 7.0   memory length: 369037   epsilon: 0.46730476001064764    steps: 400    lr: 1.6000000000000003e-05     evaluation reward: 5.76\n","episode: 1718   score: 4.0   memory length: 369339   epsilon: 0.46670680001064385    steps: 302    lr: 1.6000000000000003e-05     evaluation reward: 5.72\n","episode: 1719   score: 7.0   memory length: 369711   epsilon: 0.4659702400106392    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 5.76\n","episode: 1720   score: 6.0   memory length: 370052   epsilon: 0.4652950600106349    steps: 341    lr: 1.6000000000000003e-05     evaluation reward: 5.79\n","episode: 1721   score: 8.0   memory length: 370348   epsilon: 0.4647089800106312    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 5.82\n","episode: 1722   score: 6.0   memory length: 370687   epsilon: 0.46403776001062697    steps: 339    lr: 1.6000000000000003e-05     evaluation reward: 5.8\n","episode: 1723   score: 9.0   memory length: 371127   epsilon: 0.46316656001062145    steps: 440    lr: 1.6000000000000003e-05     evaluation reward: 5.85\n","episode: 1724   score: 7.0   memory length: 371548   epsilon: 0.4623329800106162    steps: 421    lr: 1.6000000000000003e-05     evaluation reward: 5.84\n","episode: 1725   score: 4.0   memory length: 371809   epsilon: 0.4618162000106129    steps: 261    lr: 1.6000000000000003e-05     evaluation reward: 5.77\n","episode: 1726   score: 7.0   memory length: 372200   epsilon: 0.461042020010608    steps: 391    lr: 1.6000000000000003e-05     evaluation reward: 5.76\n","episode: 1727   score: 5.0   memory length: 372532   epsilon: 0.46038466001060385    steps: 332    lr: 1.6000000000000003e-05     evaluation reward: 5.76\n","episode: 1728   score: 4.0   memory length: 372795   epsilon: 0.45986392001060056    steps: 263    lr: 1.6000000000000003e-05     evaluation reward: 5.76\n","episode: 1729   score: 7.0   memory length: 373131   epsilon: 0.45919864001059635    steps: 336    lr: 1.6000000000000003e-05     evaluation reward: 5.78\n","episode: 1730   score: 4.0   memory length: 373392   epsilon: 0.4586818600105931    steps: 261    lr: 1.6000000000000003e-05     evaluation reward: 5.77\n","episode: 1731   score: 3.0   memory length: 373606   epsilon: 0.4582581400105904    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 5.76\n","episode: 1732   score: 3.0   memory length: 373818   epsilon: 0.45783838001058774    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 5.73\n","episode: 1733   score: 4.0   memory length: 374061   epsilon: 0.4573572400105847    steps: 243    lr: 1.6000000000000003e-05     evaluation reward: 5.7\n","episode: 1734   score: 10.0   memory length: 374586   epsilon: 0.4563177400105781    steps: 525    lr: 1.6000000000000003e-05     evaluation reward: 5.75\n","episode: 1735   score: 11.0   memory length: 375136   epsilon: 0.45522874001057123    steps: 550    lr: 1.6000000000000003e-05     evaluation reward: 5.79\n","episode: 1736   score: 3.0   memory length: 375345   epsilon: 0.4548149200105686    steps: 209    lr: 1.6000000000000003e-05     evaluation reward: 5.76\n","episode: 1737   score: 8.0   memory length: 375752   epsilon: 0.4540090600105635    steps: 407    lr: 1.6000000000000003e-05     evaluation reward: 5.8\n","episode: 1738   score: 7.0   memory length: 376154   epsilon: 0.4532131000105585    steps: 402    lr: 1.6000000000000003e-05     evaluation reward: 5.82\n","episode: 1739   score: 8.0   memory length: 376627   epsilon: 0.45227656001055255    steps: 473    lr: 1.6000000000000003e-05     evaluation reward: 5.82\n","episode: 1740   score: 3.0   memory length: 376841   epsilon: 0.45185284001054987    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 5.81\n","episode: 1741   score: 5.0   memory length: 377167   epsilon: 0.4512073600105458    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 5.79\n","episode: 1742   score: 5.0   memory length: 377464   epsilon: 0.45061930001054207    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 5.8\n","episode: 1743   score: 6.0   memory length: 377785   epsilon: 0.44998372001053805    steps: 321    lr: 1.6000000000000003e-05     evaluation reward: 5.83\n","episode: 1744   score: 10.0   memory length: 378300   epsilon: 0.4489640200105316    steps: 515    lr: 1.6000000000000003e-05     evaluation reward: 5.87\n","episode: 1745   score: 7.0   memory length: 378706   epsilon: 0.4481601400105265    steps: 406    lr: 1.6000000000000003e-05     evaluation reward: 5.89\n","episode: 1746   score: 9.0   memory length: 379157   epsilon: 0.44726716001052086    steps: 451    lr: 1.6000000000000003e-05     evaluation reward: 5.95\n","episode: 1747   score: 11.0   memory length: 379700   epsilon: 0.44619202001051406    steps: 543    lr: 1.6000000000000003e-05     evaluation reward: 6.0\n","episode: 1748   score: 8.0   memory length: 380176   epsilon: 0.4452495400105081    steps: 476    lr: 1.6000000000000003e-05     evaluation reward: 6.05\n","episode: 1749   score: 6.0   memory length: 380534   epsilon: 0.4445407000105036    steps: 358    lr: 1.6000000000000003e-05     evaluation reward: 6.07\n","episode: 1750   score: 2.0   memory length: 380733   epsilon: 0.4441466800105011    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 6.07\n","episode: 1751   score: 7.0   memory length: 381103   epsilon: 0.4434140800104965    steps: 370    lr: 1.6000000000000003e-05     evaluation reward: 6.09\n","episode: 1752   score: 11.0   memory length: 381529   epsilon: 0.44257060001049114    steps: 426    lr: 1.6000000000000003e-05     evaluation reward: 6.13\n","episode: 1753   score: 10.0   memory length: 382060   epsilon: 0.4415192200104845    steps: 531    lr: 1.6000000000000003e-05     evaluation reward: 6.16\n","episode: 1754   score: 5.0   memory length: 382373   epsilon: 0.44089948001048057    steps: 313    lr: 1.6000000000000003e-05     evaluation reward: 6.15\n","episode: 1755   score: 4.0   memory length: 382634   epsilon: 0.4403827000104773    steps: 261    lr: 1.6000000000000003e-05     evaluation reward: 6.12\n","episode: 1756   score: 9.0   memory length: 383093   epsilon: 0.43947388001047155    steps: 459    lr: 1.6000000000000003e-05     evaluation reward: 6.16\n","episode: 1757   score: 10.0   memory length: 383463   epsilon: 0.4387412800104669    steps: 370    lr: 1.6000000000000003e-05     evaluation reward: 6.19\n","episode: 1758   score: 4.0   memory length: 383741   epsilon: 0.43819084001046343    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 6.18\n","episode: 1759   score: 11.0   memory length: 384356   epsilon: 0.43697314001045573    steps: 615    lr: 1.6000000000000003e-05     evaluation reward: 6.23\n","episode: 1760   score: 6.0   memory length: 384667   epsilon: 0.43635736001045183    steps: 311    lr: 1.6000000000000003e-05     evaluation reward: 6.24\n","episode: 1761   score: 4.0   memory length: 384907   epsilon: 0.4358821600104488    steps: 240    lr: 1.6000000000000003e-05     evaluation reward: 6.21\n","episode: 1762   score: 9.0   memory length: 385374   epsilon: 0.434957500010443    steps: 467    lr: 1.6000000000000003e-05     evaluation reward: 6.22\n","episode: 1763   score: 4.0   memory length: 385651   epsilon: 0.4344090400104395    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 6.22\n","episode: 1764   score: 6.0   memory length: 386010   epsilon: 0.433698220010435    steps: 359    lr: 1.6000000000000003e-05     evaluation reward: 6.24\n","episode: 1765   score: 3.0   memory length: 386239   epsilon: 0.43324480001043214    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 6.21\n","episode: 1766   score: 6.0   memory length: 386616   epsilon: 0.4324983400104274    steps: 377    lr: 1.6000000000000003e-05     evaluation reward: 6.24\n","episode: 1767   score: 3.0   memory length: 386843   epsilon: 0.4320488800104246    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 6.24\n","episode: 1768   score: 6.0   memory length: 387186   epsilon: 0.4313697400104203    steps: 343    lr: 1.6000000000000003e-05     evaluation reward: 6.27\n","episode: 1769   score: 4.0   memory length: 387462   epsilon: 0.4308232600104168    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 6.24\n","episode: 1770   score: 5.0   memory length: 387772   epsilon: 0.43020946001041294    steps: 310    lr: 1.6000000000000003e-05     evaluation reward: 6.24\n","episode: 1771   score: 8.0   memory length: 388215   epsilon: 0.4293323200104074    steps: 443    lr: 1.6000000000000003e-05     evaluation reward: 6.26\n","episode: 1772   score: 3.0   memory length: 388467   epsilon: 0.42883336001040423    steps: 252    lr: 1.6000000000000003e-05     evaluation reward: 6.22\n","episode: 1773   score: 11.0   memory length: 389004   epsilon: 0.4277701000103975    steps: 537    lr: 1.6000000000000003e-05     evaluation reward: 6.26\n","episode: 1774   score: 10.0   memory length: 389583   epsilon: 0.42662368001039025    steps: 579    lr: 1.6000000000000003e-05     evaluation reward: 6.25\n","episode: 1775   score: 8.0   memory length: 390010   epsilon: 0.4257782200103849    steps: 427    lr: 1.6000000000000003e-05     evaluation reward: 6.26\n","episode: 1776   score: 3.0   memory length: 390222   epsilon: 0.42535846001038224    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 6.23\n","episode: 1777   score: 4.0   memory length: 390466   epsilon: 0.4248753400103792    steps: 244    lr: 1.6000000000000003e-05     evaluation reward: 6.22\n","episode: 1778   score: 11.0   memory length: 390954   epsilon: 0.4239091000103731    steps: 488    lr: 1.6000000000000003e-05     evaluation reward: 6.28\n","episode: 1779   score: 3.0   memory length: 391185   epsilon: 0.4234517200103702    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 6.25\n","episode: 1780   score: 5.0   memory length: 391475   epsilon: 0.42287752001036655    steps: 290    lr: 1.6000000000000003e-05     evaluation reward: 6.23\n","episode: 1781   score: 3.0   memory length: 391705   epsilon: 0.42242212001036367    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 6.21\n","episode: 1782   score: 5.0   memory length: 392022   epsilon: 0.4217944600103597    steps: 317    lr: 1.6000000000000003e-05     evaluation reward: 6.21\n","episode: 1783   score: 8.0   memory length: 392451   epsilon: 0.4209450400103543    steps: 429    lr: 1.6000000000000003e-05     evaluation reward: 6.24\n","episode: 1784   score: 4.0   memory length: 392711   epsilon: 0.42043024001035106    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 6.21\n","episode: 1785   score: 6.0   memory length: 393049   epsilon: 0.41976100001034683    steps: 338    lr: 1.6000000000000003e-05     evaluation reward: 6.21\n","episode: 1786   score: 8.0   memory length: 393520   epsilon: 0.41882842001034093    steps: 471    lr: 1.6000000000000003e-05     evaluation reward: 6.27\n","episode: 1787   score: 11.0   memory length: 394072   epsilon: 0.417735460010334    steps: 552    lr: 1.6000000000000003e-05     evaluation reward: 6.33\n","episode: 1788   score: 6.0   memory length: 394445   epsilon: 0.41699692001032934    steps: 373    lr: 1.6000000000000003e-05     evaluation reward: 6.34\n","episode: 1789   score: 8.0   memory length: 394852   epsilon: 0.41619106001032424    steps: 407    lr: 1.6000000000000003e-05     evaluation reward: 6.37\n","episode: 1790   score: 9.0   memory length: 395306   epsilon: 0.41529214001031856    steps: 454    lr: 1.6000000000000003e-05     evaluation reward: 6.42\n","episode: 1791   score: 8.0   memory length: 395715   epsilon: 0.41448232001031343    steps: 409    lr: 1.6000000000000003e-05     evaluation reward: 6.42\n","episode: 1792   score: 8.0   memory length: 396116   epsilon: 0.4136883400103084    steps: 401    lr: 1.6000000000000003e-05     evaluation reward: 6.47\n","episode: 1793   score: 3.0   memory length: 396330   epsilon: 0.4132646200103057    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 6.45\n","episode: 1794   score: 7.0   memory length: 396722   epsilon: 0.4124884600103008    steps: 392    lr: 1.6000000000000003e-05     evaluation reward: 6.43\n","episode: 1795   score: 3.0   memory length: 396972   epsilon: 0.4119934600102977    steps: 250    lr: 1.6000000000000003e-05     evaluation reward: 6.41\n","episode: 1796   score: 6.0   memory length: 397331   epsilon: 0.4112826400102932    steps: 359    lr: 1.6000000000000003e-05     evaluation reward: 6.4\n","episode: 1797   score: 8.0   memory length: 397789   epsilon: 0.41037580001028745    steps: 458    lr: 1.6000000000000003e-05     evaluation reward: 6.42\n","episode: 1798   score: 5.0   memory length: 398096   epsilon: 0.4097679400102836    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 6.37\n","episode: 1799   score: 4.0   memory length: 398359   epsilon: 0.4092472000102803    steps: 263    lr: 1.6000000000000003e-05     evaluation reward: 6.36\n","episode: 1800   score: 4.0   memory length: 398617   epsilon: 0.4087363600102771    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 6.27\n","episode: 1801   score: 3.0   memory length: 398831   epsilon: 0.4083126400102744    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 6.2\n","episode: 1802   score: 5.0   memory length: 399160   epsilon: 0.4076612200102703    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 6.16\n","episode: 1803   score: 12.0   memory length: 399574   epsilon: 0.4068415000102651    steps: 414    lr: 1.6000000000000003e-05     evaluation reward: 6.23\n","episode: 1804   score: 3.0   memory length: 399821   epsilon: 0.406352440010262    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 6.21\n","episode: 1805   score: 11.0   memory length: 400264   epsilon: 0.40547530001025645    steps: 443    lr: 6.400000000000001e-06     evaluation reward: 6.22\n","episode: 1806   score: 7.0   memory length: 400629   epsilon: 0.4047526000102519    steps: 365    lr: 6.400000000000001e-06     evaluation reward: 6.25\n","episode: 1807   score: 6.0   memory length: 401026   epsilon: 0.4039665400102469    steps: 397    lr: 6.400000000000001e-06     evaluation reward: 6.27\n","episode: 1808   score: 8.0   memory length: 401461   epsilon: 0.40310524001024145    steps: 435    lr: 6.400000000000001e-06     evaluation reward: 6.31\n","episode: 1809   score: 8.0   memory length: 401917   epsilon: 0.40220236001023574    steps: 456    lr: 6.400000000000001e-06     evaluation reward: 6.33\n","episode: 1810   score: 4.0   memory length: 402193   epsilon: 0.4016558800102323    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 6.3\n","episode: 1811   score: 9.0   memory length: 402646   epsilon: 0.4007589400102266    steps: 453    lr: 6.400000000000001e-06     evaluation reward: 6.34\n","episode: 1812   score: 5.0   memory length: 402939   epsilon: 0.40017880001022293    steps: 293    lr: 6.400000000000001e-06     evaluation reward: 6.33\n","episode: 1813   score: 3.0   memory length: 403171   epsilon: 0.39971944001022003    steps: 232    lr: 6.400000000000001e-06     evaluation reward: 6.32\n","episode: 1814   score: 9.0   memory length: 403623   epsilon: 0.39882448001021437    steps: 452    lr: 6.400000000000001e-06     evaluation reward: 6.32\n","episode: 1815   score: 7.0   memory length: 404030   epsilon: 0.39801862001020927    steps: 407    lr: 6.400000000000001e-06     evaluation reward: 6.37\n","episode: 1816   score: 7.0   memory length: 404426   epsilon: 0.3972345400102043    steps: 396    lr: 6.400000000000001e-06     evaluation reward: 6.38\n","episode: 1817   score: 9.0   memory length: 404934   epsilon: 0.39622870001019794    steps: 508    lr: 6.400000000000001e-06     evaluation reward: 6.4\n","episode: 1818   score: 3.0   memory length: 405146   epsilon: 0.3958089400101953    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 6.39\n","episode: 1819   score: 7.0   memory length: 405551   epsilon: 0.3950070400101902    steps: 405    lr: 6.400000000000001e-06     evaluation reward: 6.39\n","episode: 1820   score: 5.0   memory length: 405823   epsilon: 0.3944684800101868    steps: 272    lr: 6.400000000000001e-06     evaluation reward: 6.38\n","episode: 1821   score: 3.0   memory length: 406054   epsilon: 0.3940111000101839    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 6.33\n","episode: 1822   score: 9.0   memory length: 406500   epsilon: 0.3931280200101783    steps: 446    lr: 6.400000000000001e-06     evaluation reward: 6.36\n","episode: 1823   score: 9.0   memory length: 406949   epsilon: 0.3922390000101727    steps: 449    lr: 6.400000000000001e-06     evaluation reward: 6.36\n","episode: 1824   score: 7.0   memory length: 407346   epsilon: 0.3914529400101677    steps: 397    lr: 6.400000000000001e-06     evaluation reward: 6.36\n","episode: 1825   score: 5.0   memory length: 407667   epsilon: 0.3908173600101637    steps: 321    lr: 6.400000000000001e-06     evaluation reward: 6.37\n","episode: 1826   score: 2.0   memory length: 407870   epsilon: 0.39041542001016116    steps: 203    lr: 6.400000000000001e-06     evaluation reward: 6.32\n","episode: 1827   score: 6.0   memory length: 408191   epsilon: 0.38977984001015714    steps: 321    lr: 6.400000000000001e-06     evaluation reward: 6.33\n","episode: 1828   score: 4.0   memory length: 408436   epsilon: 0.3892947400101541    steps: 245    lr: 6.400000000000001e-06     evaluation reward: 6.33\n","episode: 1829   score: 9.0   memory length: 408899   epsilon: 0.38837800001014827    steps: 463    lr: 6.400000000000001e-06     evaluation reward: 6.35\n","episode: 1830   score: 10.0   memory length: 409355   epsilon: 0.38747512001014256    steps: 456    lr: 6.400000000000001e-06     evaluation reward: 6.41\n","episode: 1831   score: 16.0   memory length: 409966   epsilon: 0.3862653400101349    steps: 611    lr: 6.400000000000001e-06     evaluation reward: 6.54\n","episode: 1832   score: 9.0   memory length: 410450   epsilon: 0.38530702001012884    steps: 484    lr: 6.400000000000001e-06     evaluation reward: 6.6\n","episode: 1833   score: 9.0   memory length: 410907   epsilon: 0.3844021600101231    steps: 457    lr: 6.400000000000001e-06     evaluation reward: 6.65\n","episode: 1834   score: 6.0   memory length: 411251   epsilon: 0.3837210400101188    steps: 344    lr: 6.400000000000001e-06     evaluation reward: 6.61\n","episode: 1835   score: 5.0   memory length: 411557   epsilon: 0.383115160010115    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 6.55\n","episode: 1836   score: 5.0   memory length: 411845   epsilon: 0.38254492001011137    steps: 288    lr: 6.400000000000001e-06     evaluation reward: 6.57\n","episode: 1837   score: 3.0   memory length: 412057   epsilon: 0.3821251600101087    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 6.52\n","episode: 1838   score: 8.0   memory length: 412459   epsilon: 0.3813292000101037    steps: 402    lr: 6.400000000000001e-06     evaluation reward: 6.53\n","episode: 1839   score: 3.0   memory length: 412671   epsilon: 0.380909440010101    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 6.48\n","episode: 1840   score: 7.0   memory length: 413077   epsilon: 0.38010556001009593    steps: 406    lr: 6.400000000000001e-06     evaluation reward: 6.52\n","episode: 1841   score: 4.0   memory length: 413337   epsilon: 0.3795907600100927    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 6.51\n","episode: 1842   score: 3.0   memory length: 413568   epsilon: 0.3791333800100898    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 6.49\n","episode: 1843   score: 5.0   memory length: 413898   epsilon: 0.37847998001008565    steps: 330    lr: 6.400000000000001e-06     evaluation reward: 6.48\n","episode: 1844   score: 9.0   memory length: 414398   epsilon: 0.3774899800100794    steps: 500    lr: 6.400000000000001e-06     evaluation reward: 6.47\n","episode: 1845   score: 6.0   memory length: 414774   epsilon: 0.3767455000100747    steps: 376    lr: 6.400000000000001e-06     evaluation reward: 6.46\n","episode: 1846   score: 8.0   memory length: 415211   epsilon: 0.3758802400100692    steps: 437    lr: 6.400000000000001e-06     evaluation reward: 6.45\n","episode: 1847   score: 7.0   memory length: 415616   epsilon: 0.3750783400100641    steps: 405    lr: 6.400000000000001e-06     evaluation reward: 6.41\n","episode: 1848   score: 5.0   memory length: 415946   epsilon: 0.37442494001006    steps: 330    lr: 6.400000000000001e-06     evaluation reward: 6.38\n","episode: 1849   score: 5.0   memory length: 416272   epsilon: 0.3737794600100559    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 6.37\n","episode: 1850   score: 7.0   memory length: 416708   epsilon: 0.37291618001005045    steps: 436    lr: 6.400000000000001e-06     evaluation reward: 6.42\n","episode: 1851   score: 5.0   memory length: 416979   epsilon: 0.37237960001004705    steps: 271    lr: 6.400000000000001e-06     evaluation reward: 6.4\n","episode: 1852   score: 9.0   memory length: 417419   epsilon: 0.37150840001004154    steps: 440    lr: 6.400000000000001e-06     evaluation reward: 6.38\n","episode: 1853   score: 8.0   memory length: 417736   epsilon: 0.37088074001003757    steps: 317    lr: 6.400000000000001e-06     evaluation reward: 6.36\n","episode: 1854   score: 6.0   memory length: 418075   epsilon: 0.3702095200100333    steps: 339    lr: 6.400000000000001e-06     evaluation reward: 6.37\n","episode: 1855   score: 4.0   memory length: 418331   epsilon: 0.3697026400100301    steps: 256    lr: 6.400000000000001e-06     evaluation reward: 6.37\n","episode: 1856   score: 6.0   memory length: 418688   epsilon: 0.36899578001002564    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 6.34\n","episode: 1857   score: 6.0   memory length: 419027   epsilon: 0.3683245600100214    steps: 339    lr: 6.400000000000001e-06     evaluation reward: 6.3\n","episode: 1858   score: 7.0   memory length: 419403   epsilon: 0.3675800800100167    steps: 376    lr: 6.400000000000001e-06     evaluation reward: 6.33\n","episode: 1859   score: 5.0   memory length: 419711   epsilon: 0.3669702400100128    steps: 308    lr: 6.400000000000001e-06     evaluation reward: 6.27\n","episode: 1860   score: 4.0   memory length: 419991   epsilon: 0.3664158400100093    steps: 280    lr: 6.400000000000001e-06     evaluation reward: 6.25\n","episode: 1861   score: 10.0   memory length: 420471   epsilon: 0.3654654400100033    steps: 480    lr: 6.400000000000001e-06     evaluation reward: 6.31\n","episode: 1862   score: 7.0   memory length: 420799   epsilon: 0.3648160000099992    steps: 328    lr: 6.400000000000001e-06     evaluation reward: 6.29\n","episode: 1863   score: 4.0   memory length: 421078   epsilon: 0.3642635800099957    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 6.29\n","episode: 1864   score: 3.0   memory length: 421329   epsilon: 0.36376660000999256    steps: 251    lr: 6.400000000000001e-06     evaluation reward: 6.26\n","episode: 1865   score: 8.0   memory length: 421626   epsilon: 0.36317854000998884    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 6.31\n","episode: 1866   score: 18.0   memory length: 422240   epsilon: 0.36196282000998115    steps: 614    lr: 6.400000000000001e-06     evaluation reward: 6.43\n","episode: 1867   score: 3.0   memory length: 422470   epsilon: 0.36150742000997826    steps: 230    lr: 6.400000000000001e-06     evaluation reward: 6.43\n","episode: 1868   score: 11.0   memory length: 423004   epsilon: 0.3604501000099716    steps: 534    lr: 6.400000000000001e-06     evaluation reward: 6.48\n","episode: 1869   score: 10.0   memory length: 423363   epsilon: 0.3597392800099671    steps: 359    lr: 6.400000000000001e-06     evaluation reward: 6.54\n","episode: 1870   score: 4.0   memory length: 423641   epsilon: 0.3591888400099636    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 6.53\n","episode: 1871   score: 11.0   memory length: 424160   epsilon: 0.3581612200099571    steps: 519    lr: 6.400000000000001e-06     evaluation reward: 6.56\n","episode: 1872   score: 4.0   memory length: 424423   epsilon: 0.3576404800099538    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 6.57\n","episode: 1873   score: 4.0   memory length: 424690   epsilon: 0.35711182000995045    steps: 267    lr: 6.400000000000001e-06     evaluation reward: 6.5\n","episode: 1874   score: 8.0   memory length: 425107   epsilon: 0.35628616000994523    steps: 417    lr: 6.400000000000001e-06     evaluation reward: 6.48\n","episode: 1875   score: 6.0   memory length: 425485   epsilon: 0.3555377200099405    steps: 378    lr: 6.400000000000001e-06     evaluation reward: 6.46\n","episode: 1876   score: 8.0   memory length: 425891   epsilon: 0.3547338400099354    steps: 406    lr: 6.400000000000001e-06     evaluation reward: 6.51\n","episode: 1877   score: 9.0   memory length: 426379   epsilon: 0.3537676000099293    steps: 488    lr: 6.400000000000001e-06     evaluation reward: 6.56\n","episode: 1878   score: 6.0   memory length: 426717   epsilon: 0.35309836000992506    steps: 338    lr: 6.400000000000001e-06     evaluation reward: 6.51\n","episode: 1879   score: 10.0   memory length: 427226   epsilon: 0.3520905400099187    steps: 509    lr: 6.400000000000001e-06     evaluation reward: 6.58\n","episode: 1880   score: 3.0   memory length: 427438   epsilon: 0.35167078000991603    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 6.56\n","episode: 1881   score: 8.0   memory length: 427897   epsilon: 0.3507619600099103    steps: 459    lr: 6.400000000000001e-06     evaluation reward: 6.61\n","episode: 1882   score: 9.0   memory length: 428364   epsilon: 0.34983730000990443    steps: 467    lr: 6.400000000000001e-06     evaluation reward: 6.65\n","episode: 1883   score: 8.0   memory length: 428805   epsilon: 0.3489641200098989    steps: 441    lr: 6.400000000000001e-06     evaluation reward: 6.65\n","episode: 1884   score: 8.0   memory length: 429248   epsilon: 0.34808698000989335    steps: 443    lr: 6.400000000000001e-06     evaluation reward: 6.69\n","episode: 1885   score: 3.0   memory length: 429499   epsilon: 0.3475900000098902    steps: 251    lr: 6.400000000000001e-06     evaluation reward: 6.66\n","episode: 1886   score: 5.0   memory length: 429827   epsilon: 0.3469405600098861    steps: 328    lr: 6.400000000000001e-06     evaluation reward: 6.63\n","episode: 1887   score: 15.0   memory length: 430352   epsilon: 0.3459010600098795    steps: 525    lr: 6.400000000000001e-06     evaluation reward: 6.67\n","episode: 1888   score: 4.0   memory length: 430615   epsilon: 0.34538032000987623    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 6.65\n","episode: 1889   score: 4.0   memory length: 430878   epsilon: 0.34485958000987293    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 6.61\n","episode: 1890   score: 10.0   memory length: 431440   epsilon: 0.3437468200098659    steps: 562    lr: 6.400000000000001e-06     evaluation reward: 6.62\n","episode: 1891   score: 8.0   memory length: 431877   epsilon: 0.3428815600098604    steps: 437    lr: 6.400000000000001e-06     evaluation reward: 6.62\n","episode: 1892   score: 8.0   memory length: 432332   epsilon: 0.3419806600098547    steps: 455    lr: 6.400000000000001e-06     evaluation reward: 6.62\n","episode: 1893   score: 7.0   memory length: 432707   epsilon: 0.34123816000985    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 6.66\n","episode: 1894   score: 7.0   memory length: 433087   epsilon: 0.34048576000984526    steps: 380    lr: 6.400000000000001e-06     evaluation reward: 6.66\n","episode: 1895   score: 6.0   memory length: 433465   epsilon: 0.3397373200098405    steps: 378    lr: 6.400000000000001e-06     evaluation reward: 6.69\n","episode: 1896   score: 10.0   memory length: 433982   epsilon: 0.33871366000983405    steps: 517    lr: 6.400000000000001e-06     evaluation reward: 6.73\n","episode: 1897   score: 6.0   memory length: 434322   epsilon: 0.3380404600098298    steps: 340    lr: 6.400000000000001e-06     evaluation reward: 6.71\n","episode: 1898   score: 8.0   memory length: 434746   epsilon: 0.3372009400098245    steps: 424    lr: 6.400000000000001e-06     evaluation reward: 6.74\n","episode: 1899   score: 6.0   memory length: 435120   epsilon: 0.3364604200098198    steps: 374    lr: 6.400000000000001e-06     evaluation reward: 6.76\n","episode: 1900   score: 6.0   memory length: 435451   epsilon: 0.33580504000981565    steps: 331    lr: 6.400000000000001e-06     evaluation reward: 6.78\n","episode: 1901   score: 7.0   memory length: 435826   epsilon: 0.33506254000981095    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 6.82\n","episode: 1902   score: 7.0   memory length: 436213   epsilon: 0.3342962800098061    steps: 387    lr: 6.400000000000001e-06     evaluation reward: 6.84\n","episode: 1903   score: 6.0   memory length: 436536   epsilon: 0.33365674000980206    steps: 323    lr: 6.400000000000001e-06     evaluation reward: 6.78\n","episode: 1904   score: 8.0   memory length: 436976   epsilon: 0.33278554000979654    steps: 440    lr: 6.400000000000001e-06     evaluation reward: 6.83\n","episode: 1905   score: 5.0   memory length: 437283   epsilon: 0.3321776800097927    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 6.77\n","episode: 1906   score: 6.0   memory length: 437608   epsilon: 0.3315341800097886    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 6.76\n","episode: 1907   score: 6.0   memory length: 437964   epsilon: 0.33082930000978417    steps: 356    lr: 6.400000000000001e-06     evaluation reward: 6.76\n","episode: 1908   score: 6.0   memory length: 438310   epsilon: 0.33014422000977983    steps: 346    lr: 6.400000000000001e-06     evaluation reward: 6.74\n","episode: 1909   score: 10.0   memory length: 438814   epsilon: 0.3291463000097735    steps: 504    lr: 6.400000000000001e-06     evaluation reward: 6.76\n","episode: 1910   score: 3.0   memory length: 439026   epsilon: 0.32872654000977086    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 6.75\n","episode: 1911   score: 8.0   memory length: 439424   epsilon: 0.3279385000097659    steps: 398    lr: 6.400000000000001e-06     evaluation reward: 6.74\n","episode: 1912   score: 9.0   memory length: 439946   epsilon: 0.32690494000975934    steps: 522    lr: 6.400000000000001e-06     evaluation reward: 6.78\n","episode: 1913   score: 7.0   memory length: 440325   epsilon: 0.3261545200097546    steps: 379    lr: 6.400000000000001e-06     evaluation reward: 6.82\n","episode: 1914   score: 8.0   memory length: 440698   epsilon: 0.3254159800097499    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 6.81\n","episode: 1915   score: 5.0   memory length: 440994   epsilon: 0.3248299000097462    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 6.79\n","episode: 1916   score: 9.0   memory length: 441470   epsilon: 0.32388742000974025    steps: 476    lr: 6.400000000000001e-06     evaluation reward: 6.81\n","episode: 1917   score: 4.0   memory length: 441749   epsilon: 0.32333500000973675    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 6.76\n","episode: 1918   score: 6.0   memory length: 442132   epsilon: 0.32257666000973195    steps: 383    lr: 6.400000000000001e-06     evaluation reward: 6.79\n","episode: 1919   score: 10.0   memory length: 442499   epsilon: 0.32185000000972736    steps: 367    lr: 6.400000000000001e-06     evaluation reward: 6.82\n","episode: 1920   score: 10.0   memory length: 442845   epsilon: 0.321164920009723    steps: 346    lr: 6.400000000000001e-06     evaluation reward: 6.87\n","episode: 1921   score: 14.0   memory length: 443500   epsilon: 0.3198680200097148    steps: 655    lr: 6.400000000000001e-06     evaluation reward: 6.98\n","episode: 1922   score: 4.0   memory length: 443743   epsilon: 0.31938688000971177    steps: 243    lr: 6.400000000000001e-06     evaluation reward: 6.93\n","episode: 1923   score: 5.0   memory length: 444055   epsilon: 0.31876912000970786    steps: 312    lr: 6.400000000000001e-06     evaluation reward: 6.89\n","episode: 1924   score: 4.0   memory length: 444315   epsilon: 0.3182543200097046    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 6.86\n","episode: 1925   score: 4.0   memory length: 444576   epsilon: 0.31773754000970134    steps: 261    lr: 6.400000000000001e-06     evaluation reward: 6.85\n","episode: 1926   score: 8.0   memory length: 445005   epsilon: 0.31688812000969596    steps: 429    lr: 6.400000000000001e-06     evaluation reward: 6.91\n","episode: 1927   score: 6.0   memory length: 445364   epsilon: 0.31617730000969146    steps: 359    lr: 6.400000000000001e-06     evaluation reward: 6.91\n","episode: 1928   score: 4.0   memory length: 445625   epsilon: 0.3156605200096882    steps: 261    lr: 6.400000000000001e-06     evaluation reward: 6.91\n","episode: 1929   score: 7.0   memory length: 445961   epsilon: 0.314995240009684    steps: 336    lr: 6.400000000000001e-06     evaluation reward: 6.89\n","episode: 1930   score: 7.0   memory length: 446367   epsilon: 0.3141913600096789    steps: 406    lr: 6.400000000000001e-06     evaluation reward: 6.86\n","episode: 1931   score: 6.0   memory length: 446722   epsilon: 0.31348846000967445    steps: 355    lr: 6.400000000000001e-06     evaluation reward: 6.76\n","episode: 1932   score: 9.0   memory length: 447147   epsilon: 0.31264696000966913    steps: 425    lr: 6.400000000000001e-06     evaluation reward: 6.76\n","episode: 1933   score: 5.0   memory length: 447453   epsilon: 0.3120410800096653    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 6.72\n","episode: 1934   score: 7.0   memory length: 447845   epsilon: 0.3112649200096604    steps: 392    lr: 6.400000000000001e-06     evaluation reward: 6.73\n","episode: 1935   score: 14.0   memory length: 448377   epsilon: 0.3102115600096537    steps: 532    lr: 6.400000000000001e-06     evaluation reward: 6.82\n","episode: 1936   score: 5.0   memory length: 448701   epsilon: 0.30957004000964966    steps: 324    lr: 6.400000000000001e-06     evaluation reward: 6.82\n","episode: 1937   score: 3.0   memory length: 448913   epsilon: 0.309150280009647    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 6.82\n","episode: 1938   score: 5.0   memory length: 449242   epsilon: 0.3084988600096429    steps: 329    lr: 6.400000000000001e-06     evaluation reward: 6.79\n","episode: 1939   score: 5.0   memory length: 449550   epsilon: 0.307889020009639    steps: 308    lr: 6.400000000000001e-06     evaluation reward: 6.81\n","episode: 1940   score: 9.0   memory length: 450026   epsilon: 0.30694654000963306    steps: 476    lr: 6.400000000000001e-06     evaluation reward: 6.83\n","episode: 1941   score: 9.0   memory length: 450464   epsilon: 0.3060793000096276    steps: 438    lr: 6.400000000000001e-06     evaluation reward: 6.88\n","episode: 1942   score: 5.0   memory length: 450758   epsilon: 0.3054971800096239    steps: 294    lr: 6.400000000000001e-06     evaluation reward: 6.9\n","episode: 1943   score: 8.0   memory length: 451203   epsilon: 0.3046160800096183    steps: 445    lr: 6.400000000000001e-06     evaluation reward: 6.93\n","episode: 1944   score: 8.0   memory length: 451639   epsilon: 0.30375280000961286    steps: 436    lr: 6.400000000000001e-06     evaluation reward: 6.92\n","episode: 1945   score: 6.0   memory length: 451995   epsilon: 0.3030479200096084    steps: 356    lr: 6.400000000000001e-06     evaluation reward: 6.92\n","episode: 1946   score: 5.0   memory length: 452287   epsilon: 0.30246976000960474    steps: 292    lr: 6.400000000000001e-06     evaluation reward: 6.89\n","episode: 1947   score: 10.0   memory length: 452795   epsilon: 0.3014639200095984    steps: 508    lr: 6.400000000000001e-06     evaluation reward: 6.92\n","episode: 1948   score: 5.0   memory length: 453125   epsilon: 0.30081052000959424    steps: 330    lr: 6.400000000000001e-06     evaluation reward: 6.92\n","episode: 1949   score: 7.0   memory length: 453487   epsilon: 0.3000937600095897    steps: 362    lr: 6.400000000000001e-06     evaluation reward: 6.94\n","episode: 1950   score: 5.0   memory length: 453812   epsilon: 0.29945026000958563    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 6.92\n","episode: 1951   score: 9.0   memory length: 454283   epsilon: 0.29851768000957973    steps: 471    lr: 6.400000000000001e-06     evaluation reward: 6.96\n","episode: 1952   score: 5.0   memory length: 454573   epsilon: 0.2979434800095761    steps: 290    lr: 6.400000000000001e-06     evaluation reward: 6.92\n","episode: 1953   score: 5.0   memory length: 454877   epsilon: 0.2973415600095723    steps: 304    lr: 6.400000000000001e-06     evaluation reward: 6.89\n","episode: 1954   score: 5.0   memory length: 455189   epsilon: 0.2967238000095684    steps: 312    lr: 6.400000000000001e-06     evaluation reward: 6.88\n","episode: 1955   score: 8.0   memory length: 455653   epsilon: 0.29580508000956257    steps: 464    lr: 6.400000000000001e-06     evaluation reward: 6.92\n","episode: 1956   score: 8.0   memory length: 456086   epsilon: 0.29494774000955715    steps: 433    lr: 6.400000000000001e-06     evaluation reward: 6.94\n","episode: 1957   score: 7.0   memory length: 456527   epsilon: 0.2940745600095516    steps: 441    lr: 6.400000000000001e-06     evaluation reward: 6.95\n","episode: 1958   score: 14.0   memory length: 457139   epsilon: 0.29286280000954396    steps: 612    lr: 6.400000000000001e-06     evaluation reward: 7.02\n","episode: 1959   score: 5.0   memory length: 457446   epsilon: 0.2922549400095401    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 7.02\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-589ac8ea6b12>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mframe_next_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe_next_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mterminal_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_live\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlife\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lives'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/CS444/assignment5_materials/utils.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb2gray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mHEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWIDTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reflect'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 warn(\"Anti-aliasing standard deviation greater than zero but \"\n\u001b[1;32m    180\u001b[0m                      \"not down-sampling along all axes\")\n\u001b[0;32m--> 181\u001b[0;31m         image = ndi.gaussian_filter(image, anti_aliasing_sigma,\n\u001b[0m\u001b[1;32m    182\u001b[0m                                     cval=cval, mode=ndi_mode)\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/ndimage/_filters.py\u001b[0m in \u001b[0;36mgaussian_filter\u001b[0;34m(input, sigma, order, output, mode, cval, truncate, radius)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             gaussian_filter1d(input, sigma, axis, order, output,\n\u001b[0m\u001b[1;32m    369\u001b[0m                               mode, cval, truncate, radius=radius)\n\u001b[1;32m    370\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/ndimage/_filters.py\u001b[0m in \u001b[0;36mgaussian_filter1d\u001b[0;34m(input, sigma, axis, order, output, mode, cval, truncate, radius)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Radius must be a nonnegative integer.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;31m# Since we are calling correlate, not convolve, revert the kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gaussian_kernel1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrelate1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/ndimage/_filters.py\u001b[0m in \u001b[0;36m_gaussian_kernel1d\u001b[0;34m(sigma, order, radius)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0mphi_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msigma2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0mphi_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi_x\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mphi_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0morder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     47\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["rewards, episodes = [], []\n","best_eval_reward = 0\n","for e in range(EPISODES):\n","    done = False\n","    score = 0\n","\n","    history = np.zeros([5, 84, 84], dtype=np.uint8)\n","    step = 0\n","    state = env.reset()\n","    next_state = state\n","    life = number_lives\n","\n","    get_init_state(history, state, HISTORY_SIZE)\n","\n","    while not done:\n","        step += 1\n","        frame += 1\n","\n","        # Perform a fire action if ball is no longer on screen to continue onto next life\n","        if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n","            action = 0\n","        else:\n","            action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n","        state = next_state\n","        next_state, reward, done, info = env.step(action + 1)\n","        \n","        frame_next_state = get_frame(next_state)\n","        history[4, :, :] = frame_next_state\n","        terminal_state = check_live(life, info['lives'])\n","\n","        life = info['lives']\n","        r = reward\n","\n","        # Store the transition in memory \n","        agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n","        # Start training after random sample generation\n","        if(frame >= train_frame):\n","            agent.train_policy_net(frame)\n","            # Update the target network only for Double DQN only\n","            if double_dqn and (frame % update_target_network_frequency)== 0:\n","                agent.update_target_net()\n","        score += reward\n","        history[:4, :, :] = history[1:, :, :]\n","            \n","        if done:\n","            evaluation_reward.append(score)\n","            rewards.append(np.mean(evaluation_reward))\n","            episodes.append(e)\n","            pylab.plot(episodes, rewards, 'b')\n","            pylab.xlabel('Episodes')\n","            pylab.ylabel('Rewards') \n","            pylab.title('Episodes vs Reward')\n","            pylab.savefig(\"./save_graph/breakout_dqn.png\") # save graph for training visualization\n","            \n","            # every episode, plot the play time\n","            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n","                  len(agent.memory), \"  epsilon:\", agent.epsilon, \"   steps:\", step,\n","                  \"   lr:\", agent.optimizer.param_groups[0]['lr'], \"    evaluation reward:\", np.mean(evaluation_reward))\n","\n","            # if the mean of scores of last 100 episode is bigger than 5 save model\n","            ### Change this save condition to whatever you prefer ###\n","            if np.mean(evaluation_reward) > 5 and np.mean(evaluation_reward) > best_eval_reward:\n","                torch.save(agent.policy_net, \"./save_model/breakout_dqn.pth\")\n","                best_eval_reward = np.mean(evaluation_reward)\n"]},{"cell_type":"markdown","metadata":{"id":"tM6TC9m6325F"},"source":["# Visualize Agent Performance"]},{"cell_type":"markdown","metadata":{"id":"CVdVPB-I325F"},"source":["BE AWARE THIS CODE BELOW MAY CRASH THE KERNEL IF YOU RUN THE SAME CELL TWICE.\n","\n","Please save your model before running this portion of the code."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"CqSW0oZf325F","executionInfo":{"status":"ok","timestamp":1683346865663,"user_tz":300,"elapsed":154,"user":{"displayName":"Yoon Jae Hwang","userId":"10758045548003148631"}}},"outputs":[],"source":["torch.save(agent.policy_net, \"./save_model/breakout_dqn_latest.pth\")"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"-gByBeSo325F","colab":{"base_uri":"https://localhost:8080/","height":368},"executionInfo":{"status":"error","timestamp":1683346866754,"user_tz":300,"elapsed":102,"user":{"displayName":"Yoon Jae Hwang","userId":"10758045548003148631"}},"outputId":"04e6c567-1c93-48b4-a5c1-408781d955d7"},"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-d5b196983c59>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMonitor\u001b[0m \u001b[0;31m# If importing monitor raises issues, try using `from gym.wrappers import RecordVideo`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'Monitor' from 'gym.wrappers' (/usr/local/lib/python3.10/dist-packages/gym/wrappers/__init__.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from gym.wrappers import Monitor # If importing monitor raises issues, try using `from gym.wrappers import RecordVideo`\n","import glob\n","import io\n","import base64\n","\n","from IPython.display import HTML\n","from IPython import display as ipythondisplay\n","\n","from pyvirtualdisplay import Display\n","\n","# Displaying the game live\n","def show_state(env, step=0, info=\"\"):\n","    plt.figure(3)\n","    plt.clf()\n","    plt.imshow(env.render(mode='rgb_array'))\n","    plt.title(\"%s | Step: %d %s\" % (\"Agent Playing\",step, info))\n","    plt.axis('off')\n","\n","    ipythondisplay.clear_output(wait=True)\n","    ipythondisplay.display(plt.gcf())\n","    \n","# Recording the game and replaying the game afterwards\n","def show_video():\n","    mp4list = glob.glob('video/*.mp4')\n","    if len(mp4list) > 0:\n","        mp4 = mp4list[0]\n","        video = io.open(mp4, 'r+b').read()\n","        encoded = base64.b64encode(video)\n","        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))))\n","    else: \n","        print(\"Could not find video\")\n","    \n","\n","def wrap_env(env):\n","    env = Monitor(env, './video', force=True)\n","    return env"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ttd3gPoZ325G"},"outputs":[],"source":["display = Display(visible=0, size=(300, 200))\n","display.start()\n","\n","# Load agent\n","# agent.load_policy_net(\"./save_model/breakout_dqn.pth\")\n","agent.epsilon = 0.0 # Set agent to only exploit the best action\n","\n","env = gym.make('BreakoutDeterministic-v4')\n","env = wrap_env(env)\n","\n","done = False\n","score = 0\n","step = 0\n","state = env.reset()\n","next_state = state\n","life = number_lives\n","history = np.zeros([5, 84, 84], dtype=np.uint8)\n","get_init_state(history, state)\n","\n","while not done:\n","    \n","    # Render breakout\n","    env.render()\n","#     show_state(env,step) # uncommenting this provides another way to visualize the game\n","\n","    step += 1\n","    frame += 1\n","\n","    # Perform a fire action if ball is no longer on screen\n","    if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n","        action = 0\n","    else:\n","        action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n","    state = next_state\n","    \n","    next_state, reward, done, info = env.step(action + 1)\n","        \n","    frame_next_state = get_frame(next_state)\n","    history[4, :, :] = frame_next_state\n","    terminal_state = check_live(life, info['ale.lives'])\n","        \n","    life = info['ale.lives']\n","    r = np.clip(reward, -1, 1) \n","    r = reward\n","\n","    # Store the transition in memory \n","    agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n","    # Start training after random sample generation\n","    score += reward\n","    \n","    history[:4, :, :] = history[1:, :, :]\n","env.close()\n","show_video()\n","display.stop()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"csJyyHh-325H"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"},"colab":{"provenance":[],"machine_shape":"hm","collapsed_sections":["tM6TC9m6325F"],"gpuType":"T4"},"accelerator":"GPU","gpuClass":"premium"},"nbformat":4,"nbformat_minor":0}